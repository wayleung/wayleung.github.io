<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小梁的个人博客</title>
  
  <subtitle>wayleung</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-01-07T14:18:24.150Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Way Leung</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Async注解 导致该Bean在循环依赖时启动报错</title>
    <link href="http://example.com/2021/05/12/@Async%20%E5%AF%BC%E8%87%B4%E8%AF%A5Bean%E5%9C%A8%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E6%97%B6%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/"/>
    <id>http://example.com/2021/05/12/@Async%20%E5%AF%BC%E8%87%B4%E8%AF%A5Bean%E5%9C%A8%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E6%97%B6%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/</id>
    <published>2021-05-12T10:23:14.000Z</published>
    <updated>2024-01-07T14:18:24.150Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Async-导致该Bean在循环依赖时启动报错"><a href="#Async-导致该Bean在循环依赖时启动报错" class="headerlink" title="@Async 导致该Bean在循环依赖时启动报错"></a>@Async 导致该Bean在循环依赖时启动报错</h2><p>最新推荐文章于 2022-09-21 09:50:04 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2022-09-21 09:50:04 发布</p><p>版权声明：本文为博主原创文章，遵循 <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC 4.0 BY-SA</a> 版权协议，转载请附上原文出处链接和本声明。</p><p>今天在开发代码的时候遇到了一个启动错误，错误内容大致就是：</p><blockquote><p>org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name ‘classA’: Bean with name ‘classA’ has been injected into other beans [classB] in its raw version as part of a circular reference, but has eventually been wrapped. This means that said other beans do not use the final version of the bean. This is often the result of over-eager type matching - consider using ‘getBeanNamesOfType’ with the ‘allowEagerInit’ flag turned off, for example</p></blockquote><p>后面经过分析是跟我前面使用@Async注解有关，主要原因就是@Async 导致循环依赖失效，以下是我网上寻找的一些相关资料：</p><p><a href="https://segmentfault.com/a/1190000021217176">https://segmentfault.com/a/1190000021217176</a></p><p><a href="https://cloud.tencent.com/developer/article/1497689">https://cloud.tencent.com/developer/article/1497689</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Async-导致该Bean在循环依赖时启动报错&quot;&gt;&lt;a href=&quot;#Async-导致该Bean在循环依赖时启动报错&quot; class=&quot;headerlink&quot; title=&quot;@Async 导致该Bean在循环依赖时启动报错&quot;&gt;&lt;/a&gt;@Async 导致该Bean在循</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="原创" scheme="http://example.com/tags/%E5%8E%9F%E5%88%9B/"/>
    
  </entry>
  
  <entry>
    <title>Codis与RedisCluster的原理详解</title>
    <link href="http://example.com/2021/03/13/Codis%E4%B8%8ERedisCluster%E7%9A%84%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2021/03/13/Codis%E4%B8%8ERedisCluster%E7%9A%84%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-03-13T06:58:50.000Z</published>
    <updated>2024-01-07T10:21:22.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Codis与RedisCluster的原理详解"><a href="#Codis与RedisCluster的原理详解" class="headerlink" title="Codis与RedisCluster的原理详解"></a><a href="https://www.cnblogs.com/pingyeaa/p/11294773.html">Codis与RedisCluster的原理详解</a></h2><p>最近入职新公司，公司使用的是Codis去同步Redis节点间的数据，所以最近去了解一下Codis的相关知识，找到一篇不错的文章，故转载下来</p><h3 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍#"></a>背景介绍<a href="https://www.cnblogs.com/pingyeaa/p/11294773.html#381988702">#</a></h3><p>我们先来看一下为什么要做集群，如果我们要部署一个单节点Redis，很明显会遇到单点故障的问题。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141103915-106719622.png"><img src="https://img-blog.csdnimg.cn/img_convert/b6db2d7c186516e1ee572d2f553df61b.png"></a></p><p>首先能想到解决单点故障的方法，就是做主从，但是当有海量存储需求时，单一的主从结构就会出问题，说问题之前要先了解一下主从之间是如何复制的。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141411608-792399561.png"><img src="https://img-blog.csdnimg.cn/img_convert/8db81742befce4fb90c531d2c3375c78.png"></a></p><p>我们把Redis分为三个部分，分别是客户端、主节点以及从节点，如果从节点要同步主节点的数据，它首先会发Sync指令给主节点，主节点收到指令之后会执行BGSAVE命令生成RDB文件，这个RDB文件指的是快照文件，它是Redis两种备份方式的其中一种，另一种叫AOF，它的原理是将所有的写入指令存入文件，mysql的binlog原理是一样的。</p><p>如果主节点在生成RDB的过程当中，客户端发来了写入指令，这个时候主节点会把指令全部写入缓冲区，等RDB生成完了，会把RDB文件发送给从节点，最后再把缓冲区的指令发送给从节点。这样就完成了整个的复制。</p><p>我们刚才说单纯地做主从是有缺陷的，这个缺陷就是如果我们要存储海量的数据，那么BGSAVE指令生成的RDB文件会非常巨大，这个文件传送给从节点也会非常慢，如果缓冲区命令很多的话，从节点同步数据时也会执行很久，所以，要解决单点问题和海量存储问题，还是要考虑做集群。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141301491-828982558.png"><img src="https://img-blog.csdnimg.cn/img_convert/fa9320154f5b3f82293dec53903e47d6.png"></a></p><h3 id="Redis常见集群方案"><a href="#Redis常见集群方案" class="headerlink" title="Redis常见集群方案#"></a>Redis常见集群方案<a href="https://www.cnblogs.com/pingyeaa/p/11294773.html#3388209721">#</a></h3><p>Redis集群方案目前主流的有三种，分别是Twemproxy、Codis和Redis Cluster。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141518199-781410417.png"><img src="https://img-blog.csdnimg.cn/img_convert/cb3bcdb745da8bd59f9d3aa1050c4b93.png"></a></p><p>Twemproxy，是推特开源的，它最大的缺点就是无法平滑的扩缩容，而Codis解决了Twemproxy扩缩容的问题，而且兼容了Twemproxy，它是由豌豆荚开源的，和Twemproxy都是代理模式。其实Codis能发展起来的一个主要原因是它是在Redis官方集群方案漏洞百出的时候率先成熟稳定的。以现在的Redis官方集群方案，这两个好像没有太大差别了，不过我也没有去做性能测试，不清楚哪个最好。</p><p>Redis Cluster是由官方出品的，用去中心化的方式实现，不属于代理模式，今天主要讲codis，redis cluster后面也会过一下。下面，来看一下Codis的实现原理。</p><h3 id="Codis原理"><a href="#Codis原理" class="headerlink" title="Codis原理#"></a>Codis原理<a href="https://www.cnblogs.com/pingyeaa/p/11294773.html#3237315914">#</a></h3><p>我们换一种方式去讲，就按照Codis的架构演进一下，这样理解会比较清晰一点，假如现在只有一个Redis Server，怎么让它变得高可用？</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141623637-1144964117.png"><img src="https://img-blog.csdnimg.cn/img_convert/d51b5e57179e78e09b633aeb88a35ea5.png"></a></p><p>开篇的时候也有讲，首先，能想到的就是做主从，这样就算主宕机了，从节点也能马上接替主节点的位置。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141735392-1050303803.png"><img src="https://img-blog.csdnimg.cn/img_convert/8b06d4f3cc1e17fcc98109b8944ab0d7.png"></a></p><p>我们现在已经做成主从结构了，那到底是谁来负责主从之间的切换？</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141802667-83409709.png"><img src="https://img-blog.csdnimg.cn/img_convert/b45cb95f1c8f6bc4b3fe9b9fc944fd61.png"></a></p><p>就是它，Sentinel，中文名叫哨兵，它呢，在Redis里面主要负责监控主从节点，如果主节点挂了，就会把从拉起来。但是哨兵本身也存在单点问题，所以它也需要做集群。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141826584-1854393400.png"><img src="https://img-blog.csdnimg.cn/img_convert/a31709270623f45d43669ac24e073fe0.png"></a></p><p>那么问题来了，哨兵是如何做主从切换呢？来看下哨兵的运行机制。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141909126-1869770004.png"><img src="https://img-blog.csdnimg.cn/img_convert/d4e170ac091f1784f0a8e3e6482be2d6.png"></a></p><p>假如有三个哨兵和一主两从的节点，下面是一主多从，哨兵之间会互相监测运行状态，并且会交换一下节点监测的状态，同时哨兵也会监测主从节点的状态。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803141937106-298777220.png"><img src="https://img-blog.csdnimg.cn/img_convert/7a7908b6ec4ab2b779920cc85ce36a57.png"></a></p><p>如果检测到某一个节点没有正常回复，并且距离上次正常回复的时间超过了某个阈值，那么就认为该节点为主观下线。</p><p>这个时候其他哨兵也会来监测该节点是不是真的主观下线，如果有足够多数量的哨兵都认为它确实主观下线了，那么它就会被标记为客观下线，这个时候哨兵会找下线节点的从节点，然后与其他哨兵协商出一个从节点做主节点，并将剩余的从节点指向新的主节点。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142023904-1656961626.png"><img src="https://img-blog.csdnimg.cn/img_convert/7073627e3030fc933542ccd818e123c0.png"></a></p><p>关于主从节点的切换有两个环节，第一个是哨兵要选举出领头人来负责下线机器的故障转移，第二是从Slave中选出主节点，领头人的选举规则是谁发现客观下线谁就可以马上要求其他哨兵认自己做老大，其他哨兵会无条件接受第一个发过来的人，并告知老大，如果超过一半人都同意了，那他老大的位置就坐实了。</p><p>关于从节点选举，一共有四个因素影响选举的结果，分别是断开连接时长、优先级排序、复制数量、进程id，如果连接断开的比较久，超过了某个阈值，就直接失去了选举权，如果拥有选举权，那就看谁的优先级高，这个在配置文件里可以设置，数值越小优先级越高，如果优先级相同，就看谁从master中复制的数据最多，选最多的那个，如果复制数量也相同，就选择进程id最小的那个。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142133873-2076188484.png"><img src="https://img-blog.csdnimg.cn/img_convert/342288e247a5c1c1ec0e0648b56e4b1f.png"></a></p><p>现在继续回过来，刚才讲痛点的时候说了，如果有存储海量数据的需求，同步会非常缓慢，所以我们应该把一个主从结构变成多个，把存储的key分摊到各个主从结构中来分担压力。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142157383-1209357826.png"><img src="https://img-blog.csdnimg.cn/img_convert/613a9fb4039d4c9108460c36cd566396.png"></a></p><p>就像这样，代理通过一种算法把要操作的key经过计算后分配到各个组中，这个过程叫做分片，我们来看一下分片的实现原理。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142215915-1873691463.png"><img src="https://img-blog.csdnimg.cn/img_convert/990c09e16ba4cd360b775dbd24bea91c.png"></a></p><h4 id="分片算法"><a href="#分片算法" class="headerlink" title="分片算法#"></a>分片算法<a href="https://www.cnblogs.com/pingyeaa/p/11294773.html#3119962178">#</a></h4><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142316372-1255776349.png"><img src="https://img-blog.csdnimg.cn/img_convert/951d430eb1c33b74ba99018cc67655b0.png"></a></p><p>在Codis里面，它把所有的key分为1024个槽，每一个槽位都对应了一个分组，具体槽位的分配，可以进行自定义，现在如果有一个key进来，首先要根据CRC32算法，针对key算出32位的哈希值，然后除以1024取余，然后就能算出这个KEY属于哪个槽，然后根据槽与分组的映射关系，就能去对应的分组当中处理数据了。</p><p>CRC全称是循环冗余校验，主要在数据存储和通信领域保证数据正确性的校验手段，我去看了这个算法的原理，还没理解透彻，这里就先不讲了，省得误导大家。</p><p>我们继续回过来，刚才所讲的槽位和分组的映射关系就保存在codis proxy当中，但是codis proxy它本身也存在单点问题，所以需要对proxy做一个集群。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142412234-301773304.png"><img src="https://img-blog.csdnimg.cn/img_convert/cf68d0878e02b2cdd1a5b45734adad5e.png"></a></p><p>部署好集群之后，有一个问题，就是槽位的映射关系是保存在proxy里面的，不同proxy之间怎么同步映射关系？</p><p>在Codis中使用的是Zookeeper来保存映射关系，由proxy上来同步配置信息，其实它支持的不止zookeeper，还有etcd和本地文件。在zookeeper中保存的数据格式就是这个样子。除了这个还会存储一些其他的信息，比如分组信息、代理信息等，感兴趣可以自己去了解一下。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142440305-245260215.png"><img src="https://img-blog.csdnimg.cn/img_convert/69ecf12069f8cee35ccbaade6d0dd0e0.png"></a></p><p>现在还有一个问题，就是codis proxy如果出现异常怎么处理，这个可能要利用一下k8s中pod的特性，在k8s里面可以设置pod冗余的数量，k8s会严格保证启动的数量与设置一致，所以只需要一个进程监测Proxy的异常，并且把它干掉就可以了，k8s会自动拉起来一个新的proxy。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142517608-1773814847.png"><img src="https://img-blog.csdnimg.cn/img_convert/ba36eab6d57b2587355c222bec1fd128.png"></a></p><p>codis给这个进程起名叫codis-ha，codis-ha实时监测proxy的运行状态，如果有异常就会干掉，它包含了哨兵的功能，所以豌豆荚直接把哨兵去掉了。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142546334-1563551816.png"><img src="https://img-blog.csdnimg.cn/img_convert/0b2c5c1112b25e0273d417c4f3ce1f3a.png"></a></p><p>但是codis-ha在Codis整个架构中是没有办法直接操作代理和服务，因为所有的代理和服务的操作都要经过dashboard处理。所以部署的时候会利用k8s的亲和性将codis-ha与dashboard部署在同一个节点上。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142613948-1526515846.png"><img src="https://img-blog.csdnimg.cn/img_convert/ac12eb13e37f6278dd99e8f72aa714a0.png"></a></p><p>除了这些，codis自己开发了集群管理界面，集群管理可以通过界面化的方式更方便的管理集群，这个模块叫codis-fe，我们可以看一下这个界面。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142713278-1555622317.png"><img src="https://img-blog.csdnimg.cn/img_convert/5427c8fa82932768fcc479eb21d6c269.png"></a></p><p>最后就是redis客户端了，这个没什么好讲的，客户端是直接通过代理来访问后端服务的。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142738274-34924996.png"><img src="https://img-blog.csdnimg.cn/img_convert/95a8c93bdb5532713108ab80c2b56477.png"></a></p><h3 id="Redis-Cluster原理"><a href="#Redis-Cluster原理" class="headerlink" title="Redis Cluster原理#"></a>Redis Cluster原理<a href="https://www.cnblogs.com/pingyeaa/p/11294773.html#2060064721">#</a></h3><p>下面来看一下redis cluster的原理，它和codis不太一样，Codis它是通过代理分片的，但是Redis Cluster是去中心化的没有代理，所以只能通过客户端分片，它分片的槽数跟Codis不太一样，Codis是1024个，而Redis cluster有16384个，槽跟节点的映射关系保存在每个节点上，每个节点每秒钟会ping十次其他几个最久没通信的节点，其他节点也是一样的原理互相PING ，PING的时候一个是判断其他节点有没有问题，另一个是顺便交换一下当前集群的节点信息、包括槽与节点映射的关系等。客户端操作key的时候先通过分片算法算出所属的槽，然后随机找一个服务端请求。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142840591-167003063.png"><img src="https://img-blog.csdnimg.cn/img_convert/7e1bc48c8a96881ab6d515d9adec1afd.png"></a></p><p>但是可能这个槽并不归随机找的这个节点管，节点如果发现不归自己管，就会返回一个MOVED ERROR通知，引导客户端去正确的节点访问，这个时候客户端就会去正确的节点操作数据。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142931535-1671539941.png"><img src="https://img-blog.csdnimg.cn/img_convert/6b34dd05b2a7fb8d2c4e15908266472d.png"></a></p><p>这是RedisCluster大概的原理，下面看一下Codis跟RedisCluster简要的区别。</p><p><a href="https://img2018.cnblogs.com/blog/1471773/201908/1471773-20190803142957436-474723415.png"><img src="https://img-blog.csdnimg.cn/img_convert/b6a006f88dcef7f2cf1b07f9405f58cd.png"></a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Codis与RedisCluster的原理详解&quot;&gt;&lt;a href=&quot;#Codis与RedisCluster的原理详解&quot; class=&quot;headerlink&quot; title=&quot;Codis与RedisCluster的原理详解&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>Spring 循环依赖和三级缓存</title>
    <link href="http://example.com/2021/01/19/Spring%20%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%92%8C%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98/"/>
    <id>http://example.com/2021/01/19/Spring%20%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%92%8C%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98/</id>
    <published>2021-01-19T03:34:14.000Z</published>
    <updated>2024-01-07T14:12:36.194Z</updated>
    
    <content type="html"><![CDATA[<p>前言</p><p>Spring中的循环依赖一直是Spring中一个很重要的话题，一方面是因为源码中为了解决循环依赖做了很多处理，另外一方面是因为面试的时候，如果问到Spring中比较高阶的问题，那么循环依赖必定逃不掉。如果你回答得好，那么这就是你的必杀技，反正，那就是面试官的必杀技，这也是取这个标题的原因，当然，本文的目的是为了让你在之后的所有面试中能多一个必杀技，专门用来绝杀面试官！</p><p>本文的核心思想就是，</p><p>当面试官问：</p><p>“请讲一讲Spring中的循环依赖。”的时候，</p><p>我们到底该怎么回答？</p><p>主要分下面几点</p><h3 id="什么是循环依赖？"><a href="#什么是循环依赖？" class="headerlink" title="什么是循环依赖？"></a>什么是循环依赖？</h3><p>什么情况下循环依赖可以被处理？</p><p>Spring是如何解决的循环依赖？</p><p>同时本文希望纠正几个目前业界内经常出现的几个关于循环依赖的错误的说法</p><p>只有在setter方式注入的情况下，循环依赖才能解决（错）</p><p>三级缓存的目的是为了提高效率（错）</p><p>OK，铺垫已经做完了，接下来我们开始正文</p><p>什么是循环依赖？</p><p>从字面上来理解就是A依赖B的同时B也依赖了A，就像下面这样</p><p><img src="https://img-blog.csdnimg.cn/img_convert/49462131406f26c9ee2f631344847803.png"></p><p>体现到代码层次就是这个样子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs auto">@Component<br>public class A &#123;<br>    // A中注入了B<br>    @Autowired<br>    private B b;<br>&#125;<br><br>@Component<br>public class B &#123;<br>    // B中也注入了A<br>    @Autowired<br>    private A a;<br>&#125;<br></code></pre></td></tr></table></figure><p>当然，这是最常见的一种循环依赖，比较特殊的还有</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs auto">// 自己依赖自己<br>@Component<br>public class A &#123;<br>    // A中注入了A<br>    @Autowired<br>    private A a;<br>&#125;<br></code></pre></td></tr></table></figure><p>虽然体现形式不一样，但是实际上都是同一个问题—–&gt;循环依赖</p><h3 id="什么情况下循环依赖可以被处理？"><a href="#什么情况下循环依赖可以被处理？" class="headerlink" title="什么情况下循环依赖可以被处理？"></a>什么情况下循环依赖可以被处理？</h3><p>在回答这个问题之前首先要明确一点，Spring解决循环依赖是有前置条件的</p><p>出现循环依赖的Bean必须要是单例</p><p>依赖注入的方式不能全是构造器注入的方式（很多博客上说，只能解决setter方法的循环依赖，这是错误的）</p><p>其中第一点应该很好理解，第二点：不能全是构造器注入是什么意思呢？我们还是用代码说话</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs auto">@Component<br>public class A &#123;<br>//    @Autowired<br>//    private B b;<br>    public A(B b) &#123;<br><br>    &#125;<br>&#125;<br><br><br>@Component<br>public class B &#123;<br><br>//    @Autowired<br>//    private A a;<br><br>    public B(A a)&#123;<br><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在上面的例子中，A中注入B的方式是通过构造器，B中注入A的方式也是通过构造器，这个时候循环依赖是无法被解决，如果你的项目中有两个这样相互依赖的Bean，在启动时就会报出以下错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs auto">Caused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &#x27;a&#x27;: Requested bean is currently in creation: Is there an unresolvable circular reference?<br></code></pre></td></tr></table></figure><p>为了测试循环依赖的解决情况跟注入方式的关系，我们做如下四种情况的测试：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/670ce918ea6d1da0797b73bff859a782.png"></p><p>具体的测试代码跟简单，我就不放了。从上面的测试结果我们可以看到，不是只有在setter方法注入的情况下循环依赖才能被解决，即使存在构造器注入的场景下，循环依赖依然被可以被正常处理掉。</p><p>那么到底是为什么呢？Spring到底是怎么处理的循环依赖呢？不要急，我们接着往下看</p><h3 id="Spring是如何解决的循环依赖？"><a href="#Spring是如何解决的循环依赖？" class="headerlink" title="Spring是如何解决的循环依赖？"></a>Spring是如何解决的循环依赖？</h3><p>关于循环依赖的解决方式应该要分两种情况来讨论</p><p>简单的循环依赖（没有AOP）</p><p>结合了AOP的循环依赖</p><p>简单的循环依赖（没有AOP）</p><p>我们先来分析一个最简单的例子，就是上面提到的那个demo</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs auto">@Component<br>public class A &#123;<br>    // A中注入了B<br>    @Autowired<br>    private B b;<br>&#125;<br><br>@Component<br>public class B &#123;<br>    // B中也注入了A<br>    @Autowired<br>    private A a;<br>&#125;<br></code></pre></td></tr></table></figure><p>通过上文我们已经知道了这种情况下的循环依赖是能够被解决的，那么具体的流程是什么呢？我们一步步分析</p><p>首先，我们要知道Spring在创建Bean的时候默认是按照自然排序来进行创建的，所以第一步Spring会去创建A。</p><p>与此同时，我们应该知道，Spring在创建Bean的过程中分为三步</p><p>实例化，对应方法：AbstractAutowireCapableBeanFactory中的createBeanInstance方法</p><p>属性注入，对应方法：AbstractAutowireCapableBeanFactory的populateBean方法</p><p>初始化，对应方法：AbstractAutowireCapableBeanFactory的initializeBean</p><p>这些方法在之前源码分析的文章中都做过详细的解读了，如果你之前没看过我的文章，那么你只需要知道</p><p>实例化，简单理解就是new了一个对象</p><p>属性注入，为实例化中new出来的对象填充属性</p><p>初始化，执行aware接口中的方法，初始化方法，完成AOP代理</p><p>基于上面的知识，我们开始解读整个循环依赖处理的过程，整个流程应该是以A的创建为起点，前文也说了，第一步就是创建A嘛！</p><p><img src="https://img-blog.csdnimg.cn/img_convert/b37eeaa5a8bb088c02c50aec435e8791.png"></p><p>创建A的过程实际上就是调用getBean方法，这个方法有两层含义</p><p>创建一个新的Bean</p><p>从缓存中获取到已经被创建的对象</p><p>我们现在分析的是第一层含义，因为这个时候缓存中还没有A嘛！</p><h3 id="调用getSingleton-beanName"><a href="#调用getSingleton-beanName" class="headerlink" title="调用getSingleton(beanName)"></a>调用getSingleton(beanName)</h3><p>首先调用getSingleton(a)方法，这个方法又会调用getSingleton(beanName, true)，在上图中我省略了这一步</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs auto">public Object getSingleton(String beanName) &#123;<br>    return getSingleton(beanName, true);<br>&#125;<br></code></pre></td></tr></table></figure><p>getSingleton(beanName, true)这个方法实际上就是到缓存中尝试去获取Bean，整个缓存分为三级</p><p>singletonObjects，一级缓存，存储的是所有创建好了的单例Bean</p><p>earlySingletonObjects，完成实例化，但是还未进行属性注入及初始化的对象</p><p>singletonFactories，提前暴露的一个单例工厂，二级缓存中存储的就是从这个工厂中获取到的对象</p><p>因为A是第一次被创建，所以不管哪个缓存中必然都是没有的，因此会进入getSingleton的另外一个重载方法getSingleton(beanName, singletonFactory)。</p><h3 id="调用getSingleton-beanName-singletonFactory"><a href="#调用getSingleton-beanName-singletonFactory" class="headerlink" title="调用getSingleton(beanName, singletonFactory)"></a>调用getSingleton(beanName, singletonFactory)</h3><p>这个方法就是用来创建Bean的，其源码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs auto">public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;<br>    Assert.notNull(beanName, &quot;Bean name must not be null&quot;);<br>    synchronized (this.singletonObjects) &#123;<br>        Object singletonObject = this.singletonObjects.get(beanName);<br>        if (singletonObject == null) &#123;<br><br>            // ....<br>            // 省略异常处理及日志<br>            // ....<br><br>            // 在单例对象创建前先做一个标记<br>            // 将beanName放入到singletonsCurrentlyInCreation这个集合中<br>            // 标志着这个单例Bean正在创建<br>            // 如果同一个单例Bean多次被创建，这里会抛出异常<br>            beforeSingletonCreation(beanName);<br>            boolean newSingleton = false;<br>            boolean recordSuppressedExceptions = (this.suppressedExceptions == null);<br>            if (recordSuppressedExceptions) &#123;<br>                this.suppressedExceptions = new LinkedHashSet&lt;&gt;();<br>            &#125;<br>            try &#123;<br>                // 上游传入的lambda在这里会被执行，调用createBean方法创建一个Bean后返回<br>                singletonObject = singletonFactory.getObject();<br>                newSingleton = true;<br>            &#125;<br>            // ...<br>            // 省略catch异常处理<br>            // ...<br>            finally &#123;<br>                if (recordSuppressedExceptions) &#123;<br>                    this.suppressedExceptions = null;<br>                &#125;<br>                // 创建完成后将对应的beanName从singletonsCurrentlyInCreation移除<br>                afterSingletonCreation(beanName);<br>            &#125;<br>            if (newSingleton) &#123;<br>                // 添加到一级缓存singletonObjects中<br>                addSingleton(beanName, singletonObject);<br>            &#125;<br>        &#125;<br>        return singletonObject;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的代码我们主要抓住一点，通过createBean方法返回的Bean最终被放到了一级缓存，也就是单例池中。</p><p>那么到这里我们可以得出一个结论：一级缓存中存储的是已经完全创建好了的单例Bean</p><h3 id="调用addSingletonFactory方法"><a href="#调用addSingletonFactory方法" class="headerlink" title="调用addSingletonFactory方法"></a>调用addSingletonFactory方法</h3><p>如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/fefaade085b561704af220ceef300b53.png"></p><p>在完成Bean的实例化后，属性注入之前Spring将Bean包装成一个工厂添加进了三级缓存中，对应源码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs auto">// 这里传入的参数也是一个lambda表达式，() -&gt; getEarlyBeanReference(beanName, mbd, bean)<br>protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;<br>    Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;);<br>    synchronized (this.singletonObjects) &#123;<br>        if (!this.singletonObjects.containsKey(beanName)) &#123;<br>            // 添加到三级缓存中<br>            this.singletonFactories.put(beanName, singletonFactory);<br>            this.earlySingletonObjects.remove(beanName);<br>            this.registeredSingletons.add(beanName);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这里只是添加了一个工厂，通过这个工厂（ObjectFactory）的getObject方法可以得到一个对象，而这个对象实际上就是通过getEarlyBeanReference这个方法创建的。那么，什么时候会去调用这个工厂的getObject方法呢？这个时候就要到创建B的流程了。</p><p>当A完成了实例化并添加进了三级缓存后，就要开始为A进行属性注入了，在注入时发现A依赖了B，那么这个时候Spring又会去getBean(b)，然后反射调用setter方法完成属性注入。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/b7e6c73f67c84e50c11bbadfd806f5de.png"></p><p>因为B需要注入A，所以在创建B的时候，又会去调用getBean(a)，这个时候就又回到之前的流程了，但是不同的是，之前的getBean是为了创建Bean，而此时再调用getBean不是为了创建了，而是要从缓存中获取，因为之前A在实例化后已经将其放入了三级缓存singletonFactories中，所以此时getBean(a)的流程就是这样子了。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/f5d078f0b1c26589d9ae5be4cf883402.png"></p><p>从这里我们可以看出，注入到B中的A是通过getEarlyBeanReference方法提前暴露出去的一个对象，还不是一个完整的Bean，那么getEarlyBeanReference到底干了啥了，我们看下它的源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs auto">protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123;<br>    Object exposedObject = bean;<br>    if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123;<br>        for (BeanPostProcessor bp : getBeanPostProcessors()) &#123;<br>            if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123;<br>                SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;<br>                exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);<br>            &#125;<br>        &#125;<br>    &#125;<br>    return exposedObject;<br>&#125;<br></code></pre></td></tr></table></figure><p>它实际上就是调用了后置处理器的getEarlyBeanReference，而真正实现了这个方法的后置处理器只有一个，就是通过@EnableAspectJAutoProxy注解导入的AnnotationAwareAspectJAutoProxyCreator。也就是说如果在不考虑AOP的情况下，上面的代码等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs auto">protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123;<br>    Object exposedObject = bean;<br>    return exposedObject;<br>&#125;<br></code></pre></td></tr></table></figure><p>也就是说这个工厂啥都没干，直接将实例化阶段创建的对象返回了！所以说在不考虑AOP的情况下三级缓存有用嘛？讲道理，真的没什么用，我直接将这个对象放到二级缓存中不是一点问题都没有吗？如果你说它提高了效率，那你告诉我提高的效率在哪?</p><p>那么三级缓存到底有什么作用呢？不要急，我们先把整个流程走完，在下文结合AOP分析循环依赖的时候你就能体会到三级缓存的作用！</p><p>到这里不知道小伙伴们会不会有疑问，B中提前注入了一个没有经过初始化的A类型对象不会有问题吗？</p><p>答：不会</p><p>这个时候我们需要将整个创建A这个Bean的流程走完，如下图：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/49ed72a2793cccdb3800e41075228daf.png"></p><p>从上图中我们可以看到，虽然在创建B时会提前给B注入了一个还未初始化的A对象，但是在创建A的流程中一直使用的是注入到B中的A对象的引用，之后会根据这个引用对A进行初始化，所以这是没有问题的。</p><h3 id="结合了AOP的循环依赖"><a href="#结合了AOP的循环依赖" class="headerlink" title="结合了AOP的循环依赖"></a>结合了AOP的循环依赖</h3><p>之前我们已经说过了，在普通的循环依赖的情况下，三级缓存没有任何作用。三级缓存实际上跟Spring中的AOP相关，我们再来看一看getEarlyBeanReference的代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs auto">protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123;<br>    Object exposedObject = bean;<br>    if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123;<br>        for (BeanPostProcessor bp : getBeanPostProcessors()) &#123;<br>            if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123;<br>                SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;<br>                exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);<br>            &#125;<br>        &#125;<br>    &#125;<br>    return exposedObject;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果在开启AOP的情况下，那么就是调用到AnnotationAwareAspectJAutoProxyCreator的getEarlyBeanReference方法，对应的源码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs auto">public Object getEarlyBeanReference(Object bean, String beanName) &#123;<br>    Object cacheKey = getCacheKey(bean.getClass(), beanName);<br>    this.earlyProxyReferences.put(cacheKey, bean);<br>    // 如果需要代理，返回一个代理对象，不需要代理，直接返回当前传入的这个bean对象<br>    return wrapIfNecessary(bean, beanName, cacheKey);<br>&#125;<br></code></pre></td></tr></table></figure><p>回到上面的例子，我们对A进行了AOP代理的话，那么此时getEarlyBeanReference将返回一个代理后的对象，而不是实例化阶段创建的对象，这样就意味着B中注入的A将是一个代理对象而不是A的实例化阶段创建后的对象。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/ce0a289060ce766f18710e20eb94ddc6.png"></p><p>看到这个图你可能会产生下面这些疑问</p><p>在给B注入的时候为什么要注入一个代理对象？</p><p>答：当我们对A进行了AOP代理时，说明我们希望从容器中获取到的就是A代理后的对象而不是A本身，因此把A当作依赖进行注入时也要注入它的代理对象</p><p>明明初始化的时候是A对象，那么Spring是在哪里将代理对象放入到容器中的呢？</p><p><img src="https://img-blog.csdnimg.cn/img_convert/129a11ee7d70690e46c0101341dd08d4.png"></p><p>在完成初始化后，Spring又调用了一次getSingleton方法，这一次传入的参数又不一样了，false可以理解为禁用三级缓存，前面图中已经提到过了，在为B中注入A时已经将三级缓存中的工厂取出，并从工厂中获取到了一个对象放入到了二级缓存中，所以这里的这个getSingleton方法做的时间就是从二级缓存中获取到这个代理后的A对象。exposedObject &#x3D;&#x3D; bean可以认为是必定成立的，除非你非要在初始化阶段的后置处理器中替换掉正常流程中的Bean，例如增加一个后置处理器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs auto">@Component<br>public class MyPostProcessor implements BeanPostProcessor &#123;<br>    @Override<br>    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;<br>        if (beanName.equals(&quot;a&quot;)) &#123;<br>            return new A();<br>        &#125;<br>        return bean;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>不过，请不要做这种骚操作，徒增烦恼！</p><p>初始化的时候是对A对象本身进行初始化，而容器中以及注入到B中的都是代理对象，这样不会有问题吗？</p><p>答：不会，这是因为不管是cglib代理还是jdk动态代理生成的代理类，内部都持有一个目标类的引用，当调用代理对象的方法时，实际会去调用目标对象的方法，A完成初始化相当于代理对象自身也完成了初始化</p><p>三级缓存为什么要使用工厂而不是直接使用引用？换而言之，为什么需要这个三级缓存，直接通过二级缓存暴露一个引用不行吗？</p><p>答：这个工厂的目的在于延迟对实例化阶段生成的对象的代理，只有真正发生循环依赖的时候，才去提前生成代理对象，否则只会创建一个工厂并将其放入到三级缓存中，但是不会去通过这个工厂去真正创建对象</p><p>我们思考一种简单的情况，就以单独创建A为例，假设AB之间现在没有依赖关系，但是A被代理了，这个时候当A完成实例化后还是会进入下面这段代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs auto">// A是单例的，mbd.isSingleton()条件满足<br>// allowCircularReferences：这个变量代表是否允许循环依赖，默认是开启的，条件也满足<br>// isSingletonCurrentlyInCreation：正在在创建A，也满足<br>// 所以earlySingletonExposure=true<br>boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;<br>                                  isSingletonCurrentlyInCreation(beanName));<br>// 还是会进入到这段代码中<br>if (earlySingletonExposure) &#123;<br>    // 还是会通过三级缓存提前暴露一个工厂对象<br>    addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));<br>&#125;<br></code></pre></td></tr></table></figure><p>看到了吧，即使没有循环依赖，也会将其添加到三级缓存中，而且是不得不添加到三级缓存中，因为到目前为止Spring也不能确定这个Bean有没有跟别的Bean出现循环依赖。</p><p>假设我们在这里直接使用二级缓存的话，那么意味着所有的Bean在这一步都要完成AOP代理。这样做有必要吗？</p><p>不仅没有必要，而且违背了Spring在结合AOP跟Bean的生命周期的设计！Spring结合AOP跟Bean的生命周期本身就是通过AnnotationAwareAspectJAutoProxyCreator这个后置处理器来完成的，在这个后置处理的postProcessAfterInitialization方法中对初始化后的Bean完成AOP代理。如果出现了循环依赖，那没有办法，只有给Bean先创建代理，但是没有出现循环依赖的情况下，设计之初就是让Bean在生命周期的最后一步完成代理而不是在实例化后就立马完成代理。</p><h3 id="三级缓存真的提高了效率了吗？"><a href="#三级缓存真的提高了效率了吗？" class="headerlink" title="三级缓存真的提高了效率了吗？"></a>三级缓存真的提高了效率了吗？</h3><p>现在我们已经知道了三级缓存的真正作用，但是这个答案可能还无法说服你，所以我们再最后总结分析一波，三级缓存真的提高了效率了吗？分为两点讨论：</p><p>没有进行AOP的Bean间的循环依赖</p><p>从上文分析可以看出，这种情况下三级缓存根本没用！所以不会存在什么提高了效率的说法</p><p>进行了AOP的Bean间的循环依赖</p><p>就以我们上的A、B为例，其中A被AOP代理，我们先分析下使用了三级缓存的情况下，A、B的创建流程</p><p><img src="https://img-blog.csdnimg.cn/img_convert/ea2b630fc6e5055e1e91699e1ba0f389.png"></p><p>假设不使用三级缓存，直接在二级缓存中。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/75153d446d1c125a9605aa9c881904b1.png"></p><p>上面两个流程的唯一区别在于为A对象创建代理的时机不同，在使用了三级缓存的情况下为A创建代理的时机是在B中需要注入A的时候，而不使用三级缓存的话在A实例化后就需要马上为A创建代理然后放入到二级缓存中去。对于整个A、B的创建过程而言，消耗的时间是一样的</p><p>综上，不管是哪种情况，三级缓存提高了效率这种说法都是错误的！</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>面试官：”Spring是如何解决的循环依赖？“</p><p>答：Spring通过三级缓存解决了循环依赖，其中一级缓存为单例池（singletonObjects）,二级缓存为早期曝光对象earlySingletonObjects，三级缓存为早期曝光对象工厂（singletonFactories）。当A、B两个类发生循环引用时，在A完成实例化后，就使用实例化后的对象去创建一个对象工厂，并添加到三级缓存中，如果A被AOP代理，那么通过这个工厂获取到的就是A代理后的对象，如果A没有被AOP代理，那么这个工厂获取到的就是A实例化的对象。当A进行属性注入时，会去创建B，同时B又依赖了A，所以创建B的同时又会去调用getBean(a)来获取需要的依赖，此时的getBean(a)会从缓存中获取，第一步，先获取到三级缓存中的工厂；第二步，调用对象工工厂的getObject方法来获取到对应的对象，得到这个对象后将其注入到B中。紧接着B会走完它的生命周期流程，包括初始化、后置处理器等。当B创建完后，会将B再注入到A中，此时A再完成它的整个生命周期。至此，循环依赖结束！</p><p>面试官：”为什么要使用三级缓存呢？二级缓存能解决循环依赖吗？“</p><p>答：如果要使用二级缓存解决循环依赖，意味着所有Bean在实例化后就要完成AOP代理，这样违背了Spring设计的原则，Spring在设计之初就是通过AnnotationAwareAspectJAutoProxyCreator这个后置处理器来在Bean生命周期的最后一步来完成AOP代理，而不是在实例化后就立马进行AOP代理。</p><h3 id="一道思考题"><a href="#一道思考题" class="headerlink" title="一道思考题"></a>一道思考题</h3><p>为什么在下表中的第三种情况的循环依赖能被解决，而第四种情况不能被解决呢？</p><p>提示：Spring在创建Bean时默认会根据自然排序进行创建，所以A会先于B进行创建。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/80dae51e68b503803e4143ec18864c8c.png"></p><p>作者：Java程序猿阿谷<br>链接：<a href="https://zhuanlan.zhihu.com/p/157611040">https://zhuanlan.zhihu.com/p/157611040</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前言&lt;/p&gt;
&lt;p&gt;Spring中的循环依赖一直是Spring中一个很重要的话题，一方面是因为源码中为了解决循环依赖做了很多处理，另外一方面是因为面试的时候，如果问到Spring中比较高阶的问题，那么循环依赖必定逃不掉。如果你回答得好，那么这就是你的必杀技，反正，那就是面试</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>Linux面试的5个经典问题</title>
    <link href="http://example.com/2021/01/08/Linux%E9%9D%A2%E8%AF%95%E7%9A%845%E4%B8%AA%E7%BB%8F%E5%85%B8%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2021/01/08/Linux%E9%9D%A2%E8%AF%95%E7%9A%845%E4%B8%AA%E7%BB%8F%E5%85%B8%E9%97%AE%E9%A2%98/</id>
    <published>2021-01-08T08:14:00.000Z</published>
    <updated>2024-01-07T14:12:24.601Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-CPU负载和CPU利用率的区别是什么？"><a href="#1-CPU负载和CPU利用率的区别是什么？" class="headerlink" title="1.CPU负载和CPU利用率的区别是什么？"></a>1.CPU负载和CPU利用率的区别是什么？</h4><p>首先，我们可以通过<code>uptime</code>，<code>w</code>或者<code>top</code>命令看到CPU的平均负载。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaHZ3UklsSmQ4cFNmU2I2QUF4dzFrVWhGUEo4S2liUmlhNEt4a0hXSHdCUXZUT2todGliMzlLeGZ2Zy82NDA?x-oss-process=image/format,png"> <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaERZNnlJTkJZaEV5Y3dsWldyOFh4R3FoaWFTNW1velZNVlozeXE0MkgyZEF5WldnUVh4a0ZVcWcvNjQw?x-oss-process=image/format,png"></p><p><strong>Load Average</strong> ：负载的3个数字，比如上图的4.86，5.28，5.00，分别代表系统在过去的1分钟，5分钟，15分钟内的系统平均负载。他代表的是<strong>当前系统正在运行的和处于等待运行的进程数之和</strong>。也指的是处于<strong>可运行状态</strong>和<strong>不可中断状态</strong>的平均进程数。</p><p>如果单核CPU的话，负载达到1就代表CPU已经达到满负荷的状态了，超过1，后面的进行就需要排队等待处理了。</p><p>如果是是多核多CPU的话，假设现在服务器是2个CPU，每个CPU2个核，那么总负载不超过4都没什么问题。</p><p>怎么查看CPU有多少核呢？</p><p>通过命令<code>cat /proc/cpuinfo | grep &quot;model name&quot;</code>查看CPU的情况。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaFN1UGhHR0JNYWg5Rlc5WjZiSTFsenNId0RDSmlhZXBWSWljaWMzSnNENkdYbDI4WkJjSlhSMjJBZy82NDA?x-oss-process=image/format,png"></p><p>通过<code>cat /proc/cpuinfo | grep &quot;cpu cores&quot;</code>查看CPU的核数</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaE9lbUFGWlNJaWFhc2UwYkdUdDRNdDhBWFQ0aEplYzltMjZlUWJ2eHJNNlcxbEkwUWdQQWdsd0EvNjQw?x-oss-process=image/format,png"></p><p><strong>CPU 利用率</strong>：和负载不同，CPU利用率指的是当前<strong>正在运行</strong>的进程实时占用CPU的百分比，它是对一段时间内CPU使用状况的统计。</p><p>我举个栗子????：</p><p>假设你们公司厕所有1个坑位，有一个人占了坑位，这时候负载就是1，如果还有一个人在排队，那么负载就是2。</p><p>如果在1个小时内，A上厕所花了10分钟，B上厕所花了20分钟，剩下30分钟厕所都没人使用，那么这一个小时内利用率就是50%。</p><h4 id="2-那如果CPU负载很高，利用率却很低该怎么办？"><a href="#2-那如果CPU负载很高，利用率却很低该怎么办？" class="headerlink" title="2.那如果CPU负载很高，利用率却很低该怎么办？"></a>2.那如果CPU负载很高，利用率却很低该怎么办？</h4><p>CPU负载很高，利用率却很低，说明处于等待状态的任务很多，负载越高，代表可能很多僵死的进程。通常这种情况是IO密集型的任务，大量请求在请求相同的IO，导致任务队列堆积。</p><p>同样，可以先通过<code>top</code>命令观察(截图只是示意，不代表真实情况)，假设发现现在确实是高负载低使用率。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaFp0cVdLVlM4aWFkMnJZbzFZajNCWjFwa3NXcGtnZHBpY1ltczI0cURuQkxYRnpKZU9QRlJKaWNpYWcvNjQw?x-oss-process=image/format,png"></p><p>然后，再通过命令<code>ps -axjf</code>查看是否存在状态为<code>D+</code>状态的进程，这个状态指的就是不可中断的睡眠状态的进程。处于这个状态的进程无法终止，也无法自行退出，只能通过恢复其依赖的资源或者重启系统来解决。(对不起，我截不到D+的状态)</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaElNNVA5R1NlRnFRM2NJZ0RpYU5OUE1wYk1VNXdKWFpCdzRmaWFhVDdDR1NwREsxbnR4OU9VWGZnLzY0MA?x-oss-process=image/format,png"></p><h4 id="3-那如果负载很低，利用率却很高呢？"><a href="#3-那如果负载很低，利用率却很高呢？" class="headerlink" title="3.那如果负载很低，利用率却很高呢？"></a>3.那如果负载很低，利用率却很高呢？</h4><p>如果你的公司只有一个厕所，外面没人排队，却有一个人在里面上了大半个小时，这说明什么？</p><p>两种可能：他没带纸，或者一些奇怪的事情发生了？</p><p>这表示CPU的任务并不多，但是任务执行的时间很长，大概率就是你写的代码本身有问题，通常是计算密集型任务，生成了大量耗时短的计算任务。</p><p>怎么排查？直接<code>top</code>命令找到使用率最高的任务，定位到去看看就行了。如果代码没有问题，那么过段时间CPU使用率就会下降的。</p><h4 id="4-那如果CPU使用率达到100-呢？怎么排查？"><a href="#4-那如果CPU使用率达到100-呢？怎么排查？" class="headerlink" title="4.那如果CPU使用率达到100%呢？怎么排查？"></a>4.那如果CPU使用率达到100%呢？怎么排查？</h4><ol><li>通过<code>top</code>找到占用率高的进程。</li></ol><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaHVSc2liVlh4VzlTUmZ5cXBRM0JpYndCUVB0Z3NDQmZEQWFlWGRZY1ZlUVRVanVZWUlvY2RxTWVBLzY0MA?x-oss-process=image/format,png"></p><ol><li>通过<code>top -Hp pid</code>找到占用CPU高的线程ID。这里找到958的线程ID</li></ol><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaFJzOVpLWDFVQXV1QUJWSGVxV2lhTUpzRE9VakdJalV5SG5KQWJMRWljV2dENGlhV1FZYWlia2xiYWcvNjQw?x-oss-process=image/format,png"></p><ol><li>再把线程ID转化为16进制，<code>printf &quot;0x%x\n&quot; 958</code>，得到线程ID<code>0x3be</code></li></ol><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaEtPQ2szcHNqTkg0bE9NeEp3S21QNTAzM0I4aWNwc2h6a1F2ZHpEb3R0YVZoMjhrY1o2ekpseHcvNjQw?x-oss-process=image/format,png"></p><ol><li>通过命令<code>jstack 163 | grep &#39;0x3be&#39; -C5 --color</code> 或者 <code>jstack 163|vim +/0x3be -</code> 找到有问题的代码</li></ol><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaGdQSzlybVo1bnBMQXRnbUlpYTRUTGpGZEdWclNYQUFaZU1uM201UkU4dEtNTG45V0JuVTlDWncvNjQw?x-oss-process=image/format,png"></p><h4 id="5-说说常见的Linux命令吧？"><a href="#5-说说常见的Linux命令吧？" class="headerlink" title="5.说说常见的Linux命令吧？"></a>5.说说常见的Linux命令吧？</h4><p><strong>常用的文件、目录命令</strong></p><p><code>ls</code>：用户查看目录下的文件，<code>ls -a</code>可以用来查看隐藏文件，<code>ls -l</code>可以用于查看文件的详细信息，包括权限、大小、所有者等信息。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaGliWFhvY0NTQnFpYzc3c2RjU1hCNG9TZGprMEs1VjV6aDVOajFZbkJsajk4OHlOVjI2aGFzb0xBLzY0MA?x-oss-process=image/format,png"></p><p><code>touch</code>：用于创建文件。如果文件不存在，则创建一个新的文件，如果文件已存在，则会修改文件的时间戳。</p><p><code>cat</code>：cat是英文<code>concatenate</code>的缩写，用于查看文件内容。使用<code>cat</code>查看文件的话，不管文件的内容有多少，都会一次性显示，所以他不适合查看太大的文件。</p><p><code>more</code>：more和cat有点区别，more用于分屏显示文件内容。可以用<code>空格键</code>向下翻页，<code>b</code>键向上翻页</p><p><code>less</code>：和more类似，less用于分行显示</p><p><code>tail</code>：可能是平时用的最多的命令了，查看日志文件基本靠他了。一般用户<code>tail -fn 100 xx.log</code>查看最后的100行内容</p><p><strong>常用的权限命令</strong></p><p><code>chmod</code>：修改权限命令。一般用<code>+</code>号添加权限，<code>-</code>号删除权限，<code>x</code>代表执行权限，<code>r</code>代表读取权限，<code>w</code>代表写入权限，常见写法比如<code>chmod +x 文件名</code> 添加执行权限。</p><p>还有另外一种写法，使用数字来授权，因为<code>r</code>=4，<code>w</code>=2，<code>x</code>=1，平时执行命令<code>chmod 777 文件名</code>这就是最高权限了。</p><p>第一个数字7&#x3D;4+2+1代表着所有者的权限，第二个数字7代表所属组的权限，第三个数字代表其他人的权限。</p><p>常见的权限数字还有644，所有者有读写权限，其他人只有只读权限，755代表其他人有只读和执行权限。</p><p><code>chown</code>：用于修改文件和目录的所有者和所属组。一般用法<code>chown user 文件</code>用于修改文件所有者，<code>chown user:user 文件</code>修改文件所有者和组，冒号前面是所有者，后面是组。</p><p><strong>常用的压缩命令</strong></p><p><code>zip</code>：压缩zip文件命令，比如<code>zip test.zip 文件</code>可以把文件压缩成zip文件，如果压缩目录的话则需添加<code>-r</code>选项。</p><p><code>unzip</code>：与zip对应，解压zip文件命令。<code>unzip xxx.zip</code>直接解压，还可以通过<code>-d</code>选项指定解压目录。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9pYkJNVnVEZmtaVW12UEZ2UTN5VkwxdFFZR2liSGljWUNsaHNLekpmZ0VqUHNXMXpxbm50eGQ1NUpyRDZDaWFpYXRmQjZjdXdaSE5BZFp2aWN0NGdoUFJEMnZMQS82NDA?x-oss-process=image/format,png"></p><p><code>gzip</code>：用于压缩.gz后缀文件，gzip命令不能打包目录。需要注意的是直接使用<code>gzip 文件名</code>源文件会消失，如果要保留源文件，可以使用<code>gzip -c 文件名 &gt; xx.gz</code>，解压缩直接使用<code>gzip -d xx.gz</code></p><p><code>tar</code>：tar常用几个选项，<code>-x</code>解打包，<code>-c</code>打包，<code>-f</code>指定压缩包文件名，<code>-v</code>显示打包文件过程，一般常用<code>tar -cvf xx.tar 文件</code>来打包，解压则使用<code>tar -xvf xx.tar</code>。</p><p>Linux的打包和压缩是分开的操作，如果要打包并且压缩的话，按照前面的做法必须先用tar打包，然后再用gzip压缩。当然，还有更好的做法就是<code>-z</code>命令，打包并且压缩。</p><p>使用命令<code>tar -zcvf xx.tar.gz 文件</code>来打包压缩，使用命令<code>tar -zxvf xx.tar.gz</code>来解压缩</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;1-CPU负载和CPU利用率的区别是什么？&quot;&gt;&lt;a href=&quot;#1-CPU负载和CPU利用率的区别是什么？&quot; class=&quot;headerlink&quot; title=&quot;1.CPU负载和CPU利用率的区别是什么？&quot;&gt;&lt;/a&gt;1.CPU负载和CPU利用率的区别是什么？&lt;/</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot集成kafka全面实战</title>
    <link href="http://example.com/2021/01/05/SpringBoot%E9%9B%86%E6%88%90kafka%E5%85%A8%E9%9D%A2%E5%AE%9E%E6%88%98/"/>
    <id>http://example.com/2021/01/05/SpringBoot%E9%9B%86%E6%88%90kafka%E5%85%A8%E9%9D%A2%E5%AE%9E%E6%88%98/</id>
    <published>2021-01-05T09:18:05.000Z</published>
    <updated>2024-01-07T10:21:24.969Z</updated>
    
    <content type="html"><![CDATA[<p>一、生产者实践</p><ul><li><p>普通生产者</p></li><li><p>带回调的生产者</p></li><li><p>自定义分区器</p></li><li><p>kafka事务提交</p></li></ul><p>二、消费者实践</p><ul><li><p>简单消费</p></li><li><p>指定topic、partition、offset消费</p></li><li><p>批量消费</p></li><li><p>监听异常处理器</p></li><li><p>消息过滤器</p></li><li><p>消息转发</p></li><li><p>定时启动&#x2F;停止监听器</p></li></ul><h3 id="一、前戏"><a href="#一、前戏" class="headerlink" title="一、前戏"></a>一、前戏</h3><p>1、在项目中连接kafka，因为是外网，首先要开放kafka配置文件中的如下配置（其中IP为公网IP），</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs auto">advertised.listeners=PLAINTEXT://112.126.74.249:9092<br></code></pre></td></tr></table></figure><p>2、在开始前我们先创建两个topic：topic1、topic2，其分区和副本数都设置为2，用来测试，</p><ol><li><p><code>[root@iZ2zegzlkedbo3e64vkbefZ ~]# cd /usr/local/kafka-cluster/kafka1/bin/</code></p></li><li><p><code>[root@iZ2zegzlkedbo3e64vkbefZ bin]# ./kafka-topics.sh --create --zookeeper 172.17.80.219:2181 --replication-factor 2 --partitions 2 --topic topic1</code></p></li><li><p><code>Created topic topic1.</code></p></li><li><p><code>[root@iZ2zegzlkedbo3e64vkbefZ bin]# ./kafka-topics.sh --create --zookeeper 172.17.80.219:2181 --replication-factor 2 --partitions 2 --topic topic2</code></p></li><li><p><code>Created topic topic2.</code></p></li></ol><p>当然我们也可以不手动创建topic，在执行代码kafkaTemplate.send(“topic1”, normalMessage)发送消息时，kafka会帮我们自动完成topic的创建工作，但这种情况下创建的topic默认只有一个分区，分区也没有副本。所以，我们可以在项目中新建一个配置类专门用来初始化topic，如下，</p><ol><li><p><code>@Configuration</code></p></li><li><p><code>public class KafkaInitialConfiguration &#123;</code></p></li><li><p><code>// 创建一个名为testtopic的Topic并设置分区数为8，分区副本数为2</code></p></li><li><p><code>@Bean</code></p></li><li><p><code>public NewTopic initialTopic() &#123;</code></p></li><li><p><code>return new NewTopic(&quot;testtopic&quot;,8, (short) 2 );</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 如果要修改分区数，只需修改配置值重启项目即可</code></p></li><li><p><code>// 修改分区数并不会导致数据的丢失，但是分区数只能增大不能减小</code></p></li><li><p><code>@Bean</code></p></li><li><p><code>public NewTopic updateTopic() &#123;</code></p></li><li><p><code>return new NewTopic(&quot;testtopic&quot;,10, (short) 2 );</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>&#125;</code></p></li></ol><p>3、新建SpringBoot项目</p><p>① 引入pom依赖</p><ol><li><p><code>&lt;dependency&gt;</code></p></li><li><p><code>&lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;</code></p></li><li><p><code>&lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;</code></p></li><li><p><code>&lt;/dependency&gt;</code></p></li></ol><p>② application.propertise配置（本文用到的配置项这里全列了出来）</p><ol><li><p><code>###########【Kafka集群】###########</code></p></li><li><p><code>spring.kafka.bootstrap-servers=112.126.74.249:9092,112.126.74.249:9093</code></p></li><li><p><code>###########【初始化生产者配置】###########</code></p></li><li><p><code># 重试次数</code></p></li><li><p><code>spring.kafka.producer.retries=0</code></p></li><li><p><code># 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)</code></p></li><li><p><code>spring.kafka.producer.acks=1</code></p></li><li><p><code># 批量大小</code></p></li><li><p><code>spring.kafka.producer.batch-size=16384</code></p></li><li><p><code># 提交延时</code></p></li><li><p><code>spring.kafka.producer.properties.linger.ms=0</code></p></li><li><p><code># 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka</code></p></li><li><p><code># linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了</code></p></li><li><p><code>​</code></p></li><li><p><code># 生产端缓冲区大小</code></p></li><li><p><code>spring.kafka.producer.buffer-memory = 33554432</code></p></li><li><p><code># Kafka提供的序列化和反序列化类</code></p></li><li><p><code>spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer</code></p></li><li><p><code>spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer</code></p></li><li><p><code># 自定义分区器</code></p></li><li><p><code># spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner</code></p></li><li><p><code>​</code></p></li><li><p><code>###########【初始化消费者配置】###########</code></p></li><li><p><code># 默认的消费组ID</code></p></li><li><p><code>spring.kafka.consumer.properties.group.id=defaultConsumerGroup</code></p></li><li><p><code># 是否自动提交offset</code></p></li><li><p><code>spring.kafka.consumer.enable-auto-commit=true</code></p></li><li><p><code># 提交offset延时(接收到消息后多久提交offset)</code></p></li><li><p><code>spring.kafka.consumer.auto.commit.interval.ms=1000</code></p></li><li><p><code># 当kafka中没有初始offset或offset超出范围时将自动重置offset</code></p></li><li><p><code># earliest:重置为分区中最小的offset;</code></p></li><li><p><code># latest:重置为分区中最新的offset(消费分区中新产生的数据);</code></p></li><li><p><code># none:只要有一个分区不存在已提交的offset,就抛出异常;</code></p></li><li><p><code>spring.kafka.consumer.auto-offset-reset=latest</code></p></li><li><p><code># 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)</code></p></li><li><p><code>spring.kafka.consumer.properties.session.timeout.ms=120000</code></p></li><li><p><code># 消费请求超时时间</code></p></li><li><p><code>spring.kafka.consumer.properties.request.timeout.ms=180000</code></p></li><li><p><code># Kafka提供的序列化和反序列化类</code></p></li><li><p><code>spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer</code></p></li><li><p><code>spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer</code></p></li><li><p><code># 消费端监听的topic不存在时，项目启动会报错(关掉)</code></p></li><li><p><code>spring.kafka.listener.missing-topics-fatal=false</code></p></li><li><p><code># 设置批量消费</code></p></li><li><p><code># spring.kafka.listener.type=batch</code></p></li><li><p><code># 批量消费每次最多消费多少条消息</code></p></li><li><p><code># spring.kafka.consumer.max-poll-records=50</code></p></li></ol><h3 id="二、Hello-Kafka"><a href="#二、Hello-Kafka" class="headerlink" title="二、Hello Kafka"></a>二、Hello Kafka</h3><p>1、简单生产者</p><ol><li><p><code>@RestController</code></p></li><li><p><code>public class KafkaProducer &#123;</code></p></li><li><p><code>@Autowired</code></p></li><li><p><code>private KafkaTemplate&lt;String, Object&gt; kafkaTemplate;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 发送消息</code></p></li><li><p><code>@GetMapping(&quot;/kafka/normal/&#123;message&#125;&quot;)</code></p></li><li><p><code>public void sendMessage1(@PathVariable(&quot;message&quot;) String normalMessage) &#123;</code></p></li><li><p><code>kafkaTemplate.send(&quot;topic1&quot;, normalMessage);</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>&#125;</code></p></li></ol><p> 2、简单消费</p><ol><li><p><code>@Component</code></p></li><li><p><code>public class KafkaConsumer &#123;</code></p></li><li><p><code>// 消费监听</code></p></li><li><p><code>@KafkaListener(topics = &#123;&quot;topic1&quot;&#125;)</code></p></li><li><p><code>public void onMessage1(ConsumerRecord&lt;?, ?&gt; record)&#123;</code></p></li><li><p><code>// 消费的哪个topic、partition的消息,打印出消息内容</code></p></li><li><p><code>System.out.println(&quot;简单消费：&quot;+record.topic()+&quot;-&quot;+record.partition()+&quot;-&quot;+record.value());</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>&#125;</code></p></li></ol><p>上面示例创建了一个生产者，发送消息到topic1，消费者监听topic1消费消息。监听器用@KafkaListener注解，topics表示监听的topic，支持同时监听多个，用英文逗号分隔。启动项目，postman调接口触发生产者发送消息，</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy80aWNWdnd0d1ZleUZDTkpkdGhuVFZuYnJwOUxJMXd1djNhdVV6azR4U0JPdTZneGljMk1oSzV0bWdSNHd3NWQzUG9EeERCS2tUUGNDQjdwTTJYbzBTdzZRLzY0MA?x-oss-process=image/format,png"></p><p>可以看到监听器消费成功，</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy80aWNWdnd0d1ZleUZDTkpkdGhuVFZuYnJwOUxJMXd1djNwc09pYzY3aWNYV2lid0k0a0ptV2VpYURpY01OVTB6QUxyR3dGVWd2aWI2c09pYjRtOU5zRllTeEMxcmdBLzY0MA?x-oss-process=image/format,png"></p><h3 id="三、生产者"><a href="#三、生产者" class="headerlink" title="三、生产者"></a>三、生产者</h3><p>1、带回调的生产者</p><p>kafkaTemplate提供了一个回调方法addCallback，我们可以在回调方法中监控消息是否发送成功 或 失败时做补偿处理，有两种写法，</p><ol><li><p><code>@GetMapping(&quot;/kafka/callbackOne/&#123;message&#125;&quot;)</code></p></li><li><p><code>public void sendMessage2(@PathVariable(&quot;message&quot;) String callbackMessage) &#123;</code></p></li><li><p><code>kafkaTemplate.send(&quot;topic1&quot;, callbackMessage).addCallback(success -&gt; &#123;</code></p></li><li><p><code>// 消息发送到的topic</code></p></li><li><p><code>String topic = success.getRecordMetadata().topic();</code></p></li><li><p><code>// 消息发送到的分区</code></p></li><li><p><code>int partition = success.getRecordMetadata().partition();</code></p></li><li><p><code>// 消息在分区内的offset</code></p></li><li><p><code>long offset = success.getRecordMetadata().offset();</code></p></li><li><p><code>System.out.println(&quot;发送消息成功:&quot; + topic + &quot;-&quot; + partition + &quot;-&quot; + offset);</code></p></li><li><p><code>&#125;, failure -&gt; &#123;</code></p></li><li><p><code>System.out.println(&quot;发送消息失败:&quot; + failure.getMessage());</code></p></li><li><p><code>&#125;);</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>@GetMapping(&quot;/kafka/callbackTwo/&#123;message&#125;&quot;)</code></p></li><li><p><code>public void sendMessage3(@PathVariable(&quot;message&quot;) String callbackMessage) &#123;</code></p></li><li><p><code>kafkaTemplate.send(&quot;topic1&quot;, callbackMessage).addCallback(new ListenableFutureCallback&lt;SendResult&lt;String, Object&gt;&gt;() &#123;</code></p></li><li><p><code>@Override</code></p></li><li><p><code>public void onFailure(Throwable ex) &#123;</code></p></li><li><p><code>System.out.println(&quot;发送消息失败：&quot;+ex.getMessage());</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>@Override</code></p></li><li><p><code>public void onSuccess(SendResult&lt;String, Object&gt; result) &#123;</code></p></li><li><p><code>System.out.println(&quot;发送消息成功：&quot; + result.getRecordMetadata().topic() + &quot;-&quot;</code></p></li><li><p><code>+ result.getRecordMetadata().partition() + &quot;-&quot; + result.getRecordMetadata().offset());</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>&#125;);</code></p></li><li><p><code>&#125;</code></p></li></ol><p>2、自定义分区器</p><p>我们知道，kafka中每个topic被划分为多个分区，那么生产者将消息发送到topic时，具体追加到哪个分区呢？这就是所谓的分区策略，Kafka 为我们提供了默认的分区策略，同时它也支持自定义分区策略。其路由机制为：</p><p>① 若发送消息时指定了分区（即自定义分区策略），则直接将消息append到指定分区；</p><p>② 若发送消息时未指定 patition，但指定了 key（kafka允许为每条消息设置一个key），则对key值进行hash计算，根据计算结果路由到指定分区，这种情况下可以保证同一个 Key 的所有消息都进入到相同的分区；</p><p>③  patition 和 key 都未指定，则使用kafka默认的分区策略，轮询选出一个 patition；</p><p>※ 我们来自定义一个分区策略，将消息发送到我们指定的partition，首先新建一个分区器类实现Partitioner接口，重写方法，其中partition方法的返回值就表示将消息发送到几号分区，</p><ol><li><p><code>public class CustomizePartitioner implements Partitioner &#123;</code></p></li><li><p><code>@Override</code></p></li><li><p><code>public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123;</code></p></li><li><p><code>// 自定义分区规则(这里假设全部发到0号分区)</code></p></li><li><p><code>// ......</code></p></li><li><p><code>return 0;</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>@Override</code></p></li><li><p><code>public void close() &#123;</code></p></li><li><p><code>​</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>@Override</code></p></li><li><p><code>public void configure(Map&lt;String, ?&gt; configs) &#123;</code></p></li><li><p><code>​</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>&#125;</code></p></li></ol><p>在application.propertise中配置自定义分区器，配置的值就是分区器类的全路径名，</p><ol><li><p><code># 自定义分区器</code></p></li><li><p><code>spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner</code></p></li></ol><p>3、kafka事务提交</p><p>如果在发送消息时需要创建事务，可以使用 KafkaTemplate 的 executeInTransaction 方法来声明事务，</p><ol><li><p><code>@GetMapping(&quot;/kafka/transaction&quot;)</code></p></li><li><p><code>public void sendMessage7()&#123;</code></p></li><li><p><code>// 声明事务：后面报错消息不会发出去</code></p></li><li><p><code>kafkaTemplate.executeInTransaction(operations -&gt; &#123;</code></p></li><li><p><code>operations.send(&quot;topic1&quot;,&quot;test executeInTransaction&quot;);</code></p></li><li><p><code>throw new RuntimeException(&quot;fail&quot;);</code></p></li><li><p><code>&#125;);</code></p></li><li><p><code>​</code></p></li><li><p><code>// 不声明事务：后面报错但前面消息已经发送成功了</code></p></li><li><p><code>kafkaTemplate.send(&quot;topic1&quot;,&quot;test executeInTransaction&quot;);</code></p></li><li><p><code>throw new RuntimeException(&quot;fail&quot;);</code></p></li><li><p><code>&#125;</code></p></li></ol><h3 id="四、消费者"><a href="#四、消费者" class="headerlink" title="四、消费者"></a>四、消费者</h3><p>1、指定topic、partition、offset消费</p><p>前面我们在监听消费topic1的时候，监听的是topic1上所有的消息，如果我们想指定topic、指定partition、指定offset来消费呢？也很简单，@KafkaListener注解已全部为我们提供，</p><ol><li><p><code>/**</code></p></li><li><p><code>* @Title 指定topic、partition、offset消费</code></p></li><li><p><code>* @Description 同时监听topic1和topic2，监听topic1的0号分区、topic2的 &quot;0号和1号&quot; 分区，指向1号分区的offset初始值为8</code></p></li><li><p><code>* @Author long.yuan</code></p></li><li><p><code>* @Date 2020/3/22 13:38</code></p></li><li><p><code>* @Param [record]</code></p></li><li><p><code>* @return void</code></p></li><li><p><code>**/</code></p></li><li><p><code>@KafkaListener(id = &quot;consumer1&quot;,groupId = &quot;felix-group&quot;,topicPartitions = &#123;</code></p></li><li><p><code>@TopicPartition(topic = &quot;topic1&quot;, partitions = &#123; &quot;0&quot; &#125;),</code></p></li><li><p><code>@TopicPartition(topic = &quot;topic2&quot;, partitions = &quot;0&quot;, partitionOffsets = @PartitionOffset(partition = &quot;1&quot;, initialOffset = &quot;8&quot;))</code></p></li><li><p><code>&#125;)</code></p></li><li><p><code>public void onMessage2(ConsumerRecord&lt;?, ?&gt; record) &#123;</code></p></li><li><p><code>System.out.println(&quot;topic:&quot;+record.topic()+&quot;|partition:&quot;+record.partition()+&quot;|offset:&quot;+record.offset()+&quot;|value:&quot;+record.value());</code></p></li><li><p><code>&#125;</code></p></li></ol><p>属性解释：</p><p>① id：消费者ID；</p><p>② groupId：消费组ID；</p><p>③ topics：监听的topic，可监听多个；</p><p>④ topicPartitions：可配置更加详细的监听信息，可指定topic、parition、offset监听。</p><p>上面onMessage2监听的含义：监听topic1的0号分区，同时监听topic2的0号分区和topic2的1号分区里面offset从8开始的消息。</p><p>注意：topics和topicPartitions不能同时使用；</p><p>2、批量消费</p><p>设置application.prpertise开启批量消费即可，</p><ol><li><p><code># 设置批量消费</code></p></li><li><p><code>spring.kafka.listener.type=batch</code></p></li><li><p><code># 批量消费每次最多消费多少条消息</code></p></li><li><p><code>spring.kafka.consumer.max-poll-records=50</code></p></li></ol><p>接收消息时用List来接收，监听代码如下，</p><ol><li><p><code>@KafkaListener(id = &quot;consumer2&quot;,groupId = &quot;felix-group&quot;, topics = &quot;topic1&quot;)</code></p></li><li><p><code>public void onMessage3(List&lt;ConsumerRecord&lt;?, ?&gt;&gt; records) &#123;</code></p></li><li><p><code>System.out.println(&quot;&gt;&gt;&gt;批量消费一次，records.size()=&quot;+records.size());</code></p></li><li><p><code>for (ConsumerRecord&lt;?, ?&gt; record : records) &#123;</code></p></li><li><p><code>System.out.println(record.value());</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>&#125;</code></p></li></ol><p>3、ConsumerAwareListenerErrorHandler 异常处理器</p><p>通过异常处理器，我们可以处理consumer在消费时发生的异常。</p><p>新建一个 ConsumerAwareListenerErrorHandler 类型的异常处理方法，用@Bean注入，BeanName默认就是方法名，然后我们将这个异常处理器的BeanName放到@KafkaListener注解的errorHandler属性里面，当监听抛出异常的时候，则会自动调用异常处理器，</p><ol><li><p><code>// 新建一个异常处理器，用@Bean注入</code></p></li><li><p><code>@Bean</code></p></li><li><p><code>public ConsumerAwareListenerErrorHandler consumerAwareErrorHandler() &#123;</code></p></li><li><p><code>return (message, exception, consumer) -&gt; &#123;</code></p></li><li><p><code>System.out.println(&quot;消费异常：&quot;+message.getPayload());</code></p></li><li><p><code>return null;</code></p></li><li><p><code>&#125;;</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 将这个异常处理器的BeanName放到@KafkaListener注解的errorHandler属性里面</code></p></li><li><p><code>@KafkaListener(topics = &#123;&quot;topic1&quot;&#125;,errorHandler = &quot;consumerAwareErrorHandler&quot;)</code></p></li><li><p><code>public void onMessage4(ConsumerRecord&lt;?, ?&gt; record) throws Exception &#123;</code></p></li><li><p><code>throw new Exception(&quot;简单消费-模拟异常&quot;);</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 批量消费也一样，异常处理器的message.getPayload()也可以拿到各条消息的信息</code></p></li><li><p><code>@KafkaListener(topics = &quot;topic1&quot;,errorHandler=&quot;consumerAwareErrorHandler&quot;)</code></p></li><li><p><code>public void onMessage5(List&lt;ConsumerRecord&lt;?, ?&gt;&gt; records) throws Exception &#123;</code></p></li><li><p><code>System.out.println(&quot;批量消费一次...&quot;);</code></p></li><li><p><code>throw new Exception(&quot;批量消费-模拟异常&quot;);</code></p></li><li><p><code>&#125;</code></p></li></ol><p>执行看一下效果，</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy80aWNWdnd0d1ZleUZDTkpkdGhuVFZuYnJwOUxJMXd1djNzaWJWNFpVUzNZQjJEQkVSc01PM1pZaG9RNjlCQmlidU1scTNpY1QwYm40bm9wNGliWWlhODNXZE9wQS82NDA?x-oss-process=image/format,png"></p><p>4、消息过滤器</p><p>消息过滤器可以在消息抵达consumer之前被拦截，在实际应用中，我们可以根据自己的业务逻辑，筛选出需要的信息再交由KafkaListener处理，不需要的消息则过滤掉。</p><p>配置消息过滤只需要为 监听器工厂 配置一个RecordFilterStrategy（消息过滤策略），返回true的时候消息将会被抛弃，返回false时，消息能正常抵达监听容器。</p><ol><li><p><code>@Component</code></p></li><li><p><code>public class KafkaConsumer &#123;</code></p></li><li><p><code>@Autowired</code></p></li><li><p><code>ConsumerFactory consumerFactory;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 消息过滤器</code></p></li><li><p><code>@Bean</code></p></li><li><p><code>public ConcurrentKafkaListenerContainerFactory filterContainerFactory() &#123;</code></p></li><li><p><code>ConcurrentKafkaListenerContainerFactory factory = new ConcurrentKafkaListenerContainerFactory();</code></p></li><li><p><code>factory.setConsumerFactory(consumerFactory);</code></p></li><li><p><code>// 被过滤的消息将被丢弃</code></p></li><li><p><code>factory.setAckDiscarded(true);</code></p></li><li><p><code>// 消息过滤策略</code></p></li><li><p><code>factory.setRecordFilterStrategy(consumerRecord -&gt; &#123;</code></p></li><li><p><code>if (Integer.parseInt(consumerRecord.value().toString()) % 2 == 0) &#123;</code></p></li><li><p><code>return false;</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>//返回true消息则被过滤</code></p></li><li><p><code>return true;</code></p></li><li><p><code>&#125;);</code></p></li><li><p><code>return factory;</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 消息过滤监听</code></p></li><li><p><code>@KafkaListener(topics = &#123;&quot;topic1&quot;&#125;,containerFactory = &quot;filterContainerFactory&quot;)</code></p></li><li><p><code>public void onMessage6(ConsumerRecord&lt;?, ?&gt; record) &#123;</code></p></li><li><p><code>System.out.println(record.value());</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>&#125;</code></p></li></ol><p>上面实现了一个”过滤奇数、接收偶数”的过滤策略，我们向topic1发送0-99总共100条消息，看一下监听器的消费情况，可以看到监听器只消费了偶数，</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy80aWNWdnd0d1ZleUZDTkpkdGhuVFZuYnJwOUxJMXd1djNBV1hkQ1ppYTkzR1VmZjBpYnBUcmJpY0o2cHZhbEFXMUJTdmtkR2FhR0lNWmljaWFpYTdPbXJhZFZxOXcvNjQw?x-oss-process=image/format,png"></p><p>5、消息转发</p><p>在实际开发中，我们可能有这样的需求，应用A从TopicA获取到消息，经过处理后转发到TopicB，再由应用B监听处理消息，即一个应用处理完成后将该消息转发至其他应用，完成消息的转发。</p><p>在SpringBoot集成Kafka实现消息的转发也很简单，只需要通过一个@SendTo注解，被注解方法的return值即转发的消息内容，如下，</p><ol><li><p><code>/**</code></p></li><li><p><code>* @Title 消息转发</code></p></li><li><p><code>* @Description 从topic1接收到的消息经过处理后转发到topic2</code></p></li><li><p><code>* @Author long.yuan</code></p></li><li><p><code>* @Date 2020/3/23 22:15</code></p></li><li><p><code>* @Param [record]</code></p></li><li><p><code>* @return void</code></p></li><li><p><code>**/</code></p></li><li><p><code>@KafkaListener(topics = &#123;&quot;topic1&quot;&#125;)</code></p></li><li><p><code>@SendTo(&quot;topic2&quot;)</code></p></li><li><p><code>public String onMessage7(ConsumerRecord&lt;?, ?&gt; record) &#123;</code></p></li><li><p><code>return record.value()+&quot;-forward message&quot;;</code></p></li><li><p><code>&#125;</code></p></li></ol><p>6、定时启动、停止监听器</p><p>默认情况下，当消费者项目启动的时候，监听器就开始工作，监听消费发送到指定topic的消息，那如果我们不想让监听器立即工作，想让它在我们指定的时间点开始工作，或者在我们指定的时间点停止工作，该怎么处理呢——使用KafkaListenerEndpointRegistry，下面我们就来实现：</p><p>① 禁止监听器自启动；</p><p>② 创建两个定时任务，一个用来在指定时间点启动定时器，另一个在指定时间点停止定时器；</p><p>新建一个定时任务类，用注解@EnableScheduling声明，KafkaListenerEndpointRegistry 在SpringIO中已经被注册为Bean，直接注入，设置禁止KafkaListener自启动，</p><ol><li><p><code>@EnableScheduling</code></p></li><li><p><code>@Component</code></p></li><li><p><code>public class CronTimer &#123;</code></p></li><li><p><code>​</code></p></li><li><p><code>/**</code></p></li><li><p><code>* @KafkaListener注解所标注的方法并不会在IOC容器中被注册为Bean，</code></p></li><li><p><code>* 而是会被注册在KafkaListenerEndpointRegistry中，</code></p></li><li><p><code>* 而KafkaListenerEndpointRegistry在SpringIOC中已经被注册为Bean</code></p></li><li><p><code>**/</code></p></li><li><p><code>@Autowired</code></p></li><li><p><code>private KafkaListenerEndpointRegistry registry;</code></p></li><li><p><code>​</code></p></li><li><p><code>@Autowired</code></p></li><li><p><code>private ConsumerFactory consumerFactory;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 监听器容器工厂(设置禁止KafkaListener自启动)</code></p></li><li><p><code>@Bean</code></p></li><li><p><code>public ConcurrentKafkaListenerContainerFactory delayContainerFactory() &#123;</code></p></li><li><p><code>ConcurrentKafkaListenerContainerFactory container = new ConcurrentKafkaListenerContainerFactory();</code></p></li><li><p><code>container.setConsumerFactory(consumerFactory);</code></p></li><li><p><code>//禁止KafkaListener自启动</code></p></li><li><p><code>container.setAutoStartup(false);</code></p></li><li><p><code>return container;</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 监听器</code></p></li><li><p><code>@KafkaListener(id=&quot;timingConsumer&quot;,topics = &quot;topic1&quot;,containerFactory = &quot;delayContainerFactory&quot;)</code></p></li><li><p><code>public void onMessage1(ConsumerRecord&lt;?, ?&gt; record)&#123;</code></p></li><li><p><code>System.out.println(&quot;消费成功：&quot;+record.topic()+&quot;-&quot;+record.partition()+&quot;-&quot;+record.value());</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 定时启动监听器</code></p></li><li><p><code>@Scheduled(cron = &quot;0 42 11 * * ? &quot;)</code></p></li><li><p><code>public void startListener() &#123;</code></p></li><li><p><code>System.out.println(&quot;启动监听器...&quot;);</code></p></li><li><p><code>// &quot;timingConsumer&quot;是@KafkaListener注解后面设置的监听器ID,标识这个监听器</code></p></li><li><p><code>if (!registry.getListenerContainer(&quot;timingConsumer&quot;).isRunning()) &#123;</code></p></li><li><p><code>registry.getListenerContainer(&quot;timingConsumer&quot;).start();</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>//registry.getListenerContainer(&quot;timingConsumer&quot;).resume();</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>​</code></p></li><li><p><code>// 定时停止监听器</code></p></li><li><p><code>@Scheduled(cron = &quot;0 45 11 * * ? &quot;)</code></p></li><li><p><code>public void shutDownListener() &#123;</code></p></li><li><p><code>System.out.println(&quot;关闭监听器...&quot;);</code></p></li><li><p><code>registry.getListenerContainer(&quot;timingConsumer&quot;).pause();</code></p></li><li><p><code>&#125;</code></p></li><li><p><code>&#125;</code></p></li></ol><p>启动项目，触发生产者向topic1发送消息，可以看到consumer没有消费，因为这时监听器还没有开始工作，</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy80aWNWdnd0d1ZleUZDTkpkdGhuVFZuYnJwOUxJMXd1djMySE1QbzdtOFlRQzZsVTVwT21mWmNTREtobTR0cUtMVzQzVXNUOTQ2aWM1NXhUQ2VNdlVXbmpnLzY0MA?x-oss-process=image/format,png"></p><p>11:42分监听器启动开始工作，消费消息，</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy80aWNWdnd0d1ZleUZDTkpkdGhuVFZuYnJwOUxJMXd1djN1Njg0cXJabkl2aWFWUmZIOU0waWJkUEdLaHJCdW5kV2ljaWJpYW5rbVd1U2lhUzIwWEg3aWJXMWdPSmdRLzY0MA?x-oss-process=image/format,png"></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy80aWNWdnd0d1ZleUZDTkpkdGhuVFZuYnJwOUxJMXd1djN2dnhZc1lhN2lic2xnbGtaSmE1WWdaMFE1eU8yZ0c5TVhKQlJiSXB5ZUNQeUd2S0tyZXR5NFZBLzY0MA?x-oss-process=image/format,png"></p><p>11：45分监听器停止工作，</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy80aWNWdnd0d1ZleUZDTkpkdGhuVFZuYnJwOUxJMXd1djN6QXY5UGRkaWJ6bmczQ3U1QTNDOTVva1dpY2RaZ21tUU0waWFYVGxxeTJaM0Zjd0dsUFk3UGFTWVEvNjQw?x-oss-process=image/format,png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;一、生产者实践&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;普通生产者&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;带回调的生产者&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自定义分区器&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;kafka事务提交&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;二、消费者实践&lt;/p&gt;
</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>秒懂 kafka HA（高可用）</title>
    <link href="http://example.com/2021/01/05/%E7%A7%92%E6%87%82%20kafka%20HA%EF%BC%88%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%89/"/>
    <id>http://example.com/2021/01/05/%E7%A7%92%E6%87%82%20kafka%20HA%EF%BC%88%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%89/</id>
    <published>2021-01-05T06:23:07.000Z</published>
    <updated>2024-01-07T14:12:33.269Z</updated>
    
    <content type="html"><![CDATA[<h3 id="我们知道，kafka中每个topic被划分为多个partition，每个partition又有多个副本，那么这些分区副本是怎么均匀的分布在整个kafka集群的broker节点上的？partition副本的leader是通过什么算法选举出来的？partition副本的follower是怎么复制备份leader的数据的？本文我们就来说一说和-kafka-高可用相关的一些策略。"><a href="#我们知道，kafka中每个topic被划分为多个partition，每个partition又有多个副本，那么这些分区副本是怎么均匀的分布在整个kafka集群的broker节点上的？partition副本的leader是通过什么算法选举出来的？partition副本的follower是怎么复制备份leader的数据的？本文我们就来说一说和-kafka-高可用相关的一些策略。" class="headerlink" title="我们知道，kafka中每个topic被划分为多个partition，每个partition又有多个副本，那么这些分区副本是怎么均匀的分布在整个kafka集群的broker节点上的？partition副本的leader是通过什么算法选举出来的？partition副本的follower是怎么复制备份leader的数据的？本文我们就来说一说和 kafka 高可用相关的一些策略。"></a>我们知道，kafka中每个topic被划分为多个partition，每个partition又有多个副本，那么这些分区副本是怎么均匀的分布在整个kafka集群的broker节点上的？partition副本的leader是通过什么算法选举出来的？partition副本的follower是怎么复制备份leader的数据的？本文我们就来说一说和 kafka 高可用相关的一些策略。</h3><p>01</p><p>名词解释</p><p>要想说明白kafka的HA机制，我们必须先搞明白几个缩写名词，</p><p><strong>1、AR、ISR、OSR</strong></p><p>AR：Assigned Replicas，某分区的所有副本（这里所说的副本包括leader和follower）统称为 AR。</p><p>ISR：In Sync Replicas，所有与leader副本保持”一定程度同步”的副本（包括leader副本在内）组成 ISR 。生产者发送消息时，只有leader与客户端发生交互，follower只是同步备份leader的数据，以保障高可用，所以生产者的消息会先发送到leader，然后follower才能从leader中拉取消息进行同步，同步期间，follower的数据相对leader而言会有一定程度的滞后，前面所说的”一定程度同步”就是指可忍受的滞后范围，这个范围可以通过server.properties中的参数进行配置。</p><p>OSR ：Out-of-Sync Replied，在上面的描述中，相对leader滞后过多的follower将组成OSR 。</p><p>由此可见，AR &#x3D; ISR + OSR，理想情况下，所有的follower副本都应该与leader 保持一定程度的同步，即AR&#x3D;ISR，OSR集合为空</p><p><strong>2、ISR 的伸缩性</strong></p><p>leader负责跟踪维护 ISR 集合中所有follower副本的滞后状态，当follower副本”落后太多” 或 “follower超过一定时间没有向leader发送同步请求”时，leader副本会把它从 ISR 集合中剔除。如果 OSR 集合中有follower副本”追上”了leader副本，那么leader副本会把它从 OSR 集合转移至 ISR 集合。</p><p>上面描述的”落后太多”是指follower复制的消息落后于leader的条数超过预定值，这个预定值可在server.properties中通过replica.lag.max.messages配置，其默认值是4000。”超过一定时间没有向leader发送同步请求”，这个”一定时间”可以在server.properties中通过replica.lag.time.max.ms来配置，其默认值是10000，默认情况下，当leader发生故障时，只有 ISR 集合中的follower副本才有资格被选举为新的leader，而在 OSR 集合中的副本则没有任何机会（不过这个可以通过配置来改变）。</p><p><strong>3、HW</strong></p><p>HW （High Watermark）俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能消费HW之前的消息。</p><p>下图表示一个日志文件，这个日志文件中有9条消息，第一条消息的offset为0，最后一条消息的offset为8，虚线表示的offset为9的消息，代表下一条待写入的消息。日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/a0b27955baa4da021745a5d8120dba3c.png" alt="Image"></p><p><strong>4、LEO</strong></p><p>LEO （Log End Offset），标识当前日志文件中下一条待写入的消息的offset。上图中offset为9的位置即为当前日志文件的 LEO，分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW（你品，你细品…），对消费者而言只能消费 HW 之前的消息。</p><p><strong>5、 ISR 集合和 HW、LEO的关系</strong></p><p>producer在发布消息到partition时，只会与该partition的leader发生交互将消息发送给leader，leader会将该消息写入其本地log，每个follower都从leader上pull数据做同步备份，follower在pull到该消息并写入其log后，会向leader发送ack，一旦leader收到了ISR中的所有follower的ack（只关注ISR中的所有follower，不考虑OSR，一定程度上提升了吞吐），该消息就被认为已经commit了，leader将增加HW，然后向producer发送ack。</p><p>也就是说，在ISR中所有的follower还没有完成数据备份之前，leader不会增加HW，也就是这条消息暂时还不能被消费者消费，只有当ISR中所有的follower都备份完成后，leader才会将HW后移。</p><p>ISR集合中LEO最小的副本，即同步数据同步的最慢的一个，这个最慢副本的LEO即leader的HW，消费者只能消费HW之前的消息。</p><p>02</p><p>kafka HA</p><p>Tips：我们说的副本包括leader和follower，都叫副本，不要认为叫副本说的就是follower。</p><p>kafka在0.8以前的版本中是没有分区副本的概念的，一旦某一个broker宕机，这个broker上的所有分区都将不可用。在0.8版本以后，引入了分区副本的概念，同一个partition可以有多个副本，在多个副本中会选出一个做leader，其余的作为follower，只有leader对外提供读写服务，follower只负责从leader上同步拉取数据，已保障高可用。</p><p>1、partition副本的分配策略</p><p>每个topic有多个partition，每个partition有多个副本，这些partition副本分布在不同的broker上，以保障高可用，那么这些partition副本是怎么均匀的分布到集群中的每个broker上的呢？</p><p>※ kafka分配partition副本的算法如下，</p><p>① 将所有的broker（假设总共n个broker）和 待分配的partition排序；</p><p>② 将第i个partition分配到第（i mod n）个broker上；</p><p>③ 第i个partition的第j个副本分配到第（(i+j) mod n）个broker上；</p><p>2、kafka的消息传递备份策略</p><p>生产者将消息发送给分区的leader，leader会将该消息写入其本地log，然后每个follower都会从leader pull数据，follower pull到该消息并将其写入log后，会向leader发送ack，当leader收到了ISR集合中所有follower的ack后，就认为这条消息已经commit了，leader将增加HW并且向生产者返回ack。在整个流程中，follower也可以批量的从leader复制数据，以提升复制性能。</p><p>producer在发送消息的时候，可指定参数acks，表示”在生产者认为发送请求完成之前，有多少分区副本必须接收到数据”，有三个可选值，0、1、all(或-1)，默认为1，</p><ul><li><p>acks&#x3D;0，表示producer只管发，只要发出去就认为发发送请求完成了，不管leader有没有收到，更不管follower有没有备份完成。</p></li><li><p>acks&#x3D;1，表示只要leader收到消息，并将其写入自己log后，就会返回给producer ack，不考虑follower有没有备份完成。</p></li><li><p>acks&#x3D;all(或-1)，表示不仅要leader收到消息写入本地log，还要等所有ISR集合中的follower都备份完成后，producer才认为发送成功。</p></li></ul><p><img src="https://img-blog.csdnimg.cn/img_convert/420b84aa4e74c2ec169520070903c101.png" alt="Image">实际上，为了提高性能，follower在pull到消息将其保存到内存中而尚未写入磁盘时，就会向leader发送ack，所以也就不能完全保证异常发生后该条消息一定能被Consumer消费。</p><p>3、kafka中的Leader选举</p><p>面试官在考查你kafka知识的时候如果问你：kafka中的选举是怎么回事？而不说具体哪种选举，那这个面试官可能对kafka也是一知半解，这个时候就是”弄死”他的时候了，当然如果你没有一定的知识储备，那么就是你被”弄死”的时候。</p><p>因为kafka中涉及到选举的地方有多处，最常提及的也有：①cotroller选举 、 ②分区leader选举 和 ③consumer group leader的选举。我们在前面说过同一个partition有多个副本，其中一个副本作为leader，其余的作为follower。这里我们再说一个角色：controller！kafka集群中多个broker，有一个会被选举为controller，注意区分两者，一个是broker的leader，我们称为controller，一个是分区副本的leader，我们称为leader。</p><p>① controller的选举【broker的leader】</p><p>controller的选举是通过broker在zookeeper的”&#x2F;controller”节点下创建临时节点来实现的，并在该节点中写入当前broker的信息 {“version”:1,”brokerid”:1,”timestamp”:”1512018424988”} ，利用zookeeper的强一致性特性，一个节点只能被一个客户端创建成功，创建成功的broker即为controller，即”先到先得”。 </p><p>当controller宕机或者和zookeeper失去连接时，zookeeper检测不到心跳，zookeeper上的临时节点会被删除，而其它broker会监听临时节点的变化，当节点被删除时，其它broker会收到通知，重新发起controller选举。</p><p>② leader的选举【分区副本的leader】</p><p>分区leader的选举由 controller 负责管理和实施，当leader发生故障时，controller会将leader的改变直接通过RPC的方式通知需要为此作出响应的broker，需要为此作出响应的broker即该分区的ISR集合中follower所在的broker，kafka在zookeeper中动态维护了一个ISR，只有ISR里的follower才有被选为Leader的可能。</p><p>具体过程是这样的：按照AR集合中副本的顺序 查找到 第一个 存活的、并且属于ISR集合的 副本作为新的leader。一个分区的AR集合在创建分区副本的时候就被指定，只要不发生重分配的情况，AR集合内部副本的顺序是保持不变的，而分区的ISR集合上面说过因为同步滞后等原因可能会改变，所以注意这里是根据AR的顺序而不是ISR的顺序找。</p><p>※ 对于上面描述的过程我们假设一种极端的情况，如果partition的所有副本都不可用时，怎么办？这种情况下kafka提供了两种可行的方案：</p><p>1、选择 ISR中 第一个活过来的副本作为Leader；</p><p>2、选择第一个活过来的副本（不一定是ISR中的）作为Leader；</p><p>这就需要在可用性和数据一致性当中做出选择，如果一定要等待ISR中的副本活过来，那不可用的时间可能会相对较长。选择第一个活过来的副本作为Leader，如果这个副本不在ISR中，那数据的一致性则难以保证。kafka支持用户通过配置选择，以根据业务场景在可用性和数据一致性之间做出权衡。</p><p>③消费组leader的选举</p><p>组协调器会为消费组（consumer group）内的所有消费者选举出一个leader，这个选举的算法也很简单，第一个加入consumer group的consumer即为leader，如果某一时刻leader消费者退出了消费组，那么会重新 随机 选举一个新的leader。</p><p>03</p><p>kafka架构中zookeeper的结构</p><p>1、查看方式</p><p>我们知道，kafka是基于zookeeper协调管理的，那么zookeeper中究竟存储了哪些信息？另外在后面分析 broker宕机 和 controller宕机 时，我们也需要先了解zookeeper的目录结构，所以我们先学习一下怎么查看zookeeper的目录结构？</p><p>① 首先启动zookeeper客户端连接zk服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs auto"># cd /usr/local/zookeeper-cluster/zk1/bin# ./zkCli.sh<br></code></pre></td></tr></table></figure><p>② 查看zk根节点的子目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs auto">[zk: localhost:2181(CONNECTED) 0] ls /[cluster, controller_epoch, controller, brokers, zookeeper, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]<br></code></pre></td></tr></table></figure><p>③ 可以看到zk根节点下有很多子目录，以brokers为例，查看brokers的层级结构</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs auto">[zk: localhost:2181(CONNECTED) 1] ls /brokers[ids, topics, seqid][zk: localhost:2181(CONNECTED) 2] ls /brokers/ids[0][zk: localhost:2181(CONNECTED) 3] get /brokers/ids/0&#123;&quot;listener_security_protocol_map&quot;:&#123;&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;&#125;,&quot;endpoints&quot;:[&quot;PLAINTEXT://172.17.80.219:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;172.17.80.219&quot;,&quot;timestamp&quot;:&quot;1584267365984&quot;,&quot;port&quot;:9092,&quot;version&quot;:4&#125;cZxid = 0x300000535ctime = Sun Mar 15 18:16:06 CST 2020mZxid = 0x300000535mtime = Sun Mar 15 18:16:06 CST 2020pZxid = 0x300000535cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x20191d7053f0009dataLength = 196numChildren = 0[zk: localhost:2181(CONNECTED) 4] [zk: localhost:2181(CONNECTED) 4][zk: localhost:2181(CONNECTED) 4][zk: localhost:2181(CONNECTED) 4] ls /brokers/topics[__consumer_offsets, first][zk: localhost:2181(CONNECTED) 5] ls /brokers/topics/first[partitions][zk: localhost:2181(CONNECTED) 6] ls /brokers/topics/first/partitions[0, 1][zk: localhost:2181(CONNECTED) 7] ls /brokers/topics/first/partitions/0[state][zk: localhost:2181(CONNECTED) 8] get /brokers/topics/first/partitions/0/state&#123;&quot;controller_epoch&quot;:21,&quot;leader&quot;:0,&quot;version&quot;:1,&quot;leader_epoch&quot;:8,&quot;isr&quot;:[0]&#125;cZxid = 0x3000003e9ctime = Sun Mar 08 16:24:37 CST 2020mZxid = 0x3000005cbmtime = Sun Mar 15 18:54:09 CST 2020pZxid = 0x3000003e9cversion = 0dataVersion = 10aclVersion = 0ephemeralOwner = 0x0dataLength = 73numChildren = 0[zk: localhost:2181(CONNECTED) 9]<br></code></pre></td></tr></table></figure><p>可以看到，brokers下包括[ids, topics, seqid]，ids里面存储了存活的broker的信息，topics里面存储了kafka集群中topic的信息。同样的方法，可以查看其余节点的结构，这里不再演示。</p><p>2、节点信息（这里只列出和HA相关的部分节点）</p><p>① controller</p><p>controller节点下存放的是kafka集群中controller的信息（controller即kafka集群中所有broker的leader）。</p><p>② controller_epoch</p><p>controller_epoch用于记录controller发生变更的次数（controller宕机后会重新选举controller，这时候controller_epoch的值会+1），即记录当前的控制器是第几代控制器，用于防止broker脑裂。</p><p>③ brokes</p><p>brokers下的ids存储了存活的broker信息，topics存储了kafka集群中topic的信息，其中有一个特殊的topic：_consumer_offsets，新版本的kafka将消费者的offset就存储在__consumer_offsets下。</p><p>04</p><p>broker failover</p><p>我们了解了kafka集群中zookpeeper的结构，本文的主题是kafka的高可用分析，所以我们还是结合zookpper的结构，来分析一下，当kafka集群中的一个broker节点宕机时（非controller节点），会发生什么？</p><p>在讲之前，我们再来回顾一下brokers的结构，</p><p><img src="https://img-blog.csdnimg.cn/img_convert/4405f61410cff44764a91cb77ec2f4d1.png" alt="Image"></p><p>※ 当非controller的broker宕机时，会执行如下操作，</p><p>1、controller会在zookeeper的 “ &#x2F;brokers&#x2F;ids&#x2F;“ 节点注册一个watcher（监视器），当有broker宕机时，zookeeper会触发监视器（fire watch）通知controller。</p><p>2、controller 从 “&#x2F;brokers&#x2F;ids” 节点读取到所有可用的broker。</p><p>3、controller会声明一个set_p集合，该集合包含了宕机broker上所有的partition。</p><p>4、针对set_p中的每一个partition，</p><p>① 从 “&#x2F;state”节点 读取该partition当前的ISR；</p><p>② 决定该partition的新leader：如果该分区的 ISR中有存活的副本，则选择其中一个作为新leader；如果该partition的ISR副本全部挂了，则选择该partition的 AR集合 中任一幸存的副本作为leader；如果该partition的所有副本都挂，则将分区的leader设为-1；</p><p>③ 将新 leader、ISR、controller_epoch 和 leader_epoch 等信息写入 state 节点；</p><p>5、通过RPC向set_p相关的broker发送LeaderAndISR Request命令。</p><p>05</p><p>controller failover</p><p>当 controller 宕机时会触发 controller failover。每个 broker 都会在 zookeeper 的 “&#x2F;controller” 节点注册 watcher（监听器），当 controller 宕机时 zookeeper 中的临时节点消失，所有存活的 broker 收到 fire 的通知，每个 broker 都尝试创建新的临时节点，只有一个会创建成功并当选为 controller。</p><p>当新的 controller 当选时，会回调KafkaController的onControllerFailover()方法，在这个方法中完成controller的初始化，controller 在初始化时，首先会利用 ZK 的 watch 机制注册很多不同类型的监听器，主要有以下几种：</p><ul><li><p>监听 &#x2F;admin&#x2F;reassign_partitions 节点，用于分区副本迁移的监听；</p></li><li><p>监听 &#x2F;isr_change_notification 节点，用于 Partition Isr 变动的监听；</p></li><li><p>监听 &#x2F;admin&#x2F;preferred_replica_election 节点，用于 Partition 最优 leader 选举的监听；</p></li><li><p>监听 &#x2F;brokers&#x2F;topics 节点，用于 topic 新建的监听；</p></li><li><p>监听 &#x2F;brokers&#x2F;topics&#x2F;TOPIC_NAME 节点，用于 Topic Partition 扩容的监听；</p></li><li><p>监听 &#x2F;admin&#x2F;delete_topics 节点，用于 topic 删除的监听；</p></li><li><p>监听 &#x2F;brokers&#x2F;ids 节点，用于 Broker 上下线的监听；</p></li></ul><p>除了注册多种监听器外，controller初始化时还做以下操作，</p><ul><li><p>initializeControllerContext()</p><p>初始化controller上下文，设置当前所有broker、topic、partition的leader、ISR等；</p></li><li><p>replicaStateMachine.startup()</p></li><li><p>partitionStateMachine.startup()</p><p>启动状态机；</p></li><li><p>brokerState.newState(RunningAsController)</p><p>将 brokerState 状态设置为 RunningAsController；</p></li><li><p>sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)</p><p>把partition leadership信息发到所有brokers；</p></li><li><p>autoRebalanceScheduler.startup()</p><p>如果打开了autoLeaderRebalance，则启动”partition-rebalance-thread”线程；</p></li><li><p>deleteTopicManager.start()</p><p>如果delete.topic.enable&#x3D;true，且 &#x2F;admin&#x2F;delete_topics 节点下有值，则删除相应的topic；</p></li></ul><p>最后，把onControllerFailover()方法的源码贴一下，上面说的这些操作就是在这个方法中完成的，感兴趣的可以再去看下kafka源码，</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs auto">def onControllerFailover() &#123;    if (isRunning) &#123;        info(&quot;Broker %d starting become controller state transition&quot;.format(config.brokerId))        //read controller epoch from zk        readControllerEpochFromZookeeper()        // increment the controller epoch        incrementControllerEpoch(zkUtils.zkClient)        // before reading source of truth from zookeeper, register the listeners to get broker/topic callbacks        registerReassignedPartitionsListener()        registerIsrChangeNotificationListener()        registerPreferredReplicaElectionListener()        partitionStateMachine.registerListeners()        replicaStateMachine.registerListeners()        initializeControllerContext()        replicaStateMachine.startup()        partitionStateMachine.startup()        // register the partition change listeners for all existing topics on failover        controllerContext.allTopics.foreach(topic =&gt; partitionStateMachine.registerPartitionChangeListener(topic))        info(&quot;Broker %d is ready to serve as the new controller with epoch %d&quot;.format(config.brokerId, epoch))        brokerState.newState(RunningAsController)        maybeTriggerPartitionReassignment()        maybeTriggerPreferredReplicaElection()        /* send partition leadership info to all live brokers */        sendUpdateMetadataRequest(controllerContext.liveOrShuttingDownBrokerIds.toSeq)        if (config.autoLeaderRebalanceEnable) &#123;            info(&quot;starting the partition rebalance scheduler&quot;)            autoRebalanceScheduler.startup()            autoRebalanceScheduler.schedule(&quot;partition-rebalance-thread&quot;, checkAndTriggerPartitionRebalance,                5, config.leaderImbalanceCheckIntervalSeconds.toLong, TimeUnit.SECONDS)        &#125;        deleteTopicManager.start()    &#125;    else        info(&quot;Controller has been shut down, aborting startup/failover&quot;)&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;我们知道，kafka中每个topic被划分为多个partition，每个partition又有多个副本，那么这些分区副本是怎么均匀的分布在整个kafka集群的broker节点上的？partition副本的leader是通过什么算法选举出来的？partition副本</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>大白话 kafka 架构原理</title>
    <link href="http://example.com/2021/01/05/%E5%A4%A7%E7%99%BD%E8%AF%9D%20kafka%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/01/05/%E5%A4%A7%E7%99%BD%E8%AF%9D%20kafka%20%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86/</id>
    <published>2021-01-05T06:20:33.000Z</published>
    <updated>2024-01-07T10:21:13.885Z</updated>
    
    <content type="html"><![CDATA[<h3 id="大数据时代来临，如果你还不知道Kafka那就真的out了！据统计，有三分之一的世界财富500强企业正在使用Kafka，包括所有TOP10旅游公司，7家TOP10银行，8家TOP10保险公司，9家TOP10电信公司等等。LinkedIn、Microsoft和Netflix每天都用Kafka处理万亿级的信息。本文就让我们一起来大白话kafka的架构原理。"><a href="#大数据时代来临，如果你还不知道Kafka那就真的out了！据统计，有三分之一的世界财富500强企业正在使用Kafka，包括所有TOP10旅游公司，7家TOP10银行，8家TOP10保险公司，9家TOP10电信公司等等。LinkedIn、Microsoft和Netflix每天都用Kafka处理万亿级的信息。本文就让我们一起来大白话kafka的架构原理。" class="headerlink" title="大数据时代来临，如果你还不知道Kafka那就真的out了！据统计，有三分之一的世界财富500强企业正在使用Kafka，包括所有TOP10旅游公司，7家TOP10银行，8家TOP10保险公司，9家TOP10电信公司等等。LinkedIn、Microsoft和Netflix每天都用Kafka处理万亿级的信息。本文就让我们一起来大白话kafka的架构原理。"></a>大数据时代来临，如果你还不知道Kafka那就真的out了！据统计，有三分之一的世界财富500强企业正在使用Kafka，包括所有TOP10旅游公司，7家TOP10银行，8家TOP10保险公司，9家TOP10电信公司等等。LinkedIn、Microsoft和Netflix每天都用Kafka处理万亿级的信息。本文就让我们一起来大白话kafka的架构原理。</h3><p>kafka官网：<a href="http://kafka.apache.org/">http://kafka.apache.org/</a></p><p>01</p><p>PART</p><p>kafka简介</p><p>Kafka最初由Linkedin公司开发，是一个分布式的、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常用于web&#x2F;nginx日志、访问日志、消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p><p>02</p><p>PART</p><p>kafka的特性</p><ul><li><p>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒；</p></li><li><p>可扩展性：kafka集群支持热扩展；</p></li><li><p>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止丢失；</p></li><li><p>容错性：允许集群中的节点失败(若分区副本数量为n,则允许n-1个节点失败)；</p></li><li><p>高并发：单机可支持数千个客户端同时读写；</p></li></ul><p>03</p><p>PART</p><p>kafka的应用场景</p><ul><li><p>日志收集：一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口开放给各种消费端，例如hadoop、Hbase、Solr等。</p></li><li><p>消息系统：解耦生产者和消费者、缓存消息等。</p></li><li><p>用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索记录、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。</p></li><li><p>运营指标：Kafka也经常用来记录运营监控数据。</p></li><li><p>流式处理</p></li></ul><p>04</p><p>PART</p><p>kafka架构（重头戏!）</p><p>下面是一个kafka的架构图，</p><p><img src="https://img-blog.csdnimg.cn/img_convert/0e243ead512ce442d090f6cf29ddd3a4.png" alt="Image"></p><p>整体来看，kafka架构中包含四大组件：生产者、消费者、kafka集群、zookeeper集群。对照上面的结构图，我们先来搞清楚几个很重要的术语，（看图！对照图理解~）</p><p>1、broker</p><p>kafka 集群包含一个或多个服务器，每个服务器节点称为一个broker。</p><p>2、topic</p><p>每条发布到kafka集群的消息都有一个类别，这个类别称为topic，其实就是将消息按照topic来分类，topic就是逻辑上的分类，同一个topic的数据既可以在同一个broker上也可以在不同的broker结点上。</p><p>3、partition</p><p>分区，每个topic被物理划分为一个或多个分区，每个分区在物理上对应一个文件夹，该文件夹里面存储了这个分区的所有消息和索引文件。在创建topic时可指定parition数量，生产者将消息发送到topic时，消息会根据 分区策略 追加到分区文件的末尾，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/5a5ecec9dd76ef9560625073e0cb3c8d.png" alt="Image"></p><p>上面提到了分区策略，所谓分区策略就是决定生产者将消息发送到哪个分区的算法。Kafka 为我们提供了默认的分区策略，同时它也支持自定义分区策略。kafka允许为每条消息设置一个key，一旦消息被定义了 Key，那么就可以保证同一个 Key 的所有消息都进入到相同的分区，这种策略属于自定义策略的一种，被称作”按消息key保存策略”，或Key-ordering 策略。</p><p>同一主题的多个分区可以部署在多个机器上，以此来实现 kafka 的伸缩性。同一partition中的数据是有序的，但topic下的多个partition之间在消费数据时不能保证有序性，在需要严格保证消息顺序消费的场景下，可以将partition数设为1，但这种做法的缺点是降低了吞吐，一般来说，只需要保证每个分区的有序性，再对消息设置key来保证相同key的消息落入同一分区，就可以满足绝大多数的应用。</p><p>4、offset</p><p>partition中的每条消息都被标记了一个序号，这个序号表示消息在partition中的偏移量，称为offset，每一条消息在partition都有唯一的offset，消息者通过指定offset来指定要消费的消息。</p><p>正常情况下，消费者在消费完一条消息后会递增offset，准备去消费下一条消息，但也可以将offset设成一个较小的值，重新消费一些消费过的消息，可见offset是由consumer控制的，consumer想消费哪一条消息就消费哪一条消息，所以kafka broker是无状态的，它不需要标记哪些消息被消费过。</p><p>5、producer</p><p>生产者，生产者发送消息到指定的topic下，消息再根据分配规则append到某个partition的末尾。</p><p>6、consumer</p><p>消费者，消费者从topic中消费数据。</p><p>7、consumer group</p><p>消费者组，每个consumer属于一个特定的consumer group，可为每个consumer指定consumer group，若不指定则属于默认的group。</p><p>同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。这也是kafka用来实现一个topic消息的广播和单播的手段，如果需要实现广播，一个consumer group内只放一个消费者即可，要实现单播，将所有的消费者放到同一个consumer group即可。</p><p>用consumer group还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。</p><p>8、leader</p><p>每个partition有多个副本，其中有且仅有一个作为leader，leader会负责所有的客户端读写操作。</p><p>9、follower</p><p>follower不对外提供服务，只与leader保持数据同步，如果leader失效，则选举一个follower来充当新的leader。当follower与leader挂掉、卡住或者同步太慢，leader会把这个follower从ISR列表中删除，重新创建一个follower。</p><p>10、rebalance</p><p>同一个consumer group下的多个消费者互相协调消费工作，我们这样想，一个topic分为多个分区，一个consumer group里面的所有消费者合作，一起去消费所订阅的某个topic下的所有分区(每个消费者消费部分分区)，kafka会将该topic下的所有分区均匀的分配给consumer group下的每个消费者，如下图，</p><p><img src="https://img-blog.csdnimg.cn/img_convert/924db4e3900f5802bd337b0f9b08327d.png" alt="Image"></p><p>rebalance表示”重平衡”，consumer group内某个消费者挂掉后，其他消费者自动重新分配订阅主题分区的过程，是 Kafka 消费者端实现高可用的重要手段。如下图Consumer Group A中的C2挂掉，C1会接收P1和P2，以达到重新平衡。同样的，当有新消费者加入consumer group，也会触发重平衡操作。</p><p>05</p><p>PART</p><p>对kafka架构的几点解释</p><ul><li><p>一个典型的kafka集群中包含若干producer，若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干consumer group，以及一个zookeeper集群。kafka通过zookeeper协调管理kafka集群，选举分区leader，以及在consumer group发生变化时进行rebalance。</p></li><li><p>kafka的topic被划分为一个或多个分区，多个分区可以分布在一个或多个broker节点上，同时为了故障容错，每个分区都会复制多个副本，分别位于不同的broker节点，这些分区副本中（不管是leader还是follower都称为分区副本），一个分区副本会作为leader，其余的分区副本作为follower。其中leader负责所有的客户端读写操作，follower不对外提供服务，仅仅从leader上同步数据，当leader出现故障时，其中的一个follower会顶替成为leader，继续对外提供服务。</p></li><li><p>对于传统的MQ而言，已经被消费的消息会从队列中删除，但在Kafka中被消费的消息也不会立马删除，在kafka的server.propertise配置文件中定义了数据的保存时间，当文件到设定的保存时间时才会删除，</p><p># 数据的保存时间(单位:小时，默认为7天)</p><p>log.retention.hours&#x3D;168</p><p>因为Kafka读取消息的时间复杂度为O(1)，与文件大小无关，所以这里删除过期文件与提高Kafka性能并没有关系，所以选择怎样的删除策略应该考虑磁盘以及具体的需求。</p></li><li><p>点对点模式 VS 发布订阅模式</p><p>传统的消息系统中，有两种主要的消息传递模式：点对点模式、发布订阅模式。</p><p>①点对点模式 </p><p>生产者发送消息到queue中，queue支持存在多个消费者，但是对一个消息而言，只可以被一个消费者消费，并且在点对点模式中，已经消费过的消息会从queue中删除不再存储。</p><p>②发布订阅模式</p><p>生产者将消息发布到topic中，topic可以被多个消费者订阅，且发布到topic的消息会被所有订阅者消费。而kafka就是一种发布订阅模式。</p></li><li><p>消费端 pull 和 push</p><p>① push方式：由消息中间件主动地将消息推送给消费者；</p><p>优点：优点是不需要消费者额外开启线程监控中间件，节省开销。</p><p>缺点：无法适应消费速率不相同的消费者。因为消息的发送速率是broker决定的，而消</p><p>费者的处理速度又不尽相同，所以容易造成部分消费者空闲，部分消费者堆积，造成缓</p><p>冲区溢出。</p><p>② pull方式：由消费者主动向消息中间件拉取消息；</p><p>优点：消费端可以按处理能力进行拉取；</p><p>缺点：消费端需要另开线程监控中间件，有性能开销；</p><p>对于Kafka而言，pull模式更合适。pull模式可简化broker的设计，Consumer可自主控制消费消息的速率，同时Consumer可以自己控制消费方式，既可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。</p></li></ul><p>06</p><p>PART</p><p>kafka和rabbitMQ对比</p><table><tbody><tr><td>&nbsp;</td><td><p>RabbitMQ</p></td><td><p>Kafka</p></td></tr><tr><td><p>开发语言</p></td><td><p>erlang</p></td><td><p>scala，Java</p></td></tr><tr><td><p>架构模型</p></td><td><p>① 遵循AMQP；</p><p>② 生产者、消费者、broker。</p><p>③ broker由exchange、binding、queue组成；</p><p>④ consumer消费位置由broker通过确认机制保存；</p></td><td><p>① 不遵循AMQP；</p><p>② 生产者、消费者、kafka集群、zookeeper集群；</p><p>③ kafka集群由多个broker节点组成，消息按照topic分类，每个topic又划分为多个partition；</p><p>④ broker无状态，offset由消费者指定；</p></td></tr><tr><td><p>可靠性</p></td><td>&nbsp;</td><td><p>RabbitMQ可靠性更好，支持事务，支持消息确认机制</p></td></tr><tr><td><p>高可用</p></td><td><p>采用镜像队列，即主从模式，数据是异步同步的，当消息过来，主从全部写完后，回ack，这样保障了数据的一致性。</p></td><td><p>每个分区都有一个或多个副本，这些副本保存在不同的broker上，其中有且仅有一个分区副本作为leader，其余的作为follower，当leader不可用时，会选举follower作为新leader继续提供服务。</p><p>只有leader提供读写服务，follower从leader同步拉取数据然后备份。</p></td></tr><tr><td><p>吞吐量</p></td><td><p>kafka更高</p></td><td>&nbsp;</td></tr><tr><td><p>是否支持事务</p></td><td><p>支持</p></td><td><p>不支持</p></td></tr><tr><td><p>负载均衡</p></td><td><p>需要外部支持才能实现（如：loadbalancer）</p></td><td><p>kafka利用zk和分区机制实现负载均衡</p></td></tr><tr><td><p>是否支持消费者Push</p></td><td><p>不支持</p></td><td><p>支持</p></td></tr><tr><td><p>是否支持消费者Pull</p></td><td><p>支持</p></td><td><p>支持</p></td></tr><tr><td><p>适用场景</p></td><td><p>kafka的优势主要体现在吞吐量上，它主要用在高吞吐量的场景。比如日志采集。</p></td><td><p>具有较高的严谨性，数据丢失的可能性更小，同时具备较高的实时性，用在对实时性、可靠性要求较高的消息传递上。</p></td></tr></tbody></table><p>07</p><p>PART</p><p>kafka吞吐量为什么这么高</p><p>1、顺序读写磁盘</p><p>Kafka是将消息持久化到本地磁盘中的，一般人会认为磁盘读写性能差，可能会对Kafka性能提出质疑。实际上不管是内存还是磁盘，快或慢的关键在于寻址方式，磁盘分为顺序读写与随机读写，内存一样也分为顺序读写与随机读写。基于磁盘的随机读写确实很慢，但基于磁盘的顺序读写性能却很高，一般而言要高出磁盘的随机读写三个数量级，一些情况下磁盘顺序读写性能甚至要高于内存随机读写，这里贴一张著名学术期刊 ACM Queue 上的一张性能对比图：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/47f98458333eaae12442f549893fe730.png" alt="Image"></p><p>2、page cache</p><p>为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。这样做是因为，</p><p>&gt; JVM中一切皆对象，对象的存储会带来额外的内存消耗；</p><p>&gt; 使用JVM会受到GC的影响，随着数据的增多，垃圾回收也会变得复杂与缓慢，降低吞吐量；</p><p>另外操作系统本身对page cache做了大量优化，通过操作系统的Page Cache，Kafka的读写操作基本上是基于系统内存的，读写性能也得到了极大的提升。</p><p>3、零拷贝</p><p>零拷贝是指Kafka利用 linux 操作系统的 “zero-copy” 机制在消费端做的优化。首先来看一下消费端在消费数据时，数据从broker磁盘通过网络传输到消费端的整个过程：</p><p>&gt; 操作系统从磁盘读取数据到内核空间（kernel space）的page cache；</p><p>&gt; 应用程序读取page cache的数据到用户空间（user space）的缓冲区；</p><p>&gt; 应用程序将用户空间缓冲区的数据写回内核空间的socket缓冲区（socket buffer）；</p><p>&gt; 操作系统将数据从socket缓冲区复制到硬件（如网卡）缓冲区；</p><p><img src="https://img-blog.csdnimg.cn/img_convert/213fe78a0275018b10c86ea46bbf8b08.png" alt="Image"></p><p>整个过程如上图所示，这个过程包含4次copy操作和2次系统上下文切换，而上下文切换是CPU密集型的工作，数据拷贝是I&#x2F;O密集型的工作，性能其实非常低效。</p><p>零拷贝就是使用了一个名为sendfile()的系统调用方法，将数据从page cache直接发送到Socket缓冲区，避免了系统上下文的切换，消除了从内核空间到用户空间的来回复制。从上图可以看出，”零拷贝”并不是说整个过程完全不发生拷贝，而是站在内核的角度来说的，避免了内核空间到用户空间的来回拷贝。</p><p>4、分区分段</p><p>Kafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。这也非常符合分布式系统分区分桶的设计思想。</p><p>通过这种分区分段的设计，Kafka的message消息实际上是分布式存储在一个一个小的segment中的，每次文件操作也是直接操作的segment。为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。</p><p>总之，Kafka采用顺序读写、Page Cache、零拷贝以及分区分段等这些设计，再加上在索引方面做的优化，另外Kafka数据读写也是批量的而不是单条的，使得Kafka具有了高性能、高吞吐、低延时的特点。</p><p>Scan to Follow</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;大数据时代来临，如果你还不知道Kafka那就真的out了！据统计，有三分之一的世界财富500强企业正在使用Kafka，包括所有TOP10旅游公司，7家TOP10银行，8家TOP10保险公司，9家TOP10电信公司等等。LinkedIn、Microsoft和Netf</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>一致性hash算法详解</title>
    <link href="http://example.com/2020/12/08/%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2020/12/08/%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/</id>
    <published>2020-12-08T08:04:09.000Z</published>
    <updated>2024-01-07T14:12:30.159Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一致性hash算法详解"><a href="#一致性hash算法详解" class="headerlink" title="一致性hash算法详解"></a>一致性hash算法详解</h2><p>最新推荐文章于 2024-01-06 13:51:23 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/reprint.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2024-01-06 13:51:23 发布</p><p>目前正在维护公司的分布式任务调度平台，在任务节点的分配上使用到了一致性hash算法，特此记录，那么在后面的博文中会给出基于java实现的一致性hash算法的代码，以及分布式调度平台的一些设计思路。</p><h3 id="1-hash算法"><a href="#1-hash算法" class="headerlink" title="1.hash算法"></a>1.hash算法</h3><p>那么什么是hash算法呢，百度百科的定义如下：</p><p>哈希算法将任意长度的二进制值映射为较短的固定长度的二进制值，这个小的二进制值称为哈希值。哈希值是一段数据唯一且极其紧凑的数值表示形式。</p><p><strong>普通的hash算法在分布式应用中的不足：</strong></p><p><strong>比如，在分布式的存储系统中，要将数据存储到具体的节点上，如果我们采用普通的hash算法进行路由，将数据映射到具体的节点上，如key%N，key是数据的key，N是机器节点数，如果有一个机器加入或退出这个集群，则所有的数据映射都无效了，如果是持久化存储则要做数据迁移，如果是分布式缓存，则其他缓存就失效了。</strong></p><p>接下来我们来了解，一致性hash算法是怎么解决这个问题的。</p><h3 id="2-一致性hash算法"><a href="#2-一致性hash算法" class="headerlink" title="2.一致性hash算法"></a>2.一致性hash算法</h3><p>一致性哈希提出了在动态变化的Cache环境中，哈希算法应该满足的4个适应条件(from 百度百科)：</p><h4 id="均衡性-Balance"><a href="#均衡性-Balance" class="headerlink" title="均衡性(Balance)"></a>均衡性(Balance)</h4><p>平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</p><h4 id="单调性-Monotonicity"><a href="#单调性-Monotonicity" class="headerlink" title="单调性(Monotonicity)"></a>单调性(Monotonicity)</h4><p>单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。（这段翻译信息有负面价值的，当缓冲区大小变化时一致性哈希(Consistent hashing)尽量保护已分配的内容不会被重新映射到新缓冲区。）</p><h4 id="分散性-Spread"><a href="#分散性-Spread" class="headerlink" title="分散性(Spread)"></a>分散性(Spread)</h4><p>在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。</p><h4 id="负载-Load"><a href="#负载-Load" class="headerlink" title="负载(Load)"></a>负载(Load)</h4><p>负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</p><p>接下来说一下具体的设计：</p><h4 id="2-1环形hash空间"><a href="#2-1环形hash空间" class="headerlink" title="2.1环形hash空间"></a>2.1环形hash空间</h4><p>按照常用的hash算法来将对应的key哈希到一个具有2^32次方个节点的空间中，即0 ~ (2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。</p><p><strong>NOTE:<strong>当然，节点的个数可以自定义，</strong>整个hash环我们可以用TreeMap来实现，因为treeMap是排序的，我们刚好可以利用上</strong>。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/e116caac05ee8718ae499652d5371c16.png"></p><h4 id="2-2映射服务器节点"><a href="#2-2映射服务器节点" class="headerlink" title="2.2映射服务器节点"></a>2.2映射服务器节点</h4><p>将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或唯一主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。假设我们将四台服务器使用ip地址哈希后在环空间的位置如下：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/77247578bc606dcd10613d8ea8f2b9e4.png"></p><h4 id="2-3映射数据"><a href="#2-3映射数据" class="headerlink" title="2.3映射数据"></a>2.3映射数据</h4><p>现在我们将objectA、objectB、objectC、objectD四个对象通过特定的Hash函数计算出对应的key值，<strong>然后散列到Hash环上,然后从数据所在位置沿环顺时针“行走”</strong>，第一台遇到的服务器就是其应该定位到的服务器。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/e73adab0e5d0b65b5798337cc1045b9e.png"></p><h4 id="2-4服务器的删除与添加"><a href="#2-4服务器的删除与添加" class="headerlink" title="2.4服务器的删除与添加"></a>2.4服务器的删除与添加</h4><p><strong>2.4.1如果此时NodeC宕机了，此时Object A、B、D不会受到影响，只有Object C会重新分配到Node D上面去，而其他数据对象不会发生变化</strong></p><p><strong>2.4.2如果在环境中新增一台服务器Node X，通过hash算法将Node X映射到环中，通过按顺时针迁移的规则，那么Object C被迁移到了Node X中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。</strong></p><p><img src="https://img-blog.csdnimg.cn/img_convert/c5c5780cb28e08f36dae84bc4ce9c758.png"></p><h4 id="2-5-虚拟节点"><a href="#2-5-虚拟节点" class="headerlink" title="2.5.虚拟节点"></a>2.5.虚拟节点</h4><p>到目前为止一致性hash也可以算做完成了，但是有一个问题还需要解决，那就是<strong>平衡性</strong>。从下图我们可以看出，当服务器节点比较少的时候，<strong>会出现一个问题，就是此时必然造成大量数据集中到一个节点上面，极少数数据集中到另外的节点上面。</strong></p><p><img src="https://img-blog.csdnimg.cn/img_convert/97cdd5bc93cabecf2241caa6a048f17e.png"></p><p>为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以先确定每个物理节点关联的虚拟节点数量，然后在ip或者主机名后面增加编号。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/551d603b3eb2619933d57dce7a14b4bf.png"></p><p>同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。<strong>这样就解决了服务节点少时数据倾斜的问题。每个物理节点关联的虚拟节点数量就根据具体的生产环境情况在确定。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一致性hash算法详解&quot;&gt;&lt;a href=&quot;#一致性hash算法详解&quot; class=&quot;headerlink&quot; title=&quot;一致性hash算法详解&quot;&gt;&lt;/a&gt;一致性hash算法详解&lt;/h2&gt;&lt;p&gt;最新推荐文章于 2024-01-06 13:51:23 发布&lt;/p&gt;</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器介绍以及布隆过滤器的实现</title>
    <link href="http://example.com/2020/12/04/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>http://example.com/2020/12/04/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-12-04T03:17:50.000Z</published>
    <updated>2024-01-07T10:21:05.291Z</updated>
    
    <content type="html"><![CDATA[<h2 id="布隆过滤器介绍以及布隆过滤器的实现"><a href="#布隆过滤器介绍以及布隆过滤器的实现" class="headerlink" title="布隆过滤器介绍以及布隆过滤器的实现"></a>布隆过滤器介绍以及布隆过滤器的实现</h2><p>最新推荐文章于 2023-07-26 00:15:00 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2023-07-26 00:15:00 发布</p><p>版权声明：本文为博主原创文章，遵循 <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC 4.0 BY-SA</a> 版权协议，转载请附上原文出处链接和本声明。</p><h3 id="一·简介"><a href="#一·简介" class="headerlink" title="一·简介"></a><strong>一·简介</strong></h3><p>       布隆过滤器（Bloom Filter）实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。<strong>它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难</strong>。本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 <strong>“某样东西一定不存在或者可能存在”</strong>。</p><h3 id="二·原理"><a href="#二·原理" class="headerlink" title="二·原理"></a><strong>二·原理</strong></h3><p>1·刚开始是一个全部位为0的 bit 向量或者说 bit 数组</p><p>2.往过滤器增加”Bloom”</p><p><img src="https://img-blog.csdnimg.cn/20201204111442414.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><p><img src="http://confluence.admin.bluemoon.com.cn/download/attachments/39753387/1652302-20200510160113831-543587792.png?version=1&modificationDate=1606372166000&api=v2"></p><p>3.往过滤器增加”Filter”</p><p><img src="https://img-blog.csdnimg.cn/20201204111519559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><p><img src="http://confluence.admin.bluemoon.com.cn/download/attachments/39753387/1652302-20200510160126506-1020676650.png?version=1&modificationDate=1606372198000&api=v2"></p><p>4.在过滤器中查询“Hash”，5的位置是0，说明“Hash”一定不存在</p><p><img src="http://confluence.admin.bluemoon.com.cn/download/attachments/39753387/1652302-20200510160139140-362048813.png?version=1&modificationDate=1606372206000&api=v2"></p><p><img src="https://img-blog.csdnimg.cn/20201204111611969.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><p>5.可能存在误判情况（布隆过滤器可能会误判，如果它说不存在那肯定不存在，如果它说存在，那数据有可能实际不存在；）</p><p><img src="https://img-blog.csdnimg.cn/20201204111645641.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><p><img src="http://confluence.admin.bluemoon.com.cn/download/attachments/39753387/1652302-20200510160155384-464445682.png?version=1&modificationDate=1606372206000&api=v2"></p><p>Redis的bitmap 支持2^32大小，对应到内存也就是512MB，误判率万分之一，可以放下2亿左右的数据，性能高，空间占用率及小，省去了大量无效的数据库连接。</p><h3 id="三·使用场景"><a href="#三·使用场景" class="headerlink" title="三·使用场景"></a><strong>三·使用场景</strong></h3><ul><li><strong>防止缓存穿透</strong></li><li><strong>网页爬虫对 URL 去重，避免爬取相同的 URL 地址；</strong></li><li><strong>反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱；</strong></li><li><strong>Google Chrome 使用布隆过滤器识别恶意 URL；</strong></li><li><strong>Medium 使用布隆过滤器避免推荐给用户已经读过的文章；</strong></li><li><strong>Google BigTable，Apache HBbase 和 Apache Cassandra 使用布隆过滤器减少对不存在的行和列的查找。</strong></li></ul><h3 id="四·实战使用"><a href="#四·实战使用" class="headerlink" title="四·实战使用"></a><strong>四·实战使用</strong></h3><h4 id="1-Java-Guava实现"><a href="#1-Java-Guava实现" class="headerlink" title="1.Java Guava实现"></a><strong>1.Java Guava实现</strong></h4><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.google.guava<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>guava<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>19.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> com.google.common.hash.BloomFilter;<br><span class="hljs-keyword">import</span> com.google.common.hash.Funnels;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span> wayleung</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@description</span></span><br><span class="hljs-comment"> * <span class="hljs-doctag">@date</span> 2020-11-26 11:31:24</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">BloomFilterTest</span> &#123;<br>    <span class="hljs-comment">//预计要插入多少数据</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-variable">size</span> <span class="hljs-operator">=</span> <span class="hljs-number">1000000</span>;<br><br>    <span class="hljs-comment">//期望的误判率</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">double</span> <span class="hljs-variable">fpp</span> <span class="hljs-operator">=</span> <span class="hljs-number">0.001</span>;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> BloomFilter&lt;Integer&gt; bloomFilter = BloomFilter.create(Funnels.integerFunnel(), size, fpp);<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-comment">//插入数据 1-1000000</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">1000000</span>; i++) &#123;<br>            bloomFilter.put(i);<br>        &#125;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-comment">//判断 1000001-2000000 因为肯定是不存在的，所以如果是true的话那肯定就是误判</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1000001</span>; i &lt;= <span class="hljs-number">2000000</span>; i++) &#123;<br>            <span class="hljs-keyword">if</span> (bloomFilter.mightContain(i)) &#123;<br>                count++;<br>                System.out.println(i + <span class="hljs-string">&quot;误判了&quot;</span>);<br>            &#125;<br>        &#125;<br>        System.out.println(<span class="hljs-string">&quot;一共的误判数:&quot;</span> + count);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以查看输出结果并计算得知误判率994&#x2F;1000000&#x3D;0.000994 跟期望误判率大致相等</p><p><img src="https://img-blog.csdnimg.cn/20201204114608959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><h4 id="2-Redis实现"><a href="#2-Redis实现" class="headerlink" title="2.Redis实现"></a>2.Redis实现</h4><p>1、安装Redis官方插件 RedisBloom并在Redis配置文件中添加插件</p><p><a href="https://github.com/RedisLabsModules/redisbloom/"><em>https://github.com/RedisLabsModules/redisbloom/</em></a></p><p>[root@redis]# vim redis.conf</p><p>#####################MODULES####################                                                                                                                      </p><p># Load modules at startup. If the server is not able to load modules<br># it will abort. It is possible to use multiple loadmodule directives.<br>loadmodule &#x2F;usr&#x2F;local&#x2F;redis&#x2F;redisbloom-1.1.1&#x2F;<a href="http://rebloom.so/">rebloom.so</a></p><p>2、使用布隆过滤</p><p>  增加到布隆过滤器</p><p>  bf.add myfilter  123</p><p>从布隆过滤器中查询，判断是否存在</p><p>  bf.exists myfilter  123   #返回  1 ，说明可能存在值</p><p>  bf.exists myfilter  321   #返回  0， 说明不存在该值</p><p>3、准确率</p><p>  Redis中有一个命令可以来设置布隆过滤器的准确率：</p><p>  bf.reserve myfilter  0.01 100</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;布隆过滤器介绍以及布隆过滤器的实现&quot;&gt;&lt;a href=&quot;#布隆过滤器介绍以及布隆过滤器的实现&quot; class=&quot;headerlink&quot; title=&quot;布隆过滤器介绍以及布隆过滤器的实现&quot;&gt;&lt;/a&gt;布隆过滤器介绍以及布隆过滤器的实现&lt;/h2&gt;&lt;p&gt;最新推荐文章于 20</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="原创" scheme="http://example.com/tags/%E5%8E%9F%E5%88%9B/"/>
    
  </entry>
  
  <entry>
    <title>动态修改LOGGER级别—— Arthas</title>
    <link href="http://example.com/2020/12/04/%E5%8A%A8%E6%80%81%E4%BF%AE%E6%94%B9LOGGER%E7%BA%A7%E5%88%AB%E2%80%94%E2%80%94%20Arthas/"/>
    <id>http://example.com/2020/12/04/%E5%8A%A8%E6%80%81%E4%BF%AE%E6%94%B9LOGGER%E7%BA%A7%E5%88%AB%E2%80%94%E2%80%94%20Arthas/</id>
    <published>2020-12-04T03:09:50.000Z</published>
    <updated>2024-01-07T14:12:42.441Z</updated>
    
    <content type="html"><![CDATA[<h2 id="动态修改LOGGER级别——-Arthas"><a href="#动态修改LOGGER级别——-Arthas" class="headerlink" title="动态修改LOGGER级别—— Arthas"></a>动态修改LOGGER级别—— Arthas</h2><p>最新推荐文章于 2023-05-30 13:48:41 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2023-05-30 13:48:41 发布</p><p>版权声明：本文为博主原创文章，遵循 <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC 4.0 BY-SA</a> 版权协议，转载请附上原文出处链接和本声明。</p><h3 id="一·背景"><a href="#一·背景" class="headerlink" title="一·背景"></a><strong>一·背景</strong></h3><p>记得前阵子，我在工作中就遇到过一个生产环境数据的排查，但是大多数情况下，我们的项目在部署的时候就已经定义了LOGGER级别，用来控制输出的信息范围。</p><p>一般生产环境上我们的日志级别会设置成info级别因为，过多的输出会影响输出和查看日志的效率，另一方面，过少的日志让问题定位变得困难。</p><p>所以当生产出现问题时，线上容器通常定义在info级别，发生一些疑难问题时，光靠info级别的日志很难定位问题。</p><h3 id="二·Arthas介绍"><a href="#二·Arthas介绍" class="headerlink" title="二·Arthas介绍"></a><strong>二·Arthas介绍</strong></h3><p>Arthas是阿里开源的Java诊断工具。</p><p><img src="https://img-blog.csdnimg.cn/2020120411055538.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><p>官方网站：<a href="https://arthas.aliyun.com/zh-cn/">https://arthas.aliyun.com/zh-cn/</a></p><h3 id="三·如何使用-Arthas进行日志级别动态修改"><a href="#三·如何使用-Arthas进行日志级别动态修改" class="headerlink" title="三·如何使用****Arthas进行日志级别动态修改"></a><strong>三·如何使用****Arthas进行日志级别动态修改</strong></h3><h4 id="1-下载并运行Arthas"><a href="#1-下载并运行Arthas" class="headerlink" title="1.下载并运行Arthas"></a><strong>1.下载并运行Arthas</strong></h4><p><strong>java -jar arthas-boot.jar</strong></p><p><img src="https://img-blog.csdnimg.cn/20201204110722314.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><h4 id="2-选取要查看的java应用，输入编号"><a href="#2-选取要查看的java应用，输入编号" class="headerlink" title="2.选取要查看的java应用，输入编号"></a><strong>2.选取要查看的java应用，输入编号</strong></h4><p><img src="https://img-blog.csdnimg.cn/20201204110749784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><h4 id="3-运行logger命令查看应用当前日志级别"><a href="#3-运行logger命令查看应用当前日志级别" class="headerlink" title="3.运行logger命令查看应用当前日志级别"></a><strong>3.运行logger命令查看应用当前日志级别</strong></h4><p><img src="https://img-blog.csdnimg.cn/20201204110811304.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><h4 id="4-logger-–name-ROOT-–level-info-把ROOT的日志级别修改为info"><a href="#4-logger-–name-ROOT-–level-info-把ROOT的日志级别修改为info" class="headerlink" title="4.logger –name ROOT –level info 把ROOT的日志级别修改为info"></a>4.logger –name ROOT –level info 把ROOT的日志级别修改为info</h4><p><img src="https://img-blog.csdnimg.cn/2020120411092018.png"></p><h4 id="5-logger-–name-ROOT-–level-debug-记得排查完以后把日志级别修改回debug"><a href="#5-logger-–name-ROOT-–level-debug-记得排查完以后把日志级别修改回debug" class="headerlink" title="5.logger –name ROOT –level debug 记得排查完以后把日志级别修改回debug"></a>5.logger –name ROOT –level debug 记得排查完以后把日志级别修改回debug</h4>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;动态修改LOGGER级别——-Arthas&quot;&gt;&lt;a href=&quot;#动态修改LOGGER级别——-Arthas&quot; class=&quot;headerlink&quot; title=&quot;动态修改LOGGER级别—— Arthas&quot;&gt;&lt;/a&gt;动态修改LOGGER级别—— Arthas&lt;/</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="原创" scheme="http://example.com/tags/%E5%8E%9F%E5%88%9B/"/>
    
  </entry>
  
  <entry>
    <title>Java实现一次遍历单链表删除指定节点 剑指Offer18</title>
    <link href="http://example.com/2020/11/18/Java%E5%AE%9E%E7%8E%B0%E4%B8%80%E6%AC%A1%E9%81%8D%E5%8E%86%E5%8D%95%E9%93%BE%E8%A1%A8%E5%88%A0%E9%99%A4%E6%8C%87%E5%AE%9A%E8%8A%82%E7%82%B9%20%E5%89%91%E6%8C%87Offer18/"/>
    <id>http://example.com/2020/11/18/Java%E5%AE%9E%E7%8E%B0%E4%B8%80%E6%AC%A1%E9%81%8D%E5%8E%86%E5%8D%95%E9%93%BE%E8%A1%A8%E5%88%A0%E9%99%A4%E6%8C%87%E5%AE%9A%E8%8A%82%E7%82%B9%20%E5%89%91%E6%8C%87Offer18/</id>
    <published>2020-11-18T08:11:03.000Z</published>
    <updated>2024-01-07T10:21:10.985Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Java实现一次遍历单链表删除指定节点-剑指Offer18"><a href="#Java实现一次遍历单链表删除指定节点-剑指Offer18" class="headerlink" title="Java实现一次遍历单链表删除指定节点 剑指Offer18"></a>Java实现一次遍历单链表删除指定节点 剑指Offer18</h2><p>最新推荐文章于 2024-01-03 17:56:19 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png"></p><p>置顶 <a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2024-01-03 17:56:19 发布</p><p>版权声明：本文为博主原创文章，遵循 <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC 4.0 BY-SA</a> 版权协议，转载请附上原文出处链接和本声明。</p><p>今天刷leetcode的时候做到了一条单链表的经典题目，我做的题解运行速度和所占空间都不错所以分享给大家一下我的题解和思路。</p><p>循例先上一下题目和运行结果：</p><p><strong>题目：</strong></p><p>给定单向链表的头指针和一个要删除的节点的值，定义一个函数删除该节点。</p><p>返回删除后的链表的头节点。</p><p>注意：此题对比原题有改动</p><p>示例 1:</p><p>输入: head &#x3D; [4,5,1,9], val &#x3D; 5<br>输出: [4,1,9]<br>解释: 给定你链表中值为 5 的第二个节点，那么在调用了你的函数之后，该链表应变为 4 -&gt; 1 -&gt; 9.<br>示例 2:</p><p>输入: head &#x3D; [4,5,1,9], val &#x3D; 1<br>输出: [4,5,9]<br>解释: 给定你链表中值为 1 的第三个节点，那么在调用了你的函数之后，该链表应变为 4 -&gt; 5 -&gt; 9.   </p><p>说明：</p><p>题目保证链表中节点的值互不相同<br>若使用 C 或 C++ 语言，你不需要 free 或 delete 被删除的节点</p><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode-cn.com/problems/shan-chu-lian-biao-de-jie-dian-lcof">https://leetcode-cn.com/problems/shan-chu-lian-biao-de-jie-dian-lcof</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p><p><strong>运行结果：</strong></p><p><img src="https://img-blog.csdnimg.cn/20201118160534840.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><p><strong>题解思路：</strong></p><p><strong>首先处理头节点的两种特殊情况1.头节点为空 2.头节点就是要删除的节点</strong></p><p><strong>然后创建两个引用记录现在“位置” 和 前一个listNode的位置</strong></p><p><strong>必须要记录上一个listnode的“位置” 否则无法一次遍历就删除</strong></p><p><strong>遍历判断相等是否相等 并 移动两个引用到下一个listnode</strong></p><p><strong>代码：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sword18</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-keyword">new</span> <span class="hljs-title class_">Sword18</span>().test();<br>    &#125;<br><br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">test</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">node4</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">4</span>);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">node5</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">5</span>);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">node1</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">1</span>);<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">node9</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(<span class="hljs-number">9</span>);<br>        node4.next = node5;<br>        node5.next = node1;<br>        node1.next = node9;<br>        System.out.println(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Sword18</span>().deleteNode(node4, <span class="hljs-number">5</span>));<br>    &#125;<br><br><br><br><br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">deleteNode</span><span class="hljs-params">(ListNode head, <span class="hljs-type">int</span> val)</span> &#123;<br>        <span class="hljs-comment">//处理头节点的两种特殊情况</span><br>        <span class="hljs-comment">//1.头节点为空</span><br>        <span class="hljs-keyword">if</span>(head==<span class="hljs-literal">null</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        &#125;<br>        <span class="hljs-comment">//2.头节点就是要删除的节点</span><br>        <span class="hljs-keyword">if</span>(head.val==val)&#123;<br>            <span class="hljs-keyword">return</span> head.next;<br>        &#125;<br>        <span class="hljs-comment">//当前位置的ListNode引用</span><br>        ListNode now;<br>        <span class="hljs-comment">//上一个位置的ListNode引用</span><br>        ListNode pre;<br>        now = head.next;<br>        pre = head;<br>        <span class="hljs-keyword">while</span>(now!=<span class="hljs-literal">null</span>)&#123;<br>            <span class="hljs-keyword">if</span>(now.val==val)&#123;<br>                <span class="hljs-comment">//删除</span><br>                pre.next = now.next;<br>            &#125;<br>            <span class="hljs-comment">//两个引用移动到下一个位置</span><br>            now = now.next;<br>            pre = pre.next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> head;<br>    &#125;<br><br><br><br>    <span class="hljs-keyword">class</span> <span class="hljs-title class_">ListNode</span> &#123;<br>        <span class="hljs-type">int</span> val;<br>        ListNode next;<br><br>        ListNode(<span class="hljs-type">int</span> x) &#123;<br>            val = x;<br>        &#125;<br><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> String <span class="hljs-title function_">toString</span><span class="hljs-params">()</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;ListNode&#123;&quot;</span> +<br>                    <span class="hljs-string">&quot;val=&quot;</span> + val +<br>                    <span class="hljs-string">&quot;, next=&quot;</span> + next +<br>                    <span class="hljs-string">&#x27;&#125;&#x27;</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Java实现一次遍历单链表删除指定节点-剑指Offer18&quot;&gt;&lt;a href=&quot;#Java实现一次遍历单链表删除指定节点-剑指Offer18&quot; class=&quot;headerlink&quot; title=&quot;Java实现一次遍历单链表删除指定节点 剑指Offer18&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="原创" scheme="http://example.com/tags/%E5%8E%9F%E5%88%9B/"/>
    
  </entry>
  
  <entry>
    <title>剑指 Offer 05 替换空格 ，用时0ms，超过100%用户的Java解法</title>
    <link href="http://example.com/2020/11/12/%E5%89%91%E6%8C%87%20Offer%2005%20%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC%20%EF%BC%8C%E7%94%A8%E6%97%B60ms%EF%BC%8C%E8%B6%85%E8%BF%87100%%E7%94%A8%E6%88%B7%E7%9A%84Java%E8%A7%A3%E6%B3%95/"/>
    <id>http://example.com/2020/11/12/%E5%89%91%E6%8C%87%20Offer%2005%20%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC%20%EF%BC%8C%E7%94%A8%E6%97%B60ms%EF%BC%8C%E8%B6%85%E8%BF%87100%%E7%94%A8%E6%88%B7%E7%9A%84Java%E8%A7%A3%E6%B3%95/</id>
    <published>2020-11-12T11:36:51.000Z</published>
    <updated>2024-01-07T14:12:27.279Z</updated>
    
    <content type="html"><![CDATA[<h2 id="剑指-Offer-05-替换空格-，用时0ms，超过100-用户的Java解法"><a href="#剑指-Offer-05-替换空格-，用时0ms，超过100-用户的Java解法" class="headerlink" title="剑指 Offer 05 替换空格 ，用时0ms，超过100%用户的Java解法"></a>剑指 Offer 05 替换空格 ，用时0ms，超过100%用户的Java解法</h2><p>最新推荐文章于 2024-01-06 14:29:50 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2024-01-06 14:29:50 发布</p><p>版权声明：本文为博主原创文章，遵循 <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC 4.0 BY-SA</a> 版权协议，转载请附上原文出处链接和本声明。</p><p><strong>题目：</strong></p><p>请实现一个函数，把字符串 s 中的每个空格替换成”%20”。</p><p>示例 1：</p><p>输入：s &#x3D; “We are happy.”<br>输出：”We%20are%20happy.”   </p><p>限制：</p><p>0 &lt;&#x3D; s 的长度 &lt;&#x3D; 10000</p><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode-cn.com/problems/ti-huan-kong-ge-lcof">https://leetcode-cn.com/problems/ti-huan-kong-ge-lcof</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p><p><strong>然后再上一下我的提交结果：</strong></p><p><img src="https://img-blog.csdnimg.cn/20201112193057780.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><p><strong>我的解题思路：</strong></p><h3 id="1-首先遍历记录下空格字符的数目，原字符数组大小-空格字符的数目-（替换后的字符串-1）得出新数组的大小"><a href="#1-首先遍历记录下空格字符的数目，原字符数组大小-空格字符的数目-（替换后的字符串-1）得出新数组的大小" class="headerlink" title="1.首先遍历记录下空格字符的数目，原字符数组大小+空格字符的数目*（替换后的字符串-1）得出新数组的大小"></a>1.首先遍历记录下空格字符的数目，原字符数组大小+空格字符的数目*（替换后的字符串-1）得出新数组的大小</h3><h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>2.遍历字符串的原字符数组遇到空格字符的话  新数组i位置以及后面的元素为 %20还有 修改i的位置 直至遍历完成</p><h3 id="-1"><a href="#-1" class="headerlink" title=""></a></h3><p>3.最后返回新数组组成的字符串</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;剑指-Offer-05-替换空格-，用时0ms，超过100-用户的Java解法&quot;&gt;&lt;a href=&quot;#剑指-Offer-05-替换空格-，用时0ms，超过100-用户的Java解法&quot; class=&quot;headerlink&quot; title=&quot;剑指 Offer 05 替换</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="原创" scheme="http://example.com/tags/%E5%8E%9F%E5%88%9B/"/>
    
  </entry>
  
  <entry>
    <title>Java的快速失败与安全失败与遍历修改</title>
    <link href="http://example.com/2020/10/21/Java%E7%9A%84%E5%BF%AB%E9%80%9F%E5%A4%B1%E8%B4%A5%E4%B8%8E%E5%AE%89%E5%85%A8%E5%A4%B1%E8%B4%A5%E4%B8%8E%E9%81%8D%E5%8E%86%E4%BF%AE%E6%94%B9/"/>
    <id>http://example.com/2020/10/21/Java%E7%9A%84%E5%BF%AB%E9%80%9F%E5%A4%B1%E8%B4%A5%E4%B8%8E%E5%AE%89%E5%85%A8%E5%A4%B1%E8%B4%A5%E4%B8%8E%E9%81%8D%E5%8E%86%E4%BF%AE%E6%94%B9/</id>
    <published>2020-10-21T02:48:43.000Z</published>
    <updated>2024-01-07T14:12:44.873Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Java的快速失败与安全失败与遍历修改"><a href="#Java的快速失败与安全失败与遍历修改" class="headerlink" title="Java的快速失败与安全失败与遍历修改"></a>Java的快速失败与安全失败与遍历修改</h2><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 于 2020-10-21 10:48:43 发布</p><p>版权声明：本文为博主原创文章，遵循 <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC 4.0 BY-SA</a> 版权协议，转载请附上原文出处链接和本声明。</p><h4 id="一、快速失败（fail—fast）"><a href="#一、快速失败（fail—fast）" class="headerlink" title="一、快速失败（fail—fast）"></a>一、快速失败（fail—fast）</h4><p>在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出 Concurrent Modification Exception。</p><p><strong>原理：</strong>迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变 modCount 的值。每当迭代器使用 hashNext()&#x2F;next() 遍历下一个元素之前，都会检测 modCount 变量是否为 expectedmodCount 值，是的话就返回遍历；否则抛出异常，终止遍历。</p><p><strong>注意：</strong>这里异常的抛出条件是检测到 <strong>modCount !&#x3D; expectedmodCount</strong> 这个条件。如果集合发生变化时修改 modCount 值刚好又设置为了 expectedmodCount 值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的 bug。</p><p><strong>场景：</strong>java.util 包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。</p><p><strong>方法1:</strong></p><p>在单线程的遍历过程中，如果要进行remove操作，可以调用迭代器的remove方法而不是集合类的remove方法。看看ArrayList中迭代器的remove方法的源码：</p><p><strong>方法2:</strong></p><p>使用java并发包(java.util.concurrent)中的类来代替 ArrayList 和hashMap。</p><p>比如使用 CopyOnWriterArrayList代替 ArrayList， CopyOnWriterArrayList在是使用上跟 ArrayList几乎一样， CopyOnWriter是写时复制的容器(COW)，在读写时是线程安全的。该容器在对add和remove等操作时，并不是在原数组上进行修改，而是将原数组拷贝一份，在新数组上进行修改，待完成后，才将指向旧数组的引用指向新数组，所以对于 CopyOnWriterArrayList在迭代过程并不会发生fail-fast现象。但 CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。</p><p>对于HashMap，可以使用ConcurrentHashMap， ConcurrentHashMap采用了锁机制，是线程安全的。在迭代方面，ConcurrentHashMap使用了一种不同的迭代方式。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数据 ，iterator完成后再将头指针替换为新的数据 ，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变。即迭代不会发生fail-fast，但不保证获取的是最新的数据。</p><h4 id="二、安全失败（fail—safe）"><a href="#二、安全失败（fail—safe）" class="headerlink" title="二、安全失败（fail—safe）"></a>二、安全失败（fail—safe）</h4><p>采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。</p><p><strong>原理：</strong>由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发 Concurrent Modification Exception。</p><p>&gt;缺点：基于拷贝内容的优点是避免了 Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。</p><p><strong>场景：</strong>java.util.concurrent 包下的容器都是安全失败，可以在多线程下并发使用，并发修改。</p><p>参考自：<a href="https://www.runoob.com/w3cnote/java-fail-ast-fail-safe.html">https://www.runoob.com/w3cnote/java-fail-ast-fail-safe.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Java的快速失败与安全失败与遍历修改&quot;&gt;&lt;a href=&quot;#Java的快速失败与安全失败与遍历修改&quot; class=&quot;headerlink&quot; title=&quot;Java的快速失败与安全失败与遍历修改&quot;&gt;&lt;/a&gt;Java的快速失败与安全失败与遍历修改&lt;/h2&gt;&lt;p&gt;&lt;i</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="原创" scheme="http://example.com/tags/%E5%8E%9F%E5%88%9B/"/>
    
  </entry>
  
  <entry>
    <title>记一次阿里巴巴面试的经历</title>
    <link href="http://example.com/2020/08/20/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E9%9D%A2%E8%AF%95%E7%9A%84%E7%BB%8F%E5%8E%86/"/>
    <id>http://example.com/2020/08/20/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E9%9D%A2%E8%AF%95%E7%9A%84%E7%BB%8F%E5%8E%86/</id>
    <published>2020-08-20T12:32:17.000Z</published>
    <updated>2024-01-07T10:21:19.282Z</updated>
    
    <content type="html"><![CDATA[<p>       今天我下班的时候接到了昨晚阿里巴巴面试我的技术面试官的电话，他问我昨晚的编程题是提交了全部的代码吗，我那时候正在地铁刚下班也有点迷糊，而且我想着昨晚的题也基本完成了90%应该没问题，于是我就说了：”应该是的“，然后说了一些昨晚没全部完成的理由。后面我们的通话就结束了，但是当我挂了以后我就十分后悔，我感觉这很有可能是面试官给我的最后一个机会，我想回拨回去，可是奈何这是虚拟电话，根本没有用。于是回到家中我十分懊恼，也用了一会就把昨晚的题完全做出来了，可是当我打开邮箱的时候却收到这样一封邮件：<img src="https://img-blog.csdnimg.cn/20200820201307994.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p><p>瞬间，我觉得这可能是我离阿里最远但是又是最近的一次，最近是因为从8.11日我收到了阿里的简历内推成功进入面试的通知，我很兴奋而且我感觉前面回答面试官的技术问题都回答的不错的，编程题也基本做出来了，最远又是因为这个结果已经很明确了——FAILED！后面我实在忍不住哭了，向我女朋友倾诉了，其实我这么想进去大厂，很大的一个缘故也是因为想快点赚多点钱跟她买房子，娶她。</p><p>        写到这里，我心情稍微平复，我告诉自己我得振作，总结经验：这次我感觉主要就是我的心态问题。面对阿里这样的大厂我不应该抱着完成90%就可以的心态，90%就是相当于没完成，昨晚到今天时间这么长我就应该抽出时间100%完成，这样说不定还有机会进入下一步，今天我在这里记录这个经历就当给自己的一个激励，后面我必须继续提升自己，严谨的做事，最后奉上我完成的代码和刚刚输出的符合面试官的编程题要求的输出结果：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.way.test;<br><br><span class="hljs-keyword">import</span> java.io.*;<br><span class="hljs-keyword">import</span> java.util.*;<br><span class="hljs-keyword">import</span> java.util.stream.Collectors;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span> wayleung</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@description</span></span><br><span class="hljs-comment"> * <span class="hljs-doctag">@date</span> 2020-08-19 19:40:59</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AliTest</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>        <span class="hljs-type">File</span> <span class="hljs-variable">file</span>  <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(<span class="hljs-string">&quot;/Users/wayleung/work/test.txt&quot;</span>);<br>        List&lt;Tree&gt; list = parseFile(file);<br>        <span class="hljs-type">Tree</span> <span class="hljs-variable">tree</span> <span class="hljs-operator">=</span> buildTree(list);<br><span class="hljs-comment">//        System.out.println(tree);</span><br>        System.out.println(isValid(tree, <span class="hljs-string">&quot;北京市&quot;</span>, <span class="hljs-string">&quot;平谷区&quot;</span>, <span class="hljs-literal">null</span>));<br>        System.out.println(isValid(tree, <span class="hljs-string">&quot;北京市&quot;</span>, <span class="hljs-string">&quot;天河区&quot;</span>, <span class="hljs-literal">null</span>));<br>        System.out.println(isValid(tree, <span class="hljs-string">&quot;北京市&quot;</span>, <span class="hljs-string">&quot;天河区&quot;</span>, <span class="hljs-string">&quot;武强县&quot;</span>));<br>        System.out.println(isValid(tree, <span class="hljs-string">&quot;河北省&quot;</span>, <span class="hljs-string">&quot;衡水市&quot;</span>, <span class="hljs-string">&quot;武强县&quot;</span>));<br>        System.out.println(isValid(tree, <span class="hljs-string">&quot;河北省&quot;</span>, <span class="hljs-string">&quot;衡水市&quot;</span>, <span class="hljs-string">&quot;武强县1&quot;</span>));<br>        System.out.println(isValid(tree, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>, <span class="hljs-literal">null</span>));<br><span class="hljs-comment">//        System.out.println();</span><br>        printTree(tree);<br>    &#125;<br><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 解析文件</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> file</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     * <span class="hljs-doctag">@throws</span> IOException</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> List&lt;Tree&gt; <span class="hljs-title function_">parseFile</span><span class="hljs-params">(File file)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>        List&lt;Tree&gt; result = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>        <span class="hljs-type">InputStreamReader</span> <span class="hljs-variable">read</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">InputStreamReader</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FileInputStream</span>(file),<span class="hljs-string">&quot;UTF-8&quot;</span>);<br>        BufferedReader br= <span class="hljs-keyword">new</span> <span class="hljs-title class_">BufferedReader</span>(read);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">line</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br>        <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-keyword">while</span>((line = br.readLine()) != <span class="hljs-literal">null</span>)&#123;<br>                <span class="hljs-type">Tree</span> <span class="hljs-variable">tree</span> <span class="hljs-operator">=</span> parseString(line);<br>                result.add(tree);<br>            &#125;<br>        &#125;<span class="hljs-keyword">finally</span> &#123;<br>            br.close();<br>            read.close();<br>        &#125;<br>        <span class="hljs-keyword">return</span> result;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 解析每行字符串</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> str</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Tree <span class="hljs-title function_">parseString</span><span class="hljs-params">(String str)</span>&#123;<br>        <span class="hljs-type">Tree</span> <span class="hljs-variable">tree</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Tree</span>();<br>        String[] split = str.split(<span class="hljs-string">&quot;-&quot;</span>);<br>        <span class="hljs-keyword">if</span>(split.length&gt;<span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-type">String</span> <span class="hljs-variable">parentStr</span> <span class="hljs-operator">=</span> split[<span class="hljs-number">0</span>];<br>            String[] parentStrArray = parentStr.split(<span class="hljs-string">&quot;:&quot;</span>);<br>            <span class="hljs-keyword">if</span>(parentStrArray.length&gt;<span class="hljs-number">0</span>)&#123;<br>                tree.setParent(Integer.valueOf(parentStrArray[<span class="hljs-number">0</span>]));<br>                tree.setParentArea(parentStrArray[<span class="hljs-number">1</span>]);<br>            &#125;<br>            <span class="hljs-type">String</span> <span class="hljs-variable">childStr</span> <span class="hljs-operator">=</span> split[<span class="hljs-number">1</span>];<br>            String[] childStrArray = childStr.split(<span class="hljs-string">&quot;:&quot;</span>);<br>            <span class="hljs-keyword">if</span>(childStrArray.length&gt;<span class="hljs-number">0</span>)&#123;<br>                tree.setData(Integer.valueOf(childStrArray[<span class="hljs-number">0</span>]));<br>                tree.setArea(childStrArray[<span class="hljs-number">1</span>]);<br>            &#125;<br><br>            <span class="hljs-keyword">return</span> tree;<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        &#125;<br>    &#125;<br><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 构建树</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> trees</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Tree <span class="hljs-title function_">buildTree</span><span class="hljs-params">(List&lt;Tree&gt; trees)</span> &#123;<br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * groupingby 二级code 获取一个已经groupby的 二级-三级关系的map</span><br><span class="hljs-comment">         */</span><br>        Map&lt;Integer, List&lt;Tree&gt;&gt; tempChildrenMap = sortMap(trees.stream().filter(tree -&gt; tree.getParent() != <span class="hljs-number">0</span>).sorted(Comparator.comparing(Tree::getData)).collect(Collectors.groupingBy(tree -&gt; tree.getParent())));<br>        <span class="hljs-comment">//todo 可优化</span><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 获取map key所有二级关系的code</span><br><span class="hljs-comment">         */</span><br>        Set&lt;Integer&gt; keys = tempChildrenMap.keySet();<br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * key所有二级关系的code构建一级-二级关系 零级-一级关系的Tree 其实应该先构建了Tree的List再转map</span><br><span class="hljs-comment">         */</span><br>        List&lt;Tree&gt; allTrees = getSecondAndOne(keys,trees);<br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * groupingby 二级code 获取一个已经groupby的 二级-三级关系的map 完整数据</span><br><span class="hljs-comment">         */</span><br>        Map&lt;Integer, List&lt;Tree&gt;&gt; childrenMap = sortMap(allTrees.stream().filter(tree -&gt; tree.getParent() != <span class="hljs-number">0</span>).sorted(Comparator.comparing(Tree::getData)).collect(Collectors.groupingBy(tree -&gt; tree.getParent())));<br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 遍历 把所有的节点的children都关联上 引用类型 自然会一一关联</span><br><span class="hljs-comment">         */</span><br>        allTrees.forEach(tree -&gt; tree.setChildren(childrenMap.get(tree.getData())));<br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * 最后获取根节点</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-keyword">return</span> allTrees.stream().filter(tree -&gt; tree.getParent() == <span class="hljs-number">0</span>).collect(Collectors.toList()).get(<span class="hljs-number">0</span>);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Map <span class="hljs-title function_">sortMap</span><span class="hljs-params">(Map&lt;Integer, List&lt;Tree&gt;&gt; childrenMap)</span> &#123;<br>        <span class="hljs-keyword">return</span> childrenMap.entrySet().stream()<br>                .sorted(Map.Entry.comparingByKey())<br>                .collect(<br>                        Collectors.toMap(<br>                                Map.Entry::getKey,<br>                                Map.Entry::getValue,<br>                                (oldVal, newVal) -&gt; oldVal,<br>                                LinkedHashMap::<span class="hljs-keyword">new</span><br>                        )<br>                );<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * key为二层节点 构建一二层节点</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> List&lt;Tree&gt; <span class="hljs-title function_">getSecondAndOne</span><span class="hljs-params">(Set&lt;Integer&gt; keys,List&lt;Tree&gt; trees)</span>&#123;<br>        keys.forEach(key-&gt;&#123;<br>            <span class="hljs-type">Tree</span> <span class="hljs-variable">tempTree</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Tree</span>();<br>            tempTree.setParent(<span class="hljs-number">1</span>);<br>            tempTree.setData(key);<br>            <span class="hljs-type">Tree</span> <span class="hljs-variable">tree</span> <span class="hljs-operator">=</span> getTree(trees, key);<br>            tempTree.setArea(tree.getParentArea());<br>            trees.add(tempTree);<br>        &#125;);<br>        trees.add(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Tree</span>(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-string">&quot;中国&quot;</span>,<span class="hljs-literal">null</span>,<span class="hljs-literal">null</span>));<br>        <span class="hljs-keyword">return</span> trees;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 根据data查找对应Tree</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> trees</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> data</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Tree <span class="hljs-title function_">getTree</span><span class="hljs-params">(List&lt;Tree&gt; trees, Integer data)</span>&#123;<br>        <span class="hljs-keyword">for</span>(Tree tree:trees) &#123;<br>            <span class="hljs-type">Integer</span> <span class="hljs-variable">dataTemp</span> <span class="hljs-operator">=</span> tree.getParent();<br>            <span class="hljs-keyword">if</span>(dataTemp.equals(data))&#123;<br>                <span class="hljs-keyword">return</span> tree;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>    &#125;<br><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 构建树</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> trees</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Map&lt;Integer, List&lt;Tree&gt;&gt; <span class="hljs-title function_">buildTreeMap</span><span class="hljs-params">(List&lt;Tree&gt; trees)</span> &#123;<br>        <span class="hljs-keyword">return</span> trees.stream().filter(tree -&gt; tree.getParent() != <span class="hljs-number">1</span>).collect(Collectors.groupingBy(tree -&gt; tree.getParent()));<br>    &#125;<br><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 是否有孩子节点</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isHasChild</span><span class="hljs-params">(Tree tree)</span>&#123;<br>        <span class="hljs-keyword">if</span>(tree.getChildren()!=<span class="hljs-literal">null</span>&amp;&amp;tree.getChildren().size()&gt;<span class="hljs-number">0</span>&amp;&amp;tree.getChildren().get(<span class="hljs-number">0</span>).getData()!=<span class="hljs-literal">null</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 集合是否为空</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> list</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isEmpty</span><span class="hljs-params">(List list)</span>&#123;<br>        <span class="hljs-keyword">if</span>(list!=<span class="hljs-literal">null</span>&amp;&amp;list.size()&gt;<span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 判断地址是否合法</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> lv1</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> lv2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> lv3</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isValid</span><span class="hljs-params">(Tree tree,String lv1,String lv2,String lv3)</span>&#123;<br>        <span class="hljs-keyword">if</span>(!isHasChild(tree))&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">if</span>(lv1!=<span class="hljs-literal">null</span>&amp;&amp;!lv1.equals(<span class="hljs-string">&quot;&quot;</span>))&#123;<br>                List&lt;Tree&gt; children = tree.getChildren();<br>                <span class="hljs-type">Tree</span> <span class="hljs-variable">tree1</span> <span class="hljs-operator">=</span> ifHasData(children, lv1);<br>                <span class="hljs-keyword">if</span>(tree1!=<span class="hljs-literal">null</span>)&#123;<br>                    <span class="hljs-keyword">if</span>(lv2!=<span class="hljs-literal">null</span>&amp;&amp;!lv2.equals(<span class="hljs-string">&quot;&quot;</span>))&#123;<br>                        <span class="hljs-type">Tree</span> <span class="hljs-variable">tree2</span> <span class="hljs-operator">=</span> ifHasData(tree1.getChildren(), lv2);<br>                        <span class="hljs-keyword">if</span>(tree2!=<span class="hljs-literal">null</span>)&#123;<br>                            <span class="hljs-keyword">if</span>(lv3!=<span class="hljs-literal">null</span>&amp;&amp;!lv3.equals(<span class="hljs-string">&quot;&quot;</span>))&#123;<br>                                <span class="hljs-type">Tree</span> <span class="hljs-variable">tree3</span> <span class="hljs-operator">=</span> ifHasData(tree2.getChildren(), lv3);<br>                                <span class="hljs-keyword">if</span>(tree3!=<span class="hljs-literal">null</span>)&#123;<br>                                    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>                                &#125;<span class="hljs-keyword">else</span>&#123;<br>                                    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>                                &#125;<br>                            &#125;<span class="hljs-keyword">else</span>&#123;<br>                                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>                            &#125;<br>                        &#125;<span class="hljs-keyword">else</span>&#123;<br>                            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>                        &#125;<br>                    &#125;<span class="hljs-keyword">else</span>&#123;<br>                        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>                    &#125;<br>                &#125;<span class="hljs-keyword">else</span>&#123;<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>                &#125;<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br><br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 寻找是否有该节点 有的话返回</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> trees</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> area</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Tree <span class="hljs-title function_">ifHasData</span><span class="hljs-params">(List&lt;Tree&gt; trees,String area)</span>&#123;<br>        <span class="hljs-keyword">for</span>(Tree tree:trees)&#123;<br>            <span class="hljs-keyword">if</span>(tree.getArea().equals(area))&#123;<br>                <span class="hljs-keyword">return</span> tree;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>    &#125;<br><br><br>    <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-variable">lv</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">printTree</span><span class="hljs-params">(Tree tree)</span>&#123;<br>        <span class="hljs-keyword">if</span>(tree!=<span class="hljs-literal">null</span>)&#123;<br>            System.out.println(printBlank(lv)+<span class="hljs-string">&quot;-&quot;</span> + tree.getData() + <span class="hljs-string">&quot;:&quot;</span> + tree.getArea());<br>        &#125;<br>        <span class="hljs-keyword">if</span>(isHasChild(tree))&#123;<br>            lv++;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; tree.getChildren().size(); i++) &#123;<br>                printTree(tree.getChildren().get(i));<br>            &#125;<br>            lv--;<br>        &#125;<br>    &#125;<br><br><br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title function_">printBlank</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span>&#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">blank</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            blank = blank+<span class="hljs-string">&quot; &quot;</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> blank;<br>    &#125;<br><br><br>&#125;<br><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 地区树实体</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tree</span>&#123;<br>    <span class="hljs-keyword">private</span> Integer parent;<br>    <span class="hljs-keyword">private</span> Integer data;<br>    <span class="hljs-keyword">private</span> String area;<br>    <span class="hljs-keyword">private</span> String parentArea;<br>    <span class="hljs-keyword">private</span> List&lt;Tree&gt; children;<br><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">getParentArea</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> parentArea;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">setParentArea</span><span class="hljs-params">(String parentArea)</span> &#123;<br>        <span class="hljs-built_in">this</span>.parentArea = parentArea;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">getArea</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> area;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">setArea</span><span class="hljs-params">(String area)</span> &#123;<br>        <span class="hljs-built_in">this</span>.area = area;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Tree</span><span class="hljs-params">()</span> &#123;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Tree</span><span class="hljs-params">(Integer parent, Integer data, List&lt;Tree&gt; children)</span> &#123;<br>        <span class="hljs-built_in">this</span>.parent = parent;<br>        <span class="hljs-built_in">this</span>.data = data;<br>        <span class="hljs-built_in">this</span>.children = children;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Tree</span><span class="hljs-params">(Integer parent, Integer data,String area,String parentArea, List&lt;Tree&gt; children)</span> &#123;<br>        <span class="hljs-built_in">this</span>.parent = parent;<br>        <span class="hljs-built_in">this</span>.parentArea = parentArea;<br>        <span class="hljs-built_in">this</span>.data = data;<br>        <span class="hljs-built_in">this</span>.children = children;<br>        <span class="hljs-built_in">this</span>.area = area;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> Integer <span class="hljs-title function_">getData</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> data;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">setData</span><span class="hljs-params">(Integer data)</span> &#123;<br>        <span class="hljs-built_in">this</span>.data = data;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> Integer <span class="hljs-title function_">getParent</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> parent;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">setParent</span><span class="hljs-params">(Integer parent)</span> &#123;<br>        <span class="hljs-built_in">this</span>.parent = parent;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> List&lt;Tree&gt; <span class="hljs-title function_">getChildren</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> children;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">setChildren</span><span class="hljs-params">(List&lt;Tree&gt; children)</span> &#123;<br>        <span class="hljs-built_in">this</span>.children = children;<br>    &#125;<br><br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">toString</span><span class="hljs-params">()</span> &#123;<br><span class="hljs-comment">//        return &quot;-&quot;+data+&quot;:&quot;+area+children;</span><br><br><span class="hljs-comment">//        return &quot;\n-&quot;+data+&quot;:&quot;+area+children;</span><br><br>        <span class="hljs-type">String</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;-&quot;</span>+data+<span class="hljs-string">&quot;:&quot;</span>+area;<br>        <span class="hljs-keyword">if</span>(children!=<span class="hljs-literal">null</span>)&#123;<br>            result = result + <span class="hljs-string">&quot;\n   &quot;</span>+children.toString();<br>        &#125;<br>        <span class="hljs-keyword">return</span> result;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20200820202923154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2MDM3Nw==,size_16,color_FFFFFF,t_70"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;       今天我下班的时候接到了昨晚阿里巴巴面试我的技术面试官的电话，他问我昨晚的编程题是提交了全部的代码吗，我那时候正在地铁刚下班也有点迷糊，而且我想着昨晚的题也基本完成了90%应该没问题，于是我就说了：”应该是的“，然后说了一些昨晚没全部完成的理由。后面我们的通话就</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="原创" scheme="http://example.com/tags/%E5%8E%9F%E5%88%9B/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper集群与Leader选举</title>
    <link href="http://example.com/2020/08/18/Zookeeper%E9%9B%86%E7%BE%A4%E4%B8%8ELeader%E9%80%89%E4%B8%BE/"/>
    <id>http://example.com/2020/08/18/Zookeeper%E9%9B%86%E7%BE%A4%E4%B8%8ELeader%E9%80%89%E4%B8%BE/</id>
    <published>2020-08-18T07:40:33.000Z</published>
    <updated>2024-01-07T10:21:16.602Z</updated>
    
    <content type="html"><![CDATA[<p>ZooKeeper是一个开源分布式协调服务、分布式数据一致性解决方案。可基于ZooKeeper实现命名服务、集群管理、Master选举、分布式锁等功能。</p><p><strong>高可用</strong></p><p>为了保证ZooKeeper的可用性，在生产环境中我们使用ZooKeeper集群模式对外提供服务，并且集群规模至少由3个ZooKeeper节点组成。</p><p>集群至少由3个节点组成</p><p>ZooKeeper其实2个节点也可以组成集群并对外提供服务，但我们使用集群主要目的是为了高可用。如果2个节点组成集群，其中1个节点挂了，另外ZooKeeper节点不能正常对外提供服务。因此也失去了集群的意义。</p><p>如果3个节点组成集群，其中1个节点挂掉后，根据ZooKeeper的Leader选举机制是可以从另外2个节点选出一个作为Leader的，集群可以继续对外提供服务。</p><p>并非节点越多越好</p><ul><li>节点越多，使用的资源越多</li><li>节点越多，ZooKeeper节点间花费的通讯成本越高，节点间互连的Socket也越多。影响ZooKeeper集群事务处理</li><li>节点越多，造成脑裂的可能性越大</li></ul><p>集群规模为奇数</p><p>集群规模除了考虑自身成本和资源外还要结合ZooKeeper特性考虑：</p><ul><li>节省资源<br>3节点集群和4节点集群，我们选择使用3节点集群；5节点集群和6节点集群，我们选择使用5节点集群。以此类推。因为生产环境为了保证高可用，3节点集群最多只允许挂1台，4节点集群最多也只允许挂1台(过半原则中解释了原因)。同理5节点集群最多允许挂2台，6节点集群最多也只允许挂2台。<br>出于对资源节省的考虑，我们应该使用奇数节点来满足相同的高可用性。</li><li>集群可用性<br>当集群中节点间网络通讯出现问题时奇数和偶数对集群的影响</li></ul><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi1iYmYyNGY3ZTA1N2FlZWUyOWRkMDY4MjE4ZGUyY2U5OF83MjB3LmpwZw?x-oss-process=image/format,png"></p><p>集群配置</p><p>ZooKeeper集群配置至少需要2处变更：</p><p><strong>1、增加集群配置</strong></p><p>在{ZK_HOME}&#x2F;conf&#x2F;zoo.cfg中增加集群的配置，结构以server.id&#x3D;ip:port1:port2为标准。</p><p>比如下面配置文件中表示由3个ZooKeeper组成的集群：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs auto">server.1=localhost:2881:3881<br>server.2=localhost:2882:3882<br>server.3=localhost:2883:3883<br></code></pre></td></tr></table></figure><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi03NDhlM2NlMTU2NzZlZGU1MzM2ODE2MmVkYzMyYmJiMF83MjB3LnBuZw?x-oss-process=image/format,png"></p><p><strong>2、配置节点id</strong></p><p>zoo.cfg中配置集群时需要指定server.id，这个id需要在dataDir（zoo.cfg中配置）指定的目录中创建myid文件，文件内容就是当前ZooKeeper节点的id。</p><p><strong>集群角色</strong></p><p>ZooKeeper没有使用Master&#x2F;Slave的概念，而是将集群中的节点分为了3类角色：</p><ul><li><p>Leader</p><p>在一个ZooKeeper集群中，只能存在一个Leader，这个Leader是集群中事务请求唯一的调度者和处理者，所谓事务请求是指会改变集群状态的请求；Leader根据事务ID可以保证事务处理的顺序性。<br>如果一个集群中存在多个Leader，这种现象称为「脑裂」。试想一下，一个集群中存在多个Leader会产生什么影响？<br>相当于原本一个大集群，裂出多个小集群，他们之间的数据是不会相互同步的。「脑裂」后集群中的数据会变得非常混乱。</p></li><li><p>Follower<br>Follower角色的ZooKeeper服务只能处理非事务请求；如果接收到客户端事务请求会将请求转发给Leader服务器；参与Leader选举；参与Leader事务处理投票处理。<br>Follower发现集群中Leader不可用时会变更自身状态，并发起Leader选举投票，最终集群中的某个Follower会被选为Leader。</p></li><li><p>Observer<br>Observer与Follower很像，可以处理非事务请求；将事务请求转发给Leader服务器。<br>与Follower不同的是，Observer不会参与Leader选举；不会参与Leader事务处理投票。<br>Observer用于不影响集群事务处理能力的前提下提升集群的非事务处理能力。</p></li></ul><p><strong>Leader选举</strong></p><p>Leader在集群中是非常重要的一个角色，负责了整个事务的处理和调度，保证分布式数据一致性的关键所在。既然Leader在ZooKeeper集群中这么重要所以一定要保证集群在任何时候都有且仅有一个Leader存在。</p><p>如果集群中Leader不可用了，需要有一个机制来保证能从集群中找出一个最优的服务晋升为Leader继续处理事务和调度等一系列职责。这个过程称为Leader选举。</p><p>选举机制</p><p>ZooKeeper选举Leader依赖下列原则并遵循优先顺序：</p><p><strong>1、选举投票必须在同一轮次中进行</strong></p><p>如果Follower服务选举轮次不同，不会采纳投票。</p><p><strong>2、数据最新的节点优先成为Leader</strong></p><p>数据的新旧使用事务ID判定，事务ID越大认为节点数据约接近Leader的数据，自然应该成为Leader。</p><p><strong>3、比较server.id，id值大的优先成为Leader</strong></p><p>如果每个参与竞选节点事务ID一样，再使用server.id做比较。server.id是节点在集群中唯一的id，myid文件中配置。</p><p>不管是在集群启动时选举Leader还是集群运行中重新选举Leader。集群中每个Follower角色服务都是以上面的条件作为基础推选出合适的Leader，一旦出现某个节点被过半推选，那么该节点晋升为Leader。</p><p>过半原则</p><p>ZooKeeper集群会有很多类型投票。Leader选举投票；事务提议投票；这些投票依赖过半原则。就是说ZooKeeper认为投票结果超过了集群总数的一半，便可以安全的处理后续事务。</p><ul><li><strong>事务提议投票</strong><br>假设有3个节点组成ZooKeeper集群，客户端请求添加一个节点。Leader接到该事务请求后给所有Follower发起「创建节点」的提议投票。如果Leader收到了超过集群一半数量的反馈，继续给所有Follower发起commit。此时Leader认为集群过半了，就算自己挂了集群也是安全可靠的。</li><li><strong>Leader选举投票</strong><br>假设有3个节点组成ZooKeeper集群，这时Leader挂了，需要投票选举Leader。当相同投票结果过半后Leader选出。</li><li><strong>集群可用节点</strong><br>ZooKeeper集群中每个节点有自己的角色，对于集群可用性来说必须满足过半原则。这个过半是指Leader角色 + Follower角色可用数大于集群中Leader角色 + Follower角色总数。<br>假设有5个节点组成ZooKeeper集群，一个Leader、两个Follower、两个Observer。当挂掉两个Follower或挂掉一个Leader和一个Follower时集群将不可用。因为Observer角色不参与任何形式的投票。</li></ul><p>所谓过半原则算法是说票数 &gt; 集群总节点数&#x2F;2。其中集群总节点数&#x2F;2的计算结果会向下取整。</p><p>在ZooKeeper源代码QuorumMaj.java中实现了这个算法。下面代码片段有所缩减。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs auto">public boolean containsQuorum(HashSet&lt;Long&gt; set) &#123;<br>  /** n是指集群总数 */<br>  int half = n / 2;<br>  return (set.size() &gt; half);<br>&#125;<br></code></pre></td></tr></table></figure><p>回过头我们看一下奇数和偶数集群在Leader选举的结果</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWM0LnpoaW1nLmNvbS84MC92Mi03OWExZTRmYzU1OTdmODg3ZGMwNGZlNWJlNDljNWUxMV83MjB3LnBuZw?x-oss-process=image/format,png"></p><p>所以3节点和4节点组成的集群在ZooKeeper过半原则下都最多只能挂1节点，但是4比3要多浪费一个节点资源。</p><p><strong>场景实战</strong></p><p>我们以两个场景来了解集群不可用时Leader重新选举的过程。</p><p>3节点集群重选Leader</p><p>假设有3节点组成的集群，分别是server.1（Follower）、server.2（Leader）、server.3（Follower）。此时server.2不可用了。集群会产生以下变化：</p><p><strong>1、集群不可用</strong></p><p>因为Leader挂了，集群不可用于事务请求了。</p><p><strong>2、状态变更</strong></p><p>所有Follower节点变更自身状态为LOOKING，并且变更自身投票。投票内容就是自己节点的事务ID和server.id。我们以(事务ID, server.id)表示。</p><p>假设server.1的事务id是10，变更的自身投票就是（10, 1）；server.3的事务id是8，变更的自身投票就是（8, 3）。</p><p><strong>3、首轮投票</strong></p><p>将变更的投票发给集群中所有的Follower节点。server.1将（10, 1）发给集群中所有Follower，包括它自己。server.3也一样，将（8, 3）发给所有Follower。</p><p>所以server.1将收到（10, 1）和（8, 3）两个投票，server.3将收到（8, 3）和（10, 1）两个投票。</p><p><strong>4、投票PK</strong></p><p>每个Follower节点除了发起投票外，还接其他Follower发来的投票，并与自己的投票PK(比较两个提议的事务ID以及server.id)，PK结果决定是否要变更自身状态并再次投票。</p><p>对于server.1来说收到（10, 1）和（8, 3）两个投票，与自己变更的投票比较后没有一个比自身投票（10, 1）要大的，所以server.1维持自身投票不变。</p><p>对于server.3来说收到（10, 1）和（8, 3）两个投票，与自身变更的投票比较后认为server.1发来的投票要比自身的投票大，所以server.3会变更自身投票并将变更后的投票发给集群中所有Follower。</p><p><strong>5、第二轮投票</strong></p><p>server.3将自身投票变更为（10, 1）后再次将投票发给集群中所有Follower。</p><p>对于server.1来说在第二轮收到了（10, 1）投票，server.1经过PK后继续维持不变。</p><p>对于server.3来说在第二轮收到了（10, 1）投票，因为server.3自身已变更为（10,1）投票，所以本次也维持不变。</p><p>此时server.1和server.3在投票上达成一致。</p><p><strong>6、投票接收桶</strong></p><p>节点接收的投票存储在一个接收桶里，每个Follower的投票结果在桶内只记录一次。ZooKeeper源码中接收桶用Map实现。</p><p>下面代码片段是ZooKeeper定义的接收桶，以及向桶内写入数据。Map.Key是Long类型，用来存储投票来源节点的server.id，Vote则是对应节点的投票信息。节点收到投票后会更新这个接收桶，也就是说桶里存储了所有Follower节点的投票并且仅存最后一次的投票结果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs auto">HashMap&lt;Long, Vote&gt; recvset = new HashMap&lt;Long, Vote&gt;();<br>recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch));<br></code></pre></td></tr></table></figure><p><strong>7、统计投票</strong></p><p>接收到投票后每次都会尝试统计投票，投票统计过半后选举成功。</p><p>投票统计的数据来源于投票接收桶里的投票数据，我们从头描述这个场景，来看一下接收桶里的数据变化情况。</p><p>server.2挂了后，server.1和server.3发起第一轮投票。</p><p>server.1接收到来自server.1的（10, 1）投票和来自server.3的（8, 3）投票。</p><p>server.3同样接收到来自server.1的（10, 1）投票和来自server.3的（8, 3）投票。此时server.1和server.3接收桶里的数据是这样的：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi0yZjJjYzIzMDJiNDgxNzc2OTJhYzM1MGQ3YzFiNmMwMV83MjB3LmpwZw?x-oss-process=image/format,png"></p><p>server.3经过PK后认为server.1的选票比自己要大，所以变更了自己的投票并重新发起投票。</p><p>server.1收到了来自server.3的（10, 1）投票;server.3收到了来自sever.3的（10, 1）投票。此时server.1和server.3接收桶里的数据变成了这样：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi0xNDVkNTlhMjcxZDliYTkxMGIwMWM1ZDg4ZDYxZDg0ZV83MjB3LmpwZw?x-oss-process=image/format,png"></p><p>基于ZooKeeper过半原则：桶内投票选举server.1作为Leader出现2次，满足了过半 2 &gt; 3&#x2F;2 即 2&gt;1。</p><p>最后sever.1节点晋升为Leader，server.3变更为Follower。</p><h4 id="集群扩容Leader启动时机"><a href="#集群扩容Leader启动时机" class="headerlink" title="集群扩容Leader启动时机"></a><strong>集群扩容Leader启动时机</strong></h4><p>ZooKeeper集群扩容需要在zoo.cfg配置文件中加入新节点。扩容流程在ZooKeeper扩容中介绍。这里我们以3节点扩容到5节点时，Leader启动时机做一个讨论。</p><p>假设目前有3个节点组成集群，分别是server.1（Follower）、server.2（Leader）、server.3（Follower），假设集群中节点事务ID相同。配置文件如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs auto">server.1=localhost:2881:3881<br>server.2=localhost:2882:3882<br>server.3=localhost:2883:3883<br></code></pre></td></tr></table></figure><p><strong>1、新节点加入集群</strong></p><p>集群中新增server.4和server.5两个节点，首先修改server.4和server.5的zoo.cfg配置并启动。节点4和5在启动后会变更自身投票状态，发起一轮Leader选举投票。server.1、server.2、server.3收到投票后由于集群中已有选定Leader，所以会直接反馈server.4和server.5投票结果：server.2是Leader。server.4和server.5收到投票后基于过半原则认定server.2是Leader，自身便切换为Follower。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs auto">#节点server.1、server.2、server.3配置<br>server.1=localhost:2881:3881<br>server.2=localhost:2882:3882<br>server.3=localhost:2883:3883<br><br>#节点server.4、server.5配置<br>server.1=localhost:2881:3881<br>server.2=localhost:2882:3882<br>server.3=localhost:2883:3883<br>server.4=localhost:2884:3884<br>server.5=localhost:2885:3885<br></code></pre></td></tr></table></figure><p><strong>2、停止Leader</strong></p><p>server.4和server.5的加入需要修改集群server.1、server.2、server.3的zoo.cfg配置并重启。但是Leader节点何时重启是有讲究的，因为Leader重启会导致集群中Follower发起Leader重新选举。在server.4和server.5两个新节点正常加入后，集群不会因为新节点加入变更Leader，所以目前server.2依然是Leader。</p><p>我们以一个错误的顺序启动，看一下集群会发生什么样的变化。修改server.2zoo.cfg配置文件，增加server.4和server.5的配置并停止server.2服务。停止server.2后，Leader不存在了，集群中所有Follower会发起投票。当server.1和server.3发起投票时并不会将投票发给server.4和server.5，因为在server.1和server.3的集群配置中不包含server.4和server.5节点。相反，server.4和server.5会把选票发给集群中所有节点。也就是说对于server.1和server.3他们认为集群中只有3个节点。对于server.4和server.5他们认为集群中有5个节点。</p><p>根据过半原则，server.1和server.3很快会选出一个新Leader，我们这里假设server.3晋级成为了新Leader。但是我们没有启动server.2的情况下，因为投票不满足过半原则，server.4和server.5会一直做投票选举Leader的动作。截止到现在集群中节点状态是这样的：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi1jN2E5N2M0OThlMTEwOGEyOTFjY2FjNmI2NmNmYWQ2N183MjB3LnBuZw?x-oss-process=image/format,png"></p><p><strong>3、启动Leader</strong></p><p>现在，我们启动server.2。因为server.2zoo.cfg已经是server.1到serverv.5的全量配置，在server.2启动后会发起选举投票，同时serverv.4和serverv.5也在不断的发起选举投票。当server.2的选举轮次和serverv.4与serverv.5选举轮次对齐后，最终server.2会变更自己的状态，认定server.5是Leaader。</p><p>意想不到的事情发生了，出现两个Leader：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS84MC92Mi0yM2NhMTJmNDk4YzMyYjI3MGYwN2Y2N2Q3NjVkNjkwMl83MjB3LnBuZw?x-oss-process=image/format,png"></p><p>ZooKeeper集群扩容时，如果Leader节点最后启动就可以避免这类问题发生，因为在Leader节点重启前，所有的Follower节点zoo.cfg配置已经是相同的，他们基于同一个集群配置两两互联，做投票选举。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;ZooKeeper是一个开源分布式协调服务、分布式数据一致性解决方案。可基于ZooKeeper实现命名服务、集群管理、Master选举、分布式锁等功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;高可用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了保证ZooKeeper的可用性，在生产环境中我</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>CP和AP有是什么？有什么区别？</title>
    <link href="http://example.com/2020/08/18/CP%E5%92%8CAP%E6%9C%89%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F/"/>
    <id>http://example.com/2020/08/18/CP%E5%92%8CAP%E6%9C%89%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F/</id>
    <published>2020-08-18T07:31:32.000Z</published>
    <updated>2024-01-07T10:21:33.195Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CP和AP有是什么？有什么区别？"><a href="#CP和AP有是什么？有什么区别？" class="headerlink" title="CP和AP有是什么？有什么区别？"></a>CP和AP有是什么？有什么区别？</h2><p>最新推荐文章于 2024-01-06 16:53:14 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/reprint.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2024-01-06 16:53:14 发布</p><p>最近有时间研究分布式架构，因为公司使用的Zookeeper，并没有使用Spring Cloud Eureka，所以想探究一下他们之间的区别，于是看到简书里的文章：<a href="https://www.jianshu.com/p/e47c027a9aeb">Spring Cloud Eureka简介及与Zookeeper对比</a>，明显的区别可能就是Zookeeper为CP设计，而Eureka为AP设计，但是对CAP&#x2F;AP&#x2F;CP很不理解，于是查阅资料，做一个简单的了解。</p><blockquote><p>Eureka服务治理机制与Dubbo服务治理机制的比较</p><table><thead><tr><th>Feature</th><th>Eureka</th><th>Zookeeper</th></tr></thead><tbody><tr><td>服务健康检查</td><td>可配支持</td><td>(弱)长连接，keepalive</td></tr><tr><td>CAP</td><td>AP</td><td>CP</td></tr><tr><td>watch支持（客户端观察到服务提供者变化）</td><td>支持 long polling&#x2F;大部分增量</td><td>支持</td></tr><tr><td>自我保护</td><td>支持</td><td>-</td></tr><tr><td>客户端缓存</td><td>支持</td><td>-</td></tr><tr><td>自身集群的监控</td><td>metrics</td><td>-</td></tr></tbody></table><p>Eureka支持健康检查，自我保护等</p><p>Zookeeper为CP设计，Eureka为AP设计。作为服务发现产品，可用性优先级较高，一致性的特点并不重要，宁可返回错误的数据，也比不反回结果要好得多。</p><p>服务列表变更Zookeeper服务端会有通知，Eureka则通过长轮询来实现，Eureka未来会实现watch机制</p></blockquote><p>CAP理论提出就是针对分布式数据库环境的，所以，P这个属性是必须具备的。<br>P就是在分布式环境中，由于网络的问题可能导致某个节点和其它节点失去联系，这时候就形成了P(partition)，也就是由于网络问题，将系统的成员隔离成了2个区域，互相无法知道对方的状态，这在分布式环境下是非常常见的。<br>因为P是必须的，那么我们需要选择的就是A和C。<br>大家知道，在分布式环境下，为了保证系统可用性，通常都采取了复制的方式，避免一个节点损坏，导致系统不可用。那么就出现了每个节点上的数据出现了很多个副本的情况，而数据从一个节点复制到另外的节点时需要时间和要求网络畅通的，所以，当P发生时，也就是无法向某个节点复制数据时，这时候你有两个选择：<br>选择可用性 A(Availability)，此时，那个失去联系的节点依然可以向系统提供服务，不过它的数据就不能保证是同步的了（失去了C属性）。<br>选择一致性C(Consistency)，为了保证数据库的一致性，我们必须等待失去联系的节点恢复过来，在这个过程中，那个节点是不允许对外提供服务的，这时候系统处于不可用状态(失去了A属性)。</p><p>最常见的例子是读写分离，某个节点负责写入数据，然后将数据同步到其它节点，其它节点提供读取的服务，当两个节点出现通信问题时，你就面临着选择A（继续提供服务，但是数据不保证准确），C（用户处于等待状态，一直等到数据同步完成）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;CP和AP有是什么？有什么区别？&quot;&gt;&lt;a href=&quot;#CP和AP有是什么？有什么区别？&quot; class=&quot;headerlink&quot; title=&quot;CP和AP有是什么？有什么区别？&quot;&gt;&lt;/a&gt;CP和AP有是什么？有什么区别？&lt;/h2&gt;&lt;p&gt;最新推荐文章于 2024-0</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>Hystrix熔断机制原理剖析</title>
    <link href="http://example.com/2020/08/14/Hystrix%E7%86%94%E6%96%AD%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/"/>
    <id>http://example.com/2020/08/14/Hystrix%E7%86%94%E6%96%AD%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/</id>
    <published>2020-08-14T06:10:27.000Z</published>
    <updated>2024-01-07T10:21:30.510Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hystrix熔断机制原理剖析"><a href="#Hystrix熔断机制原理剖析" class="headerlink" title="Hystrix熔断机制原理剖析"></a>Hystrix熔断机制原理剖析</h2><p>最新推荐文章于 2024-01-02 12:13:54 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/reprint.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2024-01-02 12:13:54 发布</p><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>在分布式系统架构中多个系统之间通常是通过远程RPC调用进行通信，也就是 A 系统调用 B 系统服务，B 系统调用 C 系统的服务。当尾部应用 C 发生故障而系统 B 没有服务降级时候可能会导致 B，甚至系统 A 瘫痪，这种现象被称为雪崩现象。所以在系统设计时候要使用一定的降级策略，来保证当服务提供方服务不可用时候，服务调用方可以切换到降级后的策略进行执行。</p><h2 id="二、Hystrix-中基于自反馈调节熔断状态的算法原理"><a href="#二、Hystrix-中基于自反馈调节熔断状态的算法原理" class="headerlink" title="二、Hystrix 中基于自反馈调节熔断状态的算法原理"></a>二、Hystrix 中基于自反馈调节熔断状态的算法原理</h2><p>我们可以把熔断器想象为一个保险丝，在电路系统中，一般在所有的家电系统连接外部供电的线路中间都会加一个保险丝，当外部电压过高，达到保险丝的熔点时候，保险丝就会被熔断，从而可以切断家电系统与外部电路的联通，进而保障家电系统不会因为电压过高而损坏。</p><p>Hystrix提供的熔断器就有类似功能，当在一定时间段内服务调用方调用服务提供方的服务的次数达到设定的阈值，并且出错的次数也达到设置的出错阈值，就会进行服务降级，让服务调用方之间执行本地设置的降级策略，而不再发起远程调用。但是Hystrix提供的熔断器具有自我反馈，自我恢复的功能，Hystrix会根据调用接口的情况，让熔断器在closed,open,half-open三种状态之间自动切换。</p><p>open状态说明打开熔断，也就是服务调用方执行本地降级策略，不进行远程调用。<br>closed状态说明关闭了熔断，这时候服务调用方直接发起远程调用。<br>half-open状态，则是一个中间状态，当熔断器处于这种状态时候，直接发起远程调用。</p><p>三种状态的转换：</p><ul><li><p>closed-&gt;open:正常情况下熔断器为closed状态，当访问同一个接口次数超过设定阈值并且错误比例超过设置错误阈值时候，就会打开熔断机制，这时候熔断器状态从closed-&gt;open。</p></li><li><p>open-&gt;half-open:当服务接口对应的熔断器状态为open状态时候，所有服务调用方调用该服务方法时候都是执行本地降级方法，那么什么时候才会恢复到远程调用那？Hystrix提供了一种测试策略，也就是设置了一个时间窗口，从熔断器状态变为open状态开始的一个时间窗口内，调用该服务接口时候都委托服务降级方法进行执行。如果时间超过了时间窗口，则把熔断状态从open-&gt;half-open,这时候服务调用方调用服务接口时候，就可以发起远程调用而不再使用本地降级接口，如果发起远程调用还是失败，则重新设置熔断器状态为open状态，从新记录时间窗口开始时间。</p></li><li><p>half-open-&gt;closed: 当熔断器状态为half-open,这时候服务调用方调用服务接口时候，就可以发起远程调用而不再使用本地降级接口，如果发起远程调用成功，则重新设置熔断器状态为closed状态。</p></li></ul><p>那么有一个问题，用来判断熔断器从closed-&gt;open转换的数据是哪里来的那？其实这个是HystrixCommandMetrics对象来做的，该对象用来存在HystrixCommand的一些指标数据，比如接口调用次数，调用接口失败的次数等等，后面我们会讲解。</p><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>系统设计时候要使用一定的降级策略，来保证当服务提供方服务不可用时候，服务调用方可以切换到降级后的策略进行执行，Hystrix作为熔断器组件使用范围还是很广泛的.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Hystrix熔断机制原理剖析&quot;&gt;&lt;a href=&quot;#Hystrix熔断机制原理剖析&quot; class=&quot;headerlink&quot; title=&quot;Hystrix熔断机制原理剖析&quot;&gt;&lt;/a&gt;Hystrix熔断机制原理剖析&lt;/h2&gt;&lt;p&gt;最新推荐文章于 2024-01-02</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>谈谈服务限流算法的几种实现</title>
    <link href="http://example.com/2020/08/13/%E8%B0%88%E8%B0%88%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0/"/>
    <id>http://example.com/2020/08/13/%E8%B0%88%E8%B0%88%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E7%9A%84%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-08-13T09:53:40.000Z</published>
    <updated>2024-01-07T14:12:39.708Z</updated>
    
    <content type="html"><![CDATA[<p>保障服务稳定的三大利器：熔断降级、服务限流和故障模拟。今天和大家谈谈限流算法的几种实现方式，本文所说的限流并非是Nginx层面的限流，而是业务代码中的逻辑限流。</p><h4 id="为什么需要限流"><a href="#为什么需要限流" class="headerlink" title="为什么需要限流"></a>为什么需要限流</h4><p>按照服务的调用方，可以分为以下几种类型服务</p><p>1、与用户打交道的服务</p><p>比如web服务、对外API，这种类型的服务有以下几种可能导致机器被拖垮：</p><ul><li><p>用户增长过快（这是好事）</p></li><li><p>因为某个热点事件（微博热搜）</p></li><li><p>竞争对象爬虫</p></li><li><p>恶意的刷单</p></li></ul><p>这些情况都是无法预知的，不知道什么时候会有10倍甚至20倍的流量打进来，如果真碰上这种情况，扩容是根本来不及的（弹性扩容都是虚谈，一秒钟你给我扩一下试试）</p><p>2、对内的RPC服务</p><p>一个服务A的接口可能被BCDE多个服务进行调用，在B服务发生突发流量时，直接把A服务给调用挂了，导致A服务对CDE也无法提供服务。 这种情况时有发生，解决方案有两种： 1、每个调用方采用线程池进行资源隔离 2、使用限流手段对每个调用方进行限流</p><h4 id="限流算法实现"><a href="#限流算法实现" class="headerlink" title="限流算法实现"></a>限流算法实现</h4><p>常见的限流算法有：计数器、令牌桶、漏桶。</p><p>1、计数器算法</p><p>采用计数器实现限流有点简单粗暴，一般我们会限制一秒钟的能够通过的请求数，比如限流qps为100，算法的实现思路就是从第一个请求进来开始计时，在接下去的1s内，每来一个请求，就把计数加1，如果累加的数字达到了100，那么后续的请求就会被全部拒绝。等到1s结束后，把计数恢复成0，重新开始计数。</p><p>具体的实现可以是这样的：对于每次服务调用，可以通过 <code>AtomicLong#incrementAndGet()</code>方法来给计数器加1并返回最新值，通过这个最新值和阈值进行比较。</p><p>这种实现方式，相信大家都知道有一个弊端：如果我在单位时间1s内的前10ms，已经通过了100个请求，那后面的990ms，只能眼巴巴的把请求拒绝，我们把这种现象称为“突刺现象”</p><p>2、漏桶算法</p><p>为了消除”突刺现象”，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。</p><p>不管服务调用方多么不稳定，通过漏桶算法进行限流，每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。</p><p><img src="https://img-blog.csdn.net/20180722161419529?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmh1aTI1OA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p><p>在算法实现方面，可以准备一个队列，用来保存请求，另外通过一个线程池定期从队列中获取请求并执行，可以一次性获取多个并发执行。</p><p>这种算法，在使用过后也存在弊端：无法应对短时间的突发流量。</p><p>3、令牌桶算法</p><p>从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。</p><p>在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。</p><p>放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。</p><p><img src="https://img-blog.csdn.net/20180722161357369?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmh1aTI1OA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p><p>实现思路：可以准备一个队列，用来保存令牌，另外通过一个线程池定期生成令牌放到队列中，每来一个请求，就从队列中获取一个令牌，并继续执行。</p><p>幸运的是，通过Google开源的guava包，我们可以很轻松的创建一个令牌桶算法的限流器。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br> <br>   <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.google.guava<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br> <br>   <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>guava<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br> <br>   <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>18.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><p>通过RateLimiter类的create方法，创建限流器。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RateLimiterMain</span> &#123;<br> <br>   <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br> <br>       <span class="hljs-type">RateLimiter</span> <span class="hljs-variable">rateLimiter</span> <span class="hljs-operator">=</span> RateLimiter.create(<span class="hljs-number">10</span>);<br> <br>       <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) &#123;<br> <br>           <span class="hljs-keyword">new</span> <span class="hljs-title class_">Thread</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br> <br>               <span class="hljs-meta">@Override</span><br> <br>               <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br> <br>                   rateLimiter.acquire()<br> <br>                   System.out.println(<span class="hljs-string">&quot;pass&quot;</span>);<br> <br>               &#125;<br> <br>           &#125;).start();<br> <br>       &#125;<br> <br>   &#125;<br> <br>&#125;<br></code></pre></td></tr></table></figure><p>其实Guava提供了多种create方法，方便创建适合各种需求的限流器。在上述例子中，创建了一个每秒生成10个令牌的限流器，即100ms生成一个，并最多保存10个令牌，多余的会被丢弃。</p><p>rateLimiter提供了acquire()和tryAcquire()接口 1、使用acquire()方法，如果没有可用令牌，会一直阻塞直到有足够的令牌。 2、使用tryAcquire()方法，如果没有可用令牌，就直接返回false。 3、使用tryAcquire()带超时时间的方法，如果没有可用令牌，就会判断在超时时间内是否可以等到令牌，如果不能，就返回false，如果可以，就阻塞等待。</p><p>集群限流</p><p>前面讨论的几种算法都属于单机限流的范畴，但是业务需求五花八门，简单的单机限流，根本无法满足他们。</p><p>比如为了限制某个资源被每个用户或者商户的访问次数，5s只能访问2次，或者一天只能调用1000次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。</p><p><strong>如何实现？</strong>为了控制访问次数，肯定需要一个计数器，而且这个计数器只能保存在第三方服务，比如redis。</p><p>大概思路：每次有相关操作的时候，就向redis服务器发送一个incr命令，比如需要限制某个用户访问&#x2F;index接口的次数，只需要拼接用户id和接口名生成redis的key，每次该用户访问此接口时，只需要对这个key执行incr命令，在这个key带上过期时间，就可以实现指定时间的访问频率。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;保障服务稳定的三大利器：熔断降级、服务限流和故障模拟。今天和大家谈谈限流算法的几种实现方式，本文所说的限流并非是Nginx层面的限流，而是业务代码中的逻辑限流。&lt;/p&gt;
&lt;h4 id=&quot;为什么需要限流&quot;&gt;&lt;a href=&quot;#为什么需要限流&quot; class=&quot;headerlin</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>常用4种限流算法介绍及比较</title>
    <link href="http://example.com/2020/08/13/%E5%B8%B8%E7%94%A84%E7%A7%8D%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%AF%94%E8%BE%83/"/>
    <id>http://example.com/2020/08/13/%E5%B8%B8%E7%94%A84%E7%A7%8D%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%AF%94%E8%BE%83/</id>
    <published>2020-08-13T09:46:18.000Z</published>
    <updated>2024-01-07T10:21:08.260Z</updated>
    
    <content type="html"><![CDATA[<h2 id="常用4种限流算法介绍及比较"><a href="#常用4种限流算法介绍及比较" class="headerlink" title="常用4种限流算法介绍及比较"></a>常用4种限流算法介绍及比较</h2><p>最新推荐文章于 2023-03-30 00:22:18 发布</p><p><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/reprint.png"></p><p><a href="https://blog.csdn.net/weixin_37760377" title="Wayyyyyyyy">Wayyyyyyyy</a> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCurrentTime2.png"> 最新推荐文章于 2023-03-30 00:22:18 发布</p><p><strong>1****、计数器（固定窗口）算法</strong><br>计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略。下一个周期开始时，进行清零，重新计数。</p><p>此算法在单机还是分布式环境下实现都非常简单，使用redis的incr原子自增性和线程安全即可轻松实现。</p><p><img src="https://img-blog.csdnimg.cn/20190716091143141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTg0NjMyMA==,size_16,color_FFFFFF,t_70"></p><p>这个算法通常用于QPS限流和统计总访问量，对于秒级以上的时间周期来说，会存在一个非常严重的问题，那就是临界问题，如下图：<br><img src="https://img-blog.csdnimg.cn/20190716091413825.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTg0NjMyMA==,size_16,color_FFFFFF,t_70"></p><p>假设1min内服务器的负载能力为100，因此一个周期的访问量限制在100，然而在第一个周期的最后5秒和下一个周期的开始5秒时间段内，分别涌入100的访问量，虽然没有超过每个周期的限制量，但是整体上10秒内已达到200的访问量，已远远超过服务器的负载能力，由此可见，计数器算法方式限流对于周期比较长的限流，存在很大的弊端。</p><p><strong>2****、滑动窗口算法</strong><br>滑动窗口算法是将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期。</p><p>如下图，假设时间周期为1min，将1min再分为2个小周期，统计每个小周期的访问数量，则可以看到，第一个时间周期内，访问数量为75，第二个时间周期内，访问数量为100，超过100的访问则被限流掉了   </p><p><img src="https://img-blog.csdnimg.cn/20190716091612718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTg0NjMyMA==,size_16,color_FFFFFF,t_70"></p><p>由此可见，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。</p><p>此算法可以很好的解决固定窗口算法的临界问题。</p><p><strong>3****、漏桶算法</strong></p><p>漏桶算法是访问请求到达时直接放入漏桶，如当前容量已达到上限（限流值），则进行丢弃（触发限流策略）。漏桶以固定的速率进行释放访问请求（即请求通过），直到漏桶为空。</p><p><img src="https://img-blog.csdnimg.cn/20190716090944456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTg0NjMyMA==,size_16,color_FFFFFF,t_70"></p><p><strong>4****、令牌桶算法</strong><br>令牌桶算法是程序以r（r&#x3D;时间周期&#x2F;限流值）的速度向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，如获取到令牌则通过请求，否则触发限流策略</p><p><img src="https://img-blog.csdnimg.cn/20190716090944463.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTg0NjMyMA==,size_16,color_FFFFFF,t_70"></p><p><strong>各个算法比较</strong></p><table><tbody><tr><td><p>算法</p></td><td><p>确定参数</p></td><td><p>空间复杂度</p></td><td><p>时间复杂度</p></td><td><p>限制突发流量</p></td><td><p>平滑限流</p></td><td><p>分布式环境下实现难度</p></td></tr><tr><td><p>固定窗口</p></td><td><p>计数周期T、</p><p>周期内最大访问数N</p></td><td><p>低O(1)</p><p>（记录周期内访问次数及周期开始时间）</p></td><td><p>低O(1)</p></td><td><p>否</p></td><td><p>否</p></td><td><p>低</p></td></tr><tr><td><p>滑动窗口</p></td><td><p>计数周期T、</p><p>周期内最大访问数N</p></td><td><p>高O(N)</p><p>（记录每个小周期中的访问数量）</p></td><td><p>中O(N)</p></td><td><p>是</p></td><td><p>相对实现。滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑</p></td><td><p>中</p></td></tr><tr><td><p>漏桶</p></td><td><p>漏桶流出速度r、漏桶容量N</p></td><td><p>低O(1)</p><p>（记录当前漏桶中容量）</p></td><td><p>高O(N)</p></td><td><p>是</p></td><td><p>是</p></td><td><p>高</p></td></tr><tr><td><p>令牌桶</p></td><td><p>令牌产生速度r、令牌桶容量N</p></td><td><p>低O(1)</p><p>（记录当前令牌桶中令牌数）</p></td><td><p>高O(N)</p></td><td><p>是</p></td><td><p>是</p></td><td><p>高</p></td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;常用4种限流算法介绍及比较&quot;&gt;&lt;a href=&quot;#常用4种限流算法介绍及比较&quot; class=&quot;headerlink&quot; title=&quot;常用4种限流算法介绍及比较&quot;&gt;&lt;/a&gt;常用4种限流算法介绍及比较&lt;/h2&gt;&lt;p&gt;最新推荐文章于 2023-03-30 00:22:1</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>限流算法</title>
    <link href="http://example.com/2020/08/13/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2020/08/13/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/</id>
    <published>2020-08-13T09:42:02.000Z</published>
    <updated>2024-01-07T14:12:21.281Z</updated>
    
    <content type="html"><![CDATA[<p>保障服务稳定的三大利器：熔断降级、服务限流和故障模拟。今天和大家谈谈限流算法的几种实现方式，本文所说的限流并非是Nginx层面的限流，而是业务代码中的逻辑限流。</p><h4 id="为什么需要限流"><a href="#为什么需要限流" class="headerlink" title="为什么需要限流"></a>为什么需要限流</h4><p>按照服务的调用方，可以分为以下几种类型服务</p><p>1、与用户打交道的服务</p><p>比如web服务、对外API，这种类型的服务有以下几种可能导致机器被拖垮：</p><ul><li><p>用户增长过快（这是好事）</p></li><li><p>因为某个热点事件（微博热搜）</p></li><li><p>竞争对象爬虫</p></li><li><p>恶意的刷单</p></li></ul><p>这些情况都是无法预知的，不知道什么时候会有10倍甚至20倍的流量打进来，如果真碰上这种情况，扩容是根本来不及的（弹性扩容都是虚谈，一秒钟你给我扩一下试试）</p><p>2、对内的RPC服务</p><p>一个服务A的接口可能被BCDE多个服务进行调用，在B服务发生突发流量时，直接把A服务给调用挂了，导致A服务对CDE也无法提供服务。 这种情况时有发生，解决方案有两种： 1、每个调用方采用线程池进行资源隔离 2、使用限流手段对每个调用方进行限流</p><h4 id="限流算法实现"><a href="#限流算法实现" class="headerlink" title="限流算法实现"></a>限流算法实现</h4><p>常见的限流算法有：计数器、令牌桶、漏桶。</p><p>1、计数器算法</p><p>采用计数器实现限流有点简单粗暴，一般我们会限制一秒钟的能够通过的请求数，比如限流qps为100，算法的实现思路就是从第一个请求进来开始计时，在接下去的1s内，每来一个请求，就把计数加1，如果累加的数字达到了100，那么后续的请求就会被全部拒绝。等到1s结束后，把计数恢复成0，重新开始计数。</p><p>具体的实现可以是这样的：对于每次服务调用，可以通过 <code>AtomicLong#incrementAndGet()</code>方法来给计数器加1并返回最新值，通过这个最新值和阈值进行比较。</p><p>这种实现方式，相信大家都知道有一个弊端：如果我在单位时间1s内的前10ms，已经通过了100个请求，那后面的990ms，只能眼巴巴的把请求拒绝，我们把这种现象称为“突刺现象”</p><p>2、漏桶算法</p><p>为了消除”突刺现象”，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。</p><p>不管服务调用方多么不稳定，通过漏桶算法进行限流，每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。</p><p><img src="https://img-blog.csdn.net/20180722161419529?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmh1aTI1OA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p><p>在算法实现方面，可以准备一个队列，用来保存请求，另外通过一个线程池定期从队列中获取请求并执行，可以一次性获取多个并发执行。</p><p>这种算法，在使用过后也存在弊端：无法应对短时间的突发流量。</p><p>3、令牌桶算法</p><p>从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。</p><p>在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。</p><p>放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。</p><p><img src="https://img-blog.csdn.net/20180722161357369?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpbmh1aTI1OA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p><p>实现思路：可以准备一个队列，用来保存令牌，另外通过一个线程池定期生成令牌放到队列中，每来一个请求，就从队列中获取一个令牌，并继续执行。</p><p>幸运的是，通过Google开源的guava包，我们可以很轻松的创建一个令牌桶算法的限流器。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br> <br>   <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.google.guava<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br> <br>   <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>guava<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br> <br>   <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>18.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br> <br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs html">通过RateLimiter类的create方法，创建限流器。<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RateLimiterMain</span> &#123;<br> <br>   <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br> <br>       <span class="hljs-type">RateLimiter</span> <span class="hljs-variable">rateLimiter</span> <span class="hljs-operator">=</span> RateLimiter.create(<span class="hljs-number">10</span>);<br> <br>       <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) &#123;<br> <br>           <span class="hljs-keyword">new</span> <span class="hljs-title class_">Thread</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br> <br>               <span class="hljs-meta">@Override</span><br> <br>               <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br> <br>                   rateLimiter.acquire()<br> <br>                   System.out.println(<span class="hljs-string">&quot;pass&quot;</span>);<br> <br>               &#125;<br> <br>           &#125;).start();<br> <br>       &#125;<br> <br>   &#125;<br> <br>&#125;<br></code></pre></td></tr></table></figure><p>其实Guava提供了多种create方法，方便创建适合各种需求的限流器。在上述例子中，创建了一个每秒生成10个令牌的限流器，即100ms生成一个，并最多保存10个令牌，多余的会被丢弃。</p><p>rateLimiter提供了acquire()和tryAcquire()接口 1、使用acquire()方法，如果没有可用令牌，会一直阻塞直到有足够的令牌。 2、使用tryAcquire()方法，如果没有可用令牌，就直接返回false。 3、使用tryAcquire()带超时时间的方法，如果没有可用令牌，就会判断在超时时间内是否可以等到令牌，如果不能，就返回false，如果可以，就阻塞等待。</p><p>集群限流</p><p>前面讨论的几种算法都属于单机限流的范畴，但是业务需求五花八门，简单的单机限流，根本无法满足他们。</p><p>比如为了限制某个资源被每个用户或者商户的访问次数，5s只能访问2次，或者一天只能调用1000次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。</p><p><strong>如何实现？</strong>为了控制访问次数，肯定需要一个计数器，而且这个计数器只能保存在第三方服务，比如redis。</p><p>大概思路：每次有相关操作的时候，就向redis服务器发送一个incr命令，比如需要限制某个用户访问&#x2F;index接口的次数，只需要拼接用户id和接口名生成redis的key，每次该用户访问此接口时，只需要对这个key执行incr命令，在这个key带上过期时间，就可以实现指定时间的访问频率。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;保障服务稳定的三大利器：熔断降级、服务限流和故障模拟。今天和大家谈谈限流算法的几种实现方式，本文所说的限流并非是Nginx层面的限流，而是业务代码中的逻辑限流。&lt;/p&gt;
&lt;h4 id=&quot;为什么需要限流&quot;&gt;&lt;a href=&quot;#为什么需要限流&quot; class=&quot;headerlin</summary>
      
    
    
    
    <category term="所有文章" scheme="http://example.com/categories/%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0/"/>
    
    
    <category term="转载" scheme="http://example.com/tags/%E8%BD%AC%E8%BD%BD/"/>
    
  </entry>
  
</feed>
